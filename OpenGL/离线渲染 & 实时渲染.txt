离线渲染（Offline Rendering） 和 实时渲染（Real-time Rendering） 的核心区别就在于 是否需要“边算边显示”。


离线渲染 (Offline Rendering)
定义：渲染过程发生在播放/展示之前。先把画面用大量算力（CPU/GPU/渲染农场）计算好，生成静态图片或视频文件。用户看到的是最终结果，而不是实时计算出来的。
特点：
渲染时间长，可能一帧要几分钟甚至几小时。
追求高质量（电影特效、动画电影、建筑可视化）。
常用算法：光线追踪 (Ray Tracing)、路径追踪（Path Tracing）等复杂全局光照模型。
应用场景：
皮克斯、迪士尼的动画电影
《阿凡达》等大片的CG特效
高质量广告渲染图


实时渲染 (Real-time Rendering)
定义：渲染和展示同步进行，每秒必须能渲染出几十帧（一般 30fps/60fps），才能保证交互流畅。
特点：
渲染速度快（每帧必须在 16ms 左右算完）。
画质与性能折中，使用各种近似算法和优化（如光照贴图、屏幕空间反射、阴影贴图等）。
主要跑在 GPU 上。
应用场景：
游戏引擎（Unity、Unreal）
VR/AR
交互式可视化


离线渲染：先算好 → 再看（画质优先）。
实时渲染：边算边看（流畅优先）。


光栅化 (Rasterization)：快速，适合实时渲染（游戏引擎普遍用）。但需要额外技巧（shadow maps, cube maps, screen-space reflections）来模拟光影效果。
光线追踪 (Ray Tracing)：自然、真实，但计算量大。适合高质量离线渲染（电影特效），或者在硬件加速下做实时渲染（游戏里的“RTX ON”）。


在图形学里，**光栅化（Rasterization）**的核心目标，就是 把连续的几何图元（点、线、三角形）转换成屏幕上的离散像素。
光栅化就是把几何顶点变换成屏幕上的像素（片元），决定哪些像素被哪些图元覆盖的过程。


光栅化：几何 → 像素，快速近似（适合实时渲染）
光线追踪：像素 → 光线 → 场景，精确但慢（多用于离线渲染）


光栅化过程（简化版）
1. 顶点处理
输入：模型的顶点（3D 空间坐标 + 法线 + 纹理坐标等）
经过：世界变换 → 视图变换 → 投影变换
输出：在 屏幕空间 的 2D 顶点位置
2. 图元装配
把顶点连成图元（大多数情况是三角形）
3. 三角形光栅化
遍历屏幕上的像素，判断某个像素的中心点是不是在三角形里
如果在，就生成一个 片元 (Fragment)（可以理解为“像素候选”）
4. 片元处理（像素着色）
给每个片元计算颜色：可能用材质、光照、纹理采样等
再经过深度测试、透明度混合等，决定这个片元是不是能最终显示
5. 写入帧缓冲区
通过测试的片元变成最终的像素，出现在屏幕上
https://developer.mozilla.org/zh-CN/docs/Web/HTTP

许多客户端同时支持避免弹出登录框，而是使用包含用户名和密码的经过编码的 URL，如下所示:
https://username:password@www.example.com/
这种 URL 已被弃用

==================================================资源和 URI
HTTP 请求的内容通称为"资源"
每个资源都由一个 (URI) 来进行标识。
一般情况下，资源的名称和位置由同一个 URL（统一资源定位符，它是 URI 的一种）来标识。

URI 的最常见形式是统一资源定位符 (URL)，它也被称为 Web 地址。
https://developer.mozilla.org
https://developer.mozilla.org/zh-CN/docs/Learn/
https://developer.mozilla.org/zh-CN/search?q=URL

URN 是另一种形式的 URI，它通过特定命名空间中的唯一名称来标识资源。
urn:isbn:9780141036144
urn:ietf:rfc:7230


http://www.example.com:80/path/to/myfile.html?key1=value1&key2=value2#SomewhereInTheDocument
统一资源标识符的语法 (URI):
方案或协议
主机, www.example.com 既是一个域名，也代表管理该域名的机构。它指示了需要向网络上的哪一台主机发起请求。
端口
路径
查询
片段, #SomewhereInTheDocument 是资源本身的某一部分的一个锚点。锚点代表资源内的一种“书签”，它给予浏览器显示位于该“加书签”点的内容的指示。

------------------------------Data URL
Data URL，即前缀为 data: 协议的 URL，其允许内容创建者向文档中嵌入小文件。它们之前被称作“data URI”，直到这个名字被 WHATWG 弃用。
现代浏览器将 Data URL 视作唯一的不透明来源，而不是可以用于导航的 URL。
Data URL 由四个部分组成：前缀（data:）、指示数据类型的 MIME 类型、如果非文本则为可选的 base64 标记、数据本身：
data:[<mediatype>][;base64],<data>
mediatype 是个 MIME 类型的字符串，例如 'image/jpeg' 表示 JPEG 图像文件。如果被省略，则默认值为 text/plain;charset=US-ASCII。

如果数据包含 RFC 3986 中定义为保留字符的字符或包含空格符、换行符或者其他非打印字符，这些字符必须进行百分号编码（又名“URL 编码”）。
https://datatracker.ietf.org/doc/html/rfc3986#section-2.2
如果数据是文本类型，你可以直接将文本嵌入（根据文档类型，使用合适的实体字符或转义字符）。否则，你可以指定 base64 来嵌入 base64 编码的二进制数据。

data:,Hello%2C%20World!
简单的 text/plain 类型数据。注意逗号如何百分号编码为 %2C，空格字符如何编码为 %20。

data:text/plain;base64,SGVsbG8sIFdvcmxkIQ%3D%3D
上一条示例的 base64 编码版本

data:text/html,%3Ch1%3EHello%2C%20World!%3C%2Fh1%3E
一个 HTML 文档源代码 <h1>Hello, World</h1>

给数据作 base64 编码:
Base64 是一组二进制到文本的编码方案，通过将其转换为 radix-64 表示形式，以 ASCII 字符串格式表示二进制数据。通过仅由 ASCII 字符组成，base64 字符串通常是 url 安全的，这就是为什么它们可用于在 Data URL 中编码数据。

------------------------------MIME 类型
媒体类型（通常称为 Multipurpose Internet Mail Extensions 或 MIME 类型）是一种标准，用来表示文档、文件或字节流的性质和格式
它在IETF RFC 6838中进行了定义和标准化。
https://datatracker.ietf.org/doc/html/rfc6838

互联网号码分配机构（IANA）是负责跟踪所有官方 MIME 类型的官方机构，您可以在媒体类型页面中找到最新的完整列表。
https://www.iana.org/assignments/media-types/media-types.xhtml

通用结构
type/subtype
MIME 类型对大小写不敏感，但是传统写法都是小写。

独立类型:
类型	描述	典型示例
text	表明文件是普通文本，理论上是人类可读	text/plain, text/html, text/css, text/javascript
image	表明是某种图像。不包括视频，但是动态图（比如动态 gif）也使用 image 类型	image/gif, image/png, image/jpeg, image/bmp, image/webp, image/x-icon, image/vnd.microsoft.icon
audio	表明是某种音频文件	audio/midi, audio/mpeg, audio/webm, audio/ogg, audio/wav
video	表明是某种视频文件	video/webm, video/ogg
application	表明是某种二进制数据	application/octet-stream, application/pkcs12, application/vnd.mspowerpoint, application/xhtml+xml, application/xml, application/pdf

Multipart 类型:
multipart/form-data
multipart/byteranges

常见 MIME 类型列表
https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Basics_of_HTTP/MIME_types/Common_types

multipart/form-data
multipart/form-data 可用于HTML 表单从浏览器发送信息给服务器。
作为多部分文档格式，它由边界线（一个由'--'开始的字符串）划分出的不同部分组成。每一部分有自己的实体，以及自己的 HTTP 请求头，Content-Disposition和 Content-Type 用于文件上传领域，最常用的 (Content-Length 因为边界线作为分隔符而被忽略）。

POST / HTTP/1.1
Host: localhost:8000
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:50.0) Gecko/20100101 Firefox/50.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: en-US,en;q=0.5
Accept-Encoding: gzip, deflate
Connection: keep-alive
Upgrade-Insecure-Requests: 1
Content-Type: multipart/form-data; boundary=---------------------------8721656041911415653955004498
Content-Length: 465

-----------------------------8721656041911415653955004498
Content-Disposition: form-data; name="myTextField"

Test
-----------------------------8721656041911415653955004498
Content-Disposition: form-data; name="myCheckBox"

on
-----------------------------8721656041911415653955004498
Content-Disposition: form-data; name="myFile"; filename="test.txt"
Content-Type: text/plain

Simple file.
-----------------------------8721656041911415653955004498--


multipart/byteranges
multipart/byteranges 用于把部分的响应报文发送回浏览器。
当发送状态码206Partial Content 时，这个 MIME 类型用于指出这个文件由若干部分组成，每一个都有其请求范围。就像其他很多类型Content-Type使用分隔符来制定分界线。
每一个不同的部分都有Content-Type这样的 HTTP 头来说明文件的实际类型，以及 Content-Range来说明其范围。

HTTP/1.1 206 Partial Content
Accept-Ranges: bytes
Content-Type: multipart/byteranges; boundary=3d6b6a416f9b5
Content-Length: 385

--3d6b6a416f9b5
Content-Type: text/html
Content-Range: bytes 100-200/1270

eta http-equiv="Content-type" content="text/html; charset=utf-8" />
    <meta name="vieport" content
--3d6b6a416f9b5
Content-Type: text/html
Content-Range: bytes 300-400/1270

-color: #f0f0f2;
        margin: 0;
        padding: 0;
        font-family: "Open Sans", "Helvetica
--3d6b6a416f9b5--

------------------------------
一个服务器不一定是一个独立的物理机：几台服务器可以驻留在同一台物理机器上，或者一台服务器可以通过几台机器进行处理，协作处理并响应或负载均衡它们之间的请求。
关键点在于语义上一个域名代表一个单独的服务器。

规范网址方式:
使用 HTTP 301 重定向
在这种情况下，你需要配置服务器接收的 HTTP 请求（常见为 www 和非 www 网址相同）以及适当的 HTTP 响应 301 去响应所有非规范的域名请求。
这会将尝试使访问非规范网址的浏览器重定向到其规范的等效网址。举例来说，如果您选择使用非 www 网址为规范类型，你的所有 www 网址都应该被重定向到对应的非 www 网址上。
服务器收到 http://www.example.org/whaddup 请求（当规范域名是 example.org 时）
服务器则以代码 301 与头 Location ：http://example.org/whaddup
该客户端发出的规范的域名请求：http://example.org/whaddup

==================================================HTTP 指南
HTTP/3——基于 QUIC 的 HTTP,传输层部分使用 QUIC (en-US) 而不是 TCP
https://developer.mozilla.org/en-US/docs/Glossary/QUIC
类似于 HTTP/2，它是一个多路复用协议，但是 HTTP/2 通过单个 TCP 连接运行，所以在 TCP 层处理的数据包丢失检测和重传可以阻止所有流。
QUIC 通过 UDP 运行多个流，并为每个流独立实现数据包丢失检测和重传，因此如果发生错误，只有该数据包中包含数据的流才会被阻止。

------------------------------HTTP 消息
HTTP 消息是服务器和客户端之间交换数据的方式。有两种类型的消息：请求（request）——由客户端发送用来触发一个服务器上的动作；响应（response）——来自服务器的应答。

HTTP 请求和响应具有相似的结构，由以下部分组成:
一行起始行用于描述要执行的请求，或者是对应的状态，成功或失败。这个起始行总是单行的。
一个可选的 HTTP 标头集合指明请求或描述消息主体（body）。
一个空行指示所有关于请求的元数据已经发送完毕。
一个可选的包含请求相关数据的主体（比如 HTML 表单内容），或者响应相关的文档。主体的大小有起始行的 HTTP 头来指定。

起始行和 HTTP 消息中的 HTTP 头统称为请求头，而其有效负载被称为消息主体。

HTTP 请求:
起始行
HTTP 请求是由客户端发出的消息，用来使服务器执行动作。起始行（start-line）包含三个元素:
HTTP 方法
请求目标（request target），通常是一个 URL，或者是协议、端口和域名的绝对路径，通常以请求的环境为特征。
HTTP 版本（HTTP version）

标头（Header）
不区分大小写的字符串，紧跟着的冒号（':'）和一个结构取决于标头的值。整个标头（包括值）由一行组成，这一行可以相当长。
有许多请求标头可用，它们可以分为几组:
通用标头（General header），例如 Via，适用于整个消息。
请求标头（Request header），例如 User-Agent、Accept-Type，通过进一步的定义（例如 Accept-Language）、给定上下文（例如 Referer）或者进行有条件的限制（例如 If-None）来修改请求。
表示标头（Representation header），例如 Content-Type 描述了消息数据的原始格式和应用的任意编码（仅在消息有主体时才存在）。

主体（Body）
请求的最后一部分是它的主体。不是所有的请求都有一个主体：例如获取资源的请求，像 GET、HEAD、DELETE 和 OPTIONS，通常它们不需要主体。
有些请求将数据发送到服务器以便更新数据：常见的的情况是 POST 请求（包含 HTML 表单数据）。
主体大致可分为两类:
单一资源（Single-resource）主体，由一个单文件组成。该类型的主体由两个标头定义：Content-Type 和 Content-Length。
多资源（Multiple-resource）主体，由多部分主体组成，每一部分包含不同的信息位。通常是和 HTML 表单连系在一起。

HTTP 响应:
状态行
HTTP 响应的起始行被称作状态行（status line），包含以下信息：
协议版本，通常为 HTTP/1.1。
状态码（status code），表明请求是成功或失败。常见的状态码是 200、404 或 302。
状态文本（status text）。一个简短的，纯粹的信息，通过状态码的文本描述，帮助人们理解该 HTTP 消息。

标头（Header）
许多不同的标头可能会出现在响应中。这些可以分为几组:
通用标头（General header），例如 Via，适用于整个消息。
响应标头（Response header），例如 Vary 和 Accept-Ranges，提供有关服务器的其他信息，这些信息不适合状态行。
表示标头（Representation header），例如 Content-Type 描述了消息数据的原始格式和应用的任意编码（仅在消息有主体时才存在）。

主体（Body）
响应的最后一部分是主体。不是所有的响应都有主体：具有状态码（如 201 或 204）的响应，通常不会有主体。
主体大致可分为三类:
单资源（Single-resource）主体，由已知长度的单个文件组成。该类型主体由两个标头定义：Content-Type 和 Content-Length。
单资源（Single-resource）主体，由未知长度的单个文件组成。通过将 Transfer-Encoding 设置为 chunked 来使用分块编码。
多资源（Multiple-resource）主体，由多部分 body 组成，每部分包含不同的信息段。但这是比较少见的。


HTTP/2:
HTTP/1.x 消息有一些性能上的缺点:
与主体不同，标头不会被压缩。
两个消息之间的标头通常非常相似，但它们仍然在连接中重复传输。
无法多路复用。当在同一个服务器打开几个连接时：TCP 热连接比冷连接更加有效。
HTTP/2 引入了一个额外的步骤：它将 HTTP/1.x 消息分成帧并嵌入到流（stream）中。数据帧和报头帧分离，这将允许报头压缩。将多个流组合，这是一个被称为多路复用（multiplexing）的过程，它允许更有效的底层 TCP 连接。

------------------------------HTTP 会话
在像 HTTP 这样的客户端——服务器（Client-Server）协议中，会话分为三个阶段:
客户端建立一条 TCP 连接（如果传输层不是 TCP，也可以是其他适合的连接）。
客户端发送请求并等待应答。
服务器处理请求并送回应答，回应包括一个状态码和对应的数据。

从 HTTP/1.1 开始，连接在完成第三阶段后不再关闭，客户端可以再次发起新的请求。这意味着第二步和第三步可以连续进行数次。

建立连接
在客户端——服务器协议中，连接是由客户端发起建立的。在 HTTP 中打开连接意味着在底层传输层启动连接，通常是 TCP。
使用 TCP 时，HTTP 服务器的默认端口号是 80，另外还有 8000 和 8080 也很常用。
使用 XMLHTTPRequest 或 Fetch API 周期性地请求服务器，使用 HTML WebSocket API，或其他类似协议。

发送客户端请求
一旦连接建立，用户代理就可以发送请求（用户代理通常是 Web 浏览器，但也可以是其他的，例如爬虫）。客户端请求由一系列文本指令组成，并使用 CRLF 分隔（回车，然后是换行），它们被划分为三个块：
第一行包括请求方法及请求参数：
文档路径，不包括协议和域名的绝对路径 URL
使用的 HTTP 协议版本
接下来的行每一行都表示一个 HTTP 标头，为服务器提供关于所需数据的信息（例如语言，或 MIME 类型），或是一些改变请求行为的数据（例如当数据已经被缓存，就不再应答）。这些 HTTP 标头形成一个以空行结尾的块。
最后一块是可选数据块，包含更多数据，主要被 POST 方法所使用。
注意最后的空行，它把标头与数据块分隔开。由于在 HTTP 标头中没有 Content-Length，数据块是空的，所以服务器可以在收到代表标头结束的空行后就开始处理请求。
GET 方法请求指定的资源。GET 请求应该只被用于获取数据。
POST 方法向服务器发送数据，因此会改变服务器状态。这个方法常在 HTML 表单中使用。

服务器响应结构
当收到用户代理发送的请求后，Web 服务器就会处理它，并最终送回一个响应。与客户端请求很类似，服务器响应由一系列文本指令组成，并使用 CRLF 分隔，它们被划分为三个不同的块：
第一行是状态行，包括使用的 HTTP 协议版本，然后是一个状态码（及其人类可读的描述文本）。
接下来每一行都表示一个 HTTP 标头，为客户端提供关于所发送数据的一些信息（如类型、数据大小、使用的压缩算法、缓存指示）。与客户端请求的头部块类似，这些 HTTP 标头组成一个块，并以一个空行结束。
最后一块是数据块，包含了响应的数据（如果有的话）。

响应状态码
HTTP 响应状态码用来表示一个 HTTP 请求是否成功完成。响应被分为 5 种类型：信息型响应，成功响应，重定向，客户端错误和服务端错误。

请求资源已被永久移动的网页响应:
HTTP/1.1 301 Moved Permanently
Server: Apache/2.4.37 (Red Hat)
Content-Type: text/html; charset=utf-8
Date: Thu, 06 Dec 2018 17:33:08 GMT
Location: https://developer.mozilla.org/ （目标资源的新地址，服务器期望用户代理去访问它）
Keep-Alive: timeout=15, max=98
Accept-Ranges: bytes
Via: Moz-Cache-zlb05
Connection: Keep-Alive
Content-Length: 325 (如果用户代理无法转到新地址，就显示一个默认页面)

<!DOCTYPE html>… (包含一个网站自定义页面，帮助用户找到丢失的资源)

------------------------------HTTP/1.x 的连接管理
打开和保持连接在很大程度上影响着网站和 Web 应用程序的性能。在 HTTP/1.x 里有多种模型：短连接、长连接和 HTTP 流水线。
在早期，HTTP 使用一个简单的模型来处理这样的连接。这些连接的生命周期是短暂的：每发起一个请求时都会创建一个新的连接，并在收到应答时立即关闭。
打开每一个 TCP 连接都是相当耗费资源的操作。客户端和服务器端之间需要交换好些个消息。当请求发起时，网络延迟和带宽都会对性能造成影响。
有两个新的模型在 HTTP/1.1 诞生了。首先是长连接模型，它会保持连接去完成多次连续的请求，减少了不断重新打开连接的时间。然后是 HTTP 流水线模型，它还要更先进一些，多个连续的请求甚至都不用等待立即返回就可以被发送，这样就减少了耗费在网络延迟上的时间。

HTTP/2 新增了其他连接管理模型

端到端（End-to-end）标头
这类标头必须被传输到最终的消息接收者：请求的服务器或者响应的客户端。中间的代理必须重新转发这些未经修改的标头，并且必须缓存它们。
逐跳（Hop-by-hop）标头
这类标头仅对单次传输连接有意义，并且不得由代理重传或者缓存。注意，只能使用 Connection 标头来设置逐跳标头。

要注意的一个重点是 HTTP 的连接管理适用于两个连续节点之间的连接，它是逐跳（Hop-by-hop）标头，而不是端到端（End-to-end）标头。
HTTP 协议头受不同连接模型的影响，比如 Connection 和 Keep-Alive，就是逐跳标头标头，它们的值是可以被中间节点修改的。

短连接:
HTTP 最早期的模型和 HTTP/1.0 的默认模型，是短连接。每一个 HTTP 请求都由它自己独立的连接完成；这意味着发起每一个 HTTP 请求之前都会有一次 TCP 握手，而且是连续不断的。
TCP 协议握手本身就是耗费时间的，所以 TCP 可以保持更多的热连接来适应负载。短连接破坏了 TCP 具备的能力，并且新的冷连接降低了其性能。
这是 HTTP/1.0 的默认模型（如果没有指定 Connection 协议头，或者是值被设置为 close）。而在 HTTP/1.1 中，只有当 Connection 被设置为 close 时才会用到这个模型。
除非是要兼容一个非常古老的，不支持长连接的系统，没有一个令人信服的理由继续使用这个模型。

长连接:
短连接有两个比较大的问题：创建新连接耗费的时间尤为明显，另外 TCP 连接的性能只有在该连接被使用一段时间后（热连接）才能得到改善。为了缓解这些问题，长连接的概念便被设计出来了，甚至在 HTTP/1.1 之前。或者，这被称之为一个 keep-alive 连接。
一个长连接会保持一段时间，重复用于发送一系列请求，节省了新建 TCP 连接握手的时间，还可以利用 TCP 的性能增强能力。当然这个连接也不会一直保留着：连接在空闲一段时间后会被关闭（服务器可以使用 Keep-Alive 协议头来指定一个最小的连接保持时间）。
长连接也还是有缺点的；就算是在空闲状态，它还是会消耗服务器资源，而且在重负载时，还有可能遭受 DoS 攻击。这种场景下，可以使用非长连接，即尽快关闭那些空闲的连接，也能对性能有所提升。
HTTP/1.0 里默认并不使用长连接。把 Connection 设置成 close 以外的其他参数都可以让其保持长连接，通常会设置为 retry-after。
在 HTTP/1.1 里，默认就是长连接的，不再需要标头（但我们还是会把它加上，万一某个时候因为某种原因要退回到 HTTP/1.0 呢）。

HTTP 流水线:
HTTP 流水线在现代浏览器中并不是默认被启用的
有缺陷的代理服务器仍然很常见，这些会导致 Web 开发人员无法预见和轻松诊断的奇怪和不稳定行为。
正确的实现流水线是复杂的：传输中的资源大小、多少有效的 RTT 会被用到以及有效带宽都会直接影响到流水线提供的改善。不知道这些的话，重要的消息可能被延迟到不重要的消息后面。这个重要性的概念甚至会演变为影响到页面布局！因此 HTTP 流水线在大多数情况下带来的改善并不明显。
流水线受制于队头阻塞（HOL）问题。
由于这些原因，流水线已被 HTTP/2 中更好的算法——多路复用（multiplexing）所取代
默认情况下，HTTP 请求是按顺序发出的。下一个请求只有在当前请求收到响应过后才会被发出。由于会受到网络延迟和带宽的限制，在下一个请求被发送到服务器之前，可能需要等待很长时间。
流水线是在同一条长连接上发出连续的请求，而不用等待应答返回。这样可以避免连接延迟。理论上讲，性能还会因为两个 HTTP 请求有可能被打包到一个 TCP 消息包中而得到提升。就算 HTTP 请求不断的继续，尺寸会增加，但设置 TCP 的最大分段大小（MSS）选项，仍然足够包含一系列简单的请求。
并不是所有类型的 HTTP 请求都能用到流水线：只有幂等方式，比如 GET、HEAD、PUT 和 DELETE 能够被安全地重试。如果有故障发生时，流水线的内容要能被轻易的重试。
所有遵循 HTTP/1.1 标准的代理和服务器都应该支持流水线，虽然实际情况中还是有很多限制：一个很重要的原因是，目前没有现代浏览器默认启用这个特性。

域名分片:
不要使用这一过时的技术；而是升级到 HTTP/2。
在 HTTP/2 里，做域名分片就没必要了：HTTP/2 的连接可以很好的处理并发的无优先级的请求。

作为 HTTP/1.x 的连接，请求是序列化的，哪怕本来是无序的，在没有足够庞大可用的带宽时，也无从优化。
一个解决方案是，浏览器为每个域名建立多个连接，以实现并发请求。曾经默认的连接数量为 2 到 3 个，现在比较常用的并发连接数已经增加到 6 条。如果尝试大于这个数字，就有触发服务器 DoS 保护的风险。
如果服务器端想要更快速的响应网站或应用程序的应答，它可以迫使客户端建立更多的连接。例如，不要在同一个域名下获取所有资源，假设有个域名是 www.example.com，我们可以把它拆分成好几个域名：www1.example.com、www2.example.com、www3.example.com。
所有这些域名都指向同一台服务器，浏览器会同时为每个域名建立 6 条连接（在我们这个例子中，连接数会达到 18 条）。这一技术被称作域名分片。

HTTP/2 的多路复用:
多路复用代替原来的序列和阻塞机制，所有就是请求的都是通过一个 TCP 连接并发完成。同时也很好的解决了浏览器限制同一个域名下的请求数量的问题。
在 HTTP/2 中，有了二进制分帧之后，HTTP/2 不再依赖 TCP 链接去实现多流并行了，在 HTTP/2 中:
同域名下所有通信都在单个连接上完成，同个域名只需要占用一个 TCP 连接，使用一个连接并行发送多个请求和响应。
单个连接可以承载任意数量的双向数据流，单个连接上可以并行交错的请求和响应，之间互不干扰。
数据流以消息的形式发送，而消息又由一个或多个帧组成，多个帧之间可以乱序发送，因为根据帧首部的流标识可以重新组装。每个请求都可以带一个 31bit 的优先值，0 表示最高优先级， 数值越大优先级越低。

帧（frame）和流（stream）
HTTP/2 中数据传输的最小单位，因此帧不仅要细分表达 HTTP/1.x 中的各个部份，也优化了 HTTP/1.x 表达得不好的地方，同时还增加了 HTTP/1.x 表达不了的方式。
每一帧都包含几个字段，有length、type、flags、stream identifier、frame playload等，其中type 代表帧的类型，在 HTTP/2 的标准中定义了 10 种不同的类型，包括上面所说的 HEADERS frame 和 DATA frame。
此外还有： PRIORITY（设置流的优先级） RST_STREAM（终止流） SETTINGS（设置此连接的参数） PUSH_PROMISE（服务器推送） PING（测量 RTT） GOAWAY（终止连接） WINDOW_UPDATE（流量控制） CONTINUATION（继续传输头部数据）
在 HTTP 2.0 中，它把数据报的两大部分分成了 header frame 和 data frame。也就是头部帧和数据体帧。
流（stream）
流： 存在于连接中的一个虚拟通道。流可以承载双向消息，每个流都有一个唯一的整数 ID。 
HTTP/2 长连接中的数据包是不按请求-响应顺序发送的，一个完整的请求或响应(称一个数据流 stream，每个数据流都有一个独一无二的编号)可能会分成非连续多次发送。它具有如下几个特点:
双向性：同一个流内，可同时发送和接受数据。
有序性：流中被传输的数据就是二进制帧 。帧在流上的被发送与被接收都是按照顺序进行的。
并行性：流中的 二进制帧 都是被并行传输的，无需按顺序等待。
流的创建：流可以被客户端或服务器单方面建立, 使用或共享。
流的关闭：流也可以被任意一方关闭。
HEADERS 帧在 DATA 帧前面。
流的 ID 都是奇数，说明是由客户端发起的，这是标准规定的，那么服务端发起的就是偶数了。

从 Http/0.9 到 Http/2 要发送多个请求，从多个 Tcp 连接=>keep-alive=>管道化=>多路复用不断的减少多次创建 Tcp 等等带来的性能损耗。
在最早的时候没有keep-alive只能创建多个Tcp连接来做多次请求。
一次请求完成就会关闭本次的 Tcp 连接，下个请求又要从新建立 Tcp 连接传输完成数据再关闭，造成很大的性能损耗。
Keep-Alive解决的核心问题是： 一定时间内，同一域名多次请求数据，只建立一次 HTTP 请求，其他请求可复用每一次建立的连接通道，以达到提高请求效率的问题。
这里面所说的一定时间是可以配置的，不管你用的是Apache还是nginx。 以往，浏览器判断响应数据是否接收完毕，是看连接是否关闭。
在使用持久连接后，就不能这样了，这就要求服务器对持久连接的响应头部一定要返回content-length标识body的长度，供浏览器判断界限。
有时，content-length的方法并不是太准确，也可以使用 Transfer-Encoding: chunked 头部发送一串一串的数据，最后由长度为 0 的chunked标识结束。
设置 Connection:Keep-Alive，保持连接在一段时间内不断开。
Keep-Alive还是存在如下问题:
串行的文件传输。
同域并行请求限制带来的阻塞（6~8）个
管线化
HTTP 管线化可以克服同域并行请求限制带来的阻塞，它是建立在持久连接之上，是把所有请求一并发给服务器，但是服务器需要按照顺序一个一个响应，而不是等到一个响应回来才能发下一个请求，这样就节省了很多请求到服务器的时间。不过，HTTP 管线化仍旧有阻塞的问题，若上一响应迟迟不回，后面的响应都会被阻塞到。
多路复用
多路复用代替原来的序列和阻塞机制。
所有就是请求的都是通过一个 TCP 连接并发完成。因为在多路复用之前所有的传输是基于基础文本的，在多路复用中是基于二进制数据帧的传输、消息、流，所以可以做到乱序的传输。
多路复用对同一域名下所有请求都是基于流，所以不存在同域并行的阻塞。
HTTP2 采用二进制数据帧传输，取代了 HTTP1.x 的文本格式，二进制格式解析更高效。
多路复用代替了 HTTP1.x 的序列和阻塞机制，所有的相同域名请求都通过同一个 TCP 连接并发完成。同一 Tcp 中可以发送多个请求，对端可以通过帧中的标识知道属于哪个请求。通过这个技术，可以避免 HTTP 旧版本中的队头阻塞问题，极大的提高传输性能。

HTTP/1 下的请求，并不能很好地地利用带宽：一个 TCP 连接同时只能有一个 HTTP 请求和响应。如果正在发送一个 HTTP 请求，那其他的 HTTP 请求就得排队。
这种排队会产生一个请求队列，当队头的请求发生意外（比如丢包、服务器响应缓慢），导致比平时要慢得多，就会导致后面的请求被延迟。这种情况我们称为 队头阻塞（Head-of-line blocking）。
为了缓解这个问题，浏览器会对同一个域名建立多个 TCP 连接，来实现 HTTP 的并发。
但这也对服务器造成不小的负担，所以浏览器做了限制，同一个域名下 TCP 连接数最多会在 6 ~ 8 个左右。
如果网页一次性加载的资源太多，比如大量图片，6 个 TCP 连接数可能也会顶不住。为了解决一个问题，我们会使用 域名分片（Domain sharding） 的方法，就是将资源放到不同的域名下。
比如将图片放到专门的 static.xxx.com ，或者 CDN。因为域名不同，所以总的 TCP 连接数就能突破 6 的限制。达到 域名数 x 6。
HTTP/1.1 有一个 pipeline 机制，意图解决不能并发的问题，但因为实现上的缺陷，实质上已经废弃。浏览器也默认关闭 pipeline。

为了解决这个问题，HTTP/2 使用了 多路复用。
HTTP/2 引入了流（stream）和帧（frame）的概念。
帧是最小的数据单位，HTTP 报文不再是原来的明文的 ASCII 编码，而是会被拆分成一个个的二进制形式的帧。帧上面除了 HTTP 数据，还包含数据长度、流标识符、帧类型等信息。
流是一个建立连接后的双向的虚拟字节流，可以承载多个消息。帧通过自己的流 ID，确定自己属于哪个报文，就可以不按顺序进行请求响应了。
HTTP/2 会将所有 HTTP 请求打散成帧，在一个 TCP 连接上做并发请求，充分利用 TCP 带宽。现在浏览器对于 HTTP2，只会建立一个 TCP 连接，减轻了服务端不小压力。

https://blog.csdn.net/fe_watermelon/article/details/126433842?spm=1001.2101.3001.6650.16&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-16-126433842-blog-118325824.235%5Ev38%5Epc_relevant_anti_t3_base&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-16-126433842-blog-118325824.235%5Ev38%5Epc_relevant_anti_t3_base&utm_relevant_index=21
例子:
假设依次请求一个很大的 JS 文件，和一个很小的 CSS 文件。
在 HTTP/1 时，TCP 的发送的包是这样的（JS 用多个 1 表示，CSS 用多个 2 表示）:
111111111111111111111111222
JS 很大，会让 CSS 延迟，我们可能希望比较小的 CSS 能早一点请求完，早一点做解析。而且 JS 一旦发生了意外发生阻塞，CSS 就更晚才能获取到了。
现在我们用 HTTP/2，就变成了下面这样:
121212111111111111111111111
因为并行的原因，CSS 不仅不用再担心 JS 导致的阻塞，还能更早请求并获取到资源。
###
本质上还是序列化的传输，举个例子。比如饭店上菜，http1就是上完第一桌客人的再上第二桌客人的。http2就变成根据炒出来的菜的编号属于哪个桌就上哪个桌
###
HTTP/2 的多路复用能够解决 HTTP 队头阻塞(head-of-line blocking (HOL Blocking))问题，更充分地利用 TCP 带宽。
但因为还是在 TCP 上的协议，所以不能解决 TCP 队头阻塞问题，这个问题要交给 HTTP/3 通过 UDP 来解决了

------------------------------协议升级机制
HTTP 连接升级的概念，其中 HTTP/1.1 连接升级为一个不同的协议，比如 TLS/1.0、Websocket、甚至明文形式的 HTTP/2

HTTP/1.1 协议提供了一种使用 Upgrade (en-US) 标头字段的特殊机制，这一机制允许将一个已建立的连接升级成新的、不相容的协议。
这个机制是可选的；它并不能强制协议的更改（通常来说这一机制总是由客户端发起的）。如果它们支持新协议，实现甚至可以不利用 upgrade，在实践中，这种机制主要用于引导 WebSocket 连接。
HTTP/2 明确禁止使用此机制；这个机制只属于 HTTP/1.1。

升级 HTTP/1.1 连接
客户端使用 Upgrade (en-US) 标头字段请求服务器，以降序优先的顺序切换到其中列出的一个协议。
因为 Upgrade 是一个逐跳（Hop-by-hop）标头，它还需要在 Connection 标头字段中列出。这意味着包含 Upgrade 的典型请求类似于
GET /index.html HTTP/1.1
Host: www.example.com
Connection: upgrade
Upgrade: example/1, foo/2
如果服务器决定升级这次连接，就会返回一个 101 Switching Protocols 响应状态码，和一个要切换到的协议的标头字段 Upgrade。如果服务器没有（或者不能）升级这次连接，它会忽略客户端发送的 Upgrade 标头字段，返回一个常规的响应：例如一个 200 OK).
在发送 101 状态码之后，服务器可以使用新协议，并根据需要执行任何额外的特定于协议的握手。实际上，一旦这次升级完成了，连接就变成了双向管道。并且可以通过新协议完成启动升级的请求。

升级到 websocket 协议的连接:
经常会需要升级一个 HTTP 连接的场合就是使用 WebSocket，它总是通过升级 HTTP 或 HTTPS 连接来实现。
当你用 WebSocket API 以及其他大部分实现 WebSocket 的库去建立新的连接时，基本上都不用操心升级的过程，因为这些 API 已经实现了这一步。
webSocket = new WebSocket("ws://destination.server.ext", "optionalProtocol");
WebSocket() 构造函数已经自动完成了发送初始 HTTP/1.1 连接的所有工作，然后为你处理握手及升级过程。
如果想要自己重头实现 WebSocket 连接，就必须要处理握手和升级过程。
在创建初始 HTTP/1.1 会话之后，你需要发送另一个 HTTP 标准请求来请求升级，但在标头中要带上 Upgrade (en-US) 和 Connection，也就是:
Connection: Upgrade
Upgrade: websocket

WebSocket 专有的标头:
除了 Upgrade (en-US) 和 Connection 标头，其余的通常是可选的，或者由浏览器和服务器都会在交互过程中处理好。
Sec-WebSocket-Extensions
用于指定一个或多个请求服务器使用的协议级 WebSocket 扩展。允许在一个请求中使用多个 Sec-WebSocket-Extension 标头；结果跟在一个标头文件中包含了所有列出的扩展一样。
Sec-WebSocket-Extensions: extensions
extensions
指需要（或支持）的扩展的逗号分隔列表。这些值来自 IANA WebSocket 扩展名注册表。带参数的扩展使用分号表示。
https://www.iana.org/assignments/websocket/websocket.xml#extension-name
Sec-WebSocket-Extensions: superspeed, colormode; depth=16

Sec-WebSocket-Key
该标头向服务器提供确认客户端有权请求升级到 WebSocket 的所需信息。
当不安全（HTTP）客户端希望升级时，可以使用该标头，以提供一定程度防止滥用的保护。密钥的值是使用 WebSocket 规范中定义的算法计算的，因此不提供安全性。相反，它有助于防止非 WebSocket 客户端无意中或滥用请求 WebSocket 连接。那么，从本质上讲，这个密钥是为了确认“是的，我真的是要打开一个 WebSocket 连接。”
该标头由选择使用它的客户端自动添加；它不能使用 XMLHttpRequest.setRequestHeader() 方法添加。
Sec-WebSocket-Key: key
key
此请求升级的密钥。如果客户端愿意，则添加它，服务器将在响应中包含一个自己的密钥，客户端将在向你发送升级响应之前验证该密钥。
服务器响应的 Sec-WebSocket-Accept 标头将基于指定的 key 计算的值。

Sec-WebSocket-Protocol
Sec-WebSocket-Protocol 标头按优先顺序指定你希望用的一个或者多个 WebSocket 协议。
将服务器支持的第一个 WebSocket 协议，由服务器在响应中包含的 Sec-WebSocket-Protocol 标头中选择并返回它。你可以在标头中多次使用它；结果与在单个标头中使用逗号分隔的子协议标识符列表相同。
Sec-WebSocket-Protocol: subprotocols
subprotocols
以逗号分隔的子协议名称列表，按优先顺序排列。子协议可以从 IANA WebSocket 子协议名称注册表中选择，也可以是客户端和服务器共同理解的自定义名称。
https://www.iana.org/assignments/websocket/websocket.xml#subprotocol-name

Sec-WebSocket-Version
请求标头:
指定客户端希望使用的 WebSocket 协议版本，以便服务器可以确认其是否支持该版本。
Sec-WebSocket-Version: version
version
客户端在与服务器通信时希望使用的 WebSocket 协议版本。此编号应该是 IANA WebSocket 版本号注册表可能列出的最新版本。WebSocket 协议的最新最终版本是版本 13。
https://www.iana.org/assignments/websocket/websocket.xml#version-number
响应标头:
如果服务器无法使用指定版本的 Websocket 协议进行通信，它将响应一个错误（例如 426 Upgrade Required），该错误在它的标头中包含一个 Sec-WebSocket-Version 标头，其中包含支持的逗号分隔列表的协议版本。如果服务器确实支持请求的协议版本，则响应中不包含 Sec-WebSocket-Version 标头。
Sec-WebSocket-Version: supportedVersions
supportedVersions
服务器支持的 WebSocket 协议版本的逗号分隔列表。

仅响应标头:
Sec-WebSocket-Accept
当服务器愿意发起 WebSocket 连接时，其包含在打开握手过程中来自服务器的响应消息中。它只会在响应标头中出现一次。
Sec-WebSocket-Accept: hash
hash
如果提供了 Sec-WebSocket-Key 标头，那么将通过以下流程计算此标头的值：首先取密钥的值，然后将该值与“258EAFA5-E914-47DA-95CA-C5AB0DC85B11”进行拼接，再取拼接后的字符串的 SHA-1 哈希。最后对得出的 20 字节的值进行 base64 编码以获得该属性的值。



WebSocket 是一个双向通信协议，它在握手阶段采用 HTTP/1.1 协议（暂时不支持 HTTP/2）。
握手过程:
首先客户端向服务端发起一个特殊的 HTTP 请求，其消息头
GET /chat HTTP/1.1  // 请求行
Host: server.example.com
Upgrade: websocket  // required
Connection: Upgrade // required
Sec-WebSocket-Key: dGhlIHNhbXBsZSBub25jZQ== // required
Origin: http://example.com  // 用于防止未认证的跨域脚本使用浏览器 websocket api 与服务端进行通信
Sec-WebSocket-Protocol: chat, superchat  // optional, 子协议协商字段
Sec-WebSocket-Version: 13

如果服务端支持该版本的 WebSocket，会返回 101 响应，响应标头
HTTP/1.1 101 Switching Protocols  // 状态行
Upgrade: websocket   // required
Connection: Upgrade  // required
Sec-WebSocket-Accept: s3pPLMBiTxaQ9kYGzzhZRbK+xOo= // required，加密后的 Sec-WebSocket-Key
Sec-WebSocket-Protocol: chat // 表明选择的子协议

握手完成后，接下来的 TCP 数据包就都是 WebSocket 协议的帧了
这里的握手不是 TCP 的握手，而是在 TCP 连接内部，从 HTTP/1.1 upgrade 到 WebSocket 的握手。
WebSocket 提供两种协议：不加密的 ws:// 和 加密的 wss://. 因为是用 HTTP 握手，它和 HTTP 使用同样的端口：ws 是 80（HTTP），wss 是 443（HTTPS）
// WebSocket API
var socket = new WebSocket('ws://websocket.example.com');
 
// Show a connected message when the WebSocket is opened.
socket.onopen = function(event) {
  console.log('WebSocket is connected.');
};
 
// Handle messages sent by the server.
socket.onmessage = function(event) {
  var message = event.data;
  console.log(message);
};
 
// Handle any error that occurs.
socket.onerror = function(error) {
  console.log('WebSocket Error: ' + error);
};


SSE（Server-Send Events）是基于 HTTP协议中的持久连接
是一种服务端向客户端推送信息的单向通信方法

HTTP/2 虽然也支持 Server Push，但是服务器只能主动将资源推送到客户端缓存！并不允许将数据推送到客户端里跑的 Web App 本身。
服务器推送只能由浏览器处理，不会在应用程序代码中弹出服务器数据，这意味着应用程序没有 API 来获取这些事件的通知。
为了接近实时地将数据推送给 Web App， HTTP/2 可以结合 SSE（Server-Sent Event）使用。这是一种新提出的 API，用于从服务端单向将数据推送给 Web App.

// create SSE connection
var source = new EventSource('/dates');
 
// 连接建立时，这些 API 和 WebSocket 的很相似
source.onopen = function(event) {
  // handle open event
};
 
// 收到消息时（它只捕获未命名 event）
source.onmessage = function(event) {
  var data = event.data;  // 发送过来的实际数据（string）
  var origin = event.origin;  // 服务器端URL的域名部分，即协议、域名和端口。
  var lastEventId = event.lastEventId;  // 数据的编号，由服务器端发送。如果没有编号，这个属性为空。
  // handle message
};
 
source.onerror = function(event) {
  // handle error event
};

==================================================HTTP 安全
1.内容安全策略（CSP）
内容安全策略（CSP）是一个额外的安全层，用于检测并削弱某些特定类型的攻击，包括跨站脚本（XSS）和数据注入攻击等。
配置内容安全策略涉及到添加 Content-Security-Policy HTTP 标头到一个页面，并配置相应的值，以控制用户代理（浏览器等）可以为该页面获取哪些资源。
比如一个可以上传文件和显示图片页面，应该允许图片来自任何地方，但限制表单的 action 属性只可以赋值为指定的端点。一个经过恰当设计的内容安全策略应该可以有效的保护页面免受跨站脚本攻击。
策略由一系列策略指令所组成，每个策略指令都描述了针对某个特定资源的类型以及策略生效的范围。
你的策略应当包含一个 default-src 策略指令，在其他资源类型没有符合自己的策略时应用该策略（有关完整列表，请查看 default-src 指令的描述）。
一个策略可以包含 default-src 或者 script-src (en-US) 指令来防止内联脚本运行，并杜绝 eval() 的使用。
一个策略也可包含一个 default-src 或 style-src (en-US) 指令去限制来自一个 <style> 元素或者 style 属性的內联样式。

一个网站管理者想要所有内容均来自站点的同一个源
Content-Security-Policy: default-src 'self'

一个网站管理者允许网页应用的用户在他们自己的内容中包含来自任何源的图片，但是限制音频或视频需从信任的资源提供者，所有脚本必须从特定主机服务器获取可信的代码。
Content-Security-Policy: default-src 'self'; img-src *; media-src media1.com media2.com; script-src userscripts.example.com
各种内容默认仅允许从文档所在的源获取，但存在如下例外:
图片可以从任何地方加载 (注意“*”通配符)。
多媒体文件仅允许从 media1.com 和 media2.com 加载（不允许从这些站点的子域名）。
可运行脚本仅允许来自于 userscripts.example.com。

2.HTTP Strict-Transport-Security（通常简称为 HSTS）响应标头用来通知浏览器应该只通过 HTTPS 访问该站点，并且以后使用 HTTP 访问该站点的所有尝试都应自动重定向到 HTTPS。
Strict-Transport-Security: max-age=<expire-time>; includeSubDomains; preload
max-age=<expire-time>
浏览器应该记住的，只能使用 HTTPS 访问站点的最大时间量（以秒为单位）。
includeSubDomains 可选
如果这个可选的参数被指定，那么说明此规则也适用于该网站的所有子域名。
preload 可选 非标准
查看预加载 HSTS 获得详情。当使用 preload，max-age 指令必须至少是 31536000（一年），并且必须存在 includeSubDomains 指令。这不是标准的一部分。

示例场景:
你登录到一个免费 Wi-Fi 热点，然后开始浏览网站，访问你的网上银行，查看你的支出，并且支付一些订单。很不幸，你接入的 Wi-Fi 实际上是黑客的笔记本热点，他们拦截了你原始的 HTTP 请求，然后重定向到一个与你银行网站一模一样的钓鱼网站。现在，你的隐私数据暴露给黑客了。
Strict Transport Security 解决了这个问题；只要你通过 HTTPS 请求访问银行网站，并且银行网站配置好 Strict Transport Security，你的浏览器知道自动使用 HTTPS 请求，这可以阻止黑客的中间人攻击的把戏。

浏览器如何处理:
你的网站第一次通过 HTTPS 请求，服务器响应 Strict-Transport-Security 标头，浏览器记录下这些信息，然后后面尝试访问这个网站的请求都会自动把 HTTP 替换为 HTTPS。
当 Strict-Transport-Security 标头设置的过期时间到了，后面通过 HTTP 的访问恢复到正常模式，不会再自动重定向到 HTTPS。
每次浏览器接收到 Strict-Transport-Security 标头，它都会更新这个网站的过期时间，所以网站可以刷新这些信息，防止过期发生。如果有禁用 Strict-Transport-Security 的需求，将 max-age 设置为 0（通过 https 连接）将立即使 Strict-Transport-Security 标头失效，从而可以通过 http 访问。

现在和未来的所有子域名会自动使用 HTTPS，有效期（max-age）为一年。同时阻止了只能通过 HTTP 访问页面或者子域的内容。
Strict-Transport-Security: max-age=31536000; includeSubDomains

3.HTTP Cookie

4.X-Content-Type-Options
X-Content-Type-Options HTTP 消息头相当于一个提示标志，被服务器用来提示客户端一定要遵循在 Content-Type 首部中对 MIME 类型 的设定，而不能对其进行修改。
这就禁用了客户端的 MIME 类型嗅探行为，换句话说，也就是意味着网站管理员确定自己的设置没有问题。
nosniff 只应用于 "script" 和 "style" 两种类型。事实证明，将其应用于图片类型的文件会导致与现有的站点冲突
X-Content-Type-Options: nosniff
nosniff
下面两种情况的请求将被阻止:
请求类型是"style" 但是 MIME 类型不是 "text/css"，
请求类型是"script" 但是 MIME 类型不是 JavaScript MIME 类型。

5.X-Frame-Options
X-Frame-Options HTTP 响应头是用来给浏览器指示允许一个页面可否在 <frame>、<iframe>、<embed> 或者 <object> 中展现的标记。站点可以通过确保网站没有被嵌入到别人的站点里面，从而避免点击劫持 (en-US)攻击。
X-Frame-Options 有两个可能的值:
X-Frame-Options: DENY
X-Frame-Options: SAMEORIGIN
如果设置为 DENY，不光在别人的网站 frame 嵌入时会无法加载，在同域名页面中同样会无法加载。另一方面，如果设置为 SAMEORIGIN，那么页面就可以在同域名页面的 frame 中嵌套。
使用 <meta> 标签来设置 X-Frame-Options 是无效的！例如 <meta http-equiv="X-Frame-Options" content="deny"> 没有任何效果。

6.X-XSS-Protection
HTTP X-XSS-Protection 响应头是 Internet Explorer，Chrome 和 Safari 的一个特性，当检测到跨站脚本攻击 (XSS (en-US)) 时，浏览器将停止加载页面。

Types of attacks:
https://developer.mozilla.org/en-US/docs/Web/Security/Types_of_attacks

==================================================跨源资源共享（CORS）



==================================================HTTP 身份验证
HTTP 提供一个用于权限控制和认证的通用框架。
通过 HTTP “Basic”模式限制对你服务器的访问。

https://datatracker.ietf.org/doc/html/rfc7235
RFC 7235 定义了一个 HTTP 身份验证框架，服务器可以用来质询（challenge）客户端的请求，客户端则可以提供身份验证凭据。

质询与响应的工作流程如下：
服务器端向客户端返回 401（Unauthorized，未被授权的）响应状态码，并在 WWW-Authenticate 响应标头提供如何进行验证的信息，其中至少包含有一种质询方式。
之后，想要使用服务器对自己身份进行验证的客户端，可以通过包含凭据的 Authorization 请求标头进行验证。
通常，客户端会向用户显示密码提示，然后发送包含正确的 Authorization 标头的请求。

使用的“Basic”身份验证方案会对凭据进行编码，但是并不会进行加密。除非信息交换通过安全的连接（HTTPS/TLS），否则这件事极其不安全的。

禁止访问
如果（代理）服务器收到无效的凭据，它应该响应 401 Unauthorized 或 407 Proxy Authentication Required，用户可以发送新的请求或替换 Authorization 标头字段。
如果（代理）服务器接受的有效凭据不足以访问给定的资源，服务器将响应 403 Forbidden 状态码。与 401 Unauthorized 或 407 Proxy Authentication Required 不同的是，该用户无法进行身份验证并且浏览器不会提出新的的尝试。
在所有情况下，服务器更可能返回 404 Not Found 状态码，以向没有足够权限或者未正确身份验证的用户隐藏页面的存在。

Basic,参见 RFC 7617，base64 编码凭据
https://datatracker.ietf.org/doc/html/rfc7617
Bearer,参见 RFC 6750，bearer 令牌通过 OAuth 2.0 保护资源。
https://datatracker.ietf.org/doc/html/rfc6750

Basic 验证方案:
“Basic” HTTP 验证方案是在 RFC 7617 中规定的，在该方案中，使用用户的 ID/密码作为凭据信息，并且使用 base64 算法进行编码。

Basic 验证方案的安全性:
由于用户 ID 与密码是是以明文的形式在网络中进行传输的（尽管采用了 base64 编码，但是 base64 算法是可逆的），所以基本验证方案并不安全。
basic 验证方案应与 HTTPS/TLS 协议搭配使用。假如没有这些安全方面的增强，那么 basic 验证方案不应该被来用保护敏感或者极具价值的信息。

==================================================HTTP 缓存
HTTP 缓存会存储与请求关联的响应，并将存储的响应复用于后续请求。
可复用性有几个优点。首先，由于不需要将请求传递到源服务器，因此客户端和缓存越近，响应速度就越快。最典型的例子是浏览器本身为浏览器请求存储缓存。
此外，当响应可复用时，源服务器不需要处理请求——因为它不需要解析和路由请求、根据 cookie 恢复会话、查询数据库以获取结果或渲染模板引擎。这减少了服务器上的负载。

有两种不同类型的缓存：私有缓存和共享缓存。

私有缓存:
私有缓存是绑定到特定客户端的缓存——通常是浏览器缓存。由于存储的响应不与其他客户端共享，因此私有缓存可以存储该用户的个性化响应。
另一方面，如果个性化内容存储在私有缓存以外的缓存中，那么其他用户可能能够检索到这些内容——这可能会导致无意的信息泄露。
如果响应包含个性化内容并且你只想将响应存储在私有缓存中，则必须指定 private 指令。
Cache-Control: private
个性化内容通常由 cookie 控制，但 cookie 的存在并不能表明它是私有的，因此单独的 cookie 不会使响应成为私有的。
请注意，如果响应具有 Authorization 标头，则不能将其存储在私有缓存（或共享缓存，除非 Cache-Control 指定的是 public）中。

共享缓存:
共享缓存位于客户端和服务器之间，可以存储能在用户之间共享的响应。共享缓存可以进一步细分为代理缓存和托管缓存。
代理缓存
除了访问控制的功能外，一些代理还实现了缓存以减少网络流量。这通常不由服务开发人员管理，因此必须由恰当的 HTTP 标头等控制。
托管缓存
托管缓存由服务开发人员明确部署，以降低源服务器负载并有效地交付内容。示例包括反向代理、CDN 和 service worker 与缓存 API 的组合。
###
反向代理服务器位于用户与目标服务器之间，但是对于用户而言，反向代理服务器就相当于目标服务器，即用户直接访问反向代理服务器就可以获得目标服务器的资源。
同时，用户不需要知道目标服务器的地址，也无须在用户端作任何设定。反向代理服务器通常可用来作为Web加速，即使用反向代理作为Web服务器的前置机来降低网络和服务器的负载，提高访问效率。

通常的代理服务器，只用于代理内部网络对Internet的连接请求，客户机必须指定代理服务器,并将本来要直接发送到Web服务器上的http请求发送到代理服务器中。
由于外部网络上的主机并不会配置并使用这个代理服务器，普通代理服务器也被设计为在Internet上搜寻多个不确定的服务器,而不是针对Internet上多个客户机的请求访问某一个固定的服务器，因此普通的Web代理服务器不支持外部对内部网络的访问请求。
当一个代理服务器能够代理外部网络上的主机，访问内部网络时，这种代理服务的方式称为反向代理服务。
此时代理服务器对外就表现为一个Web服务器，外部网络就可以简单把它当作一个标准的Web服务器而不需要特定的配置。
不同之处在于，这个服务器没有保存任何网页的真实数据，所有的静态网页或者CGI程序，都保存在内部的Web服务器上。因此对反向代理服务器的攻击并不会使得网页信息遭到破坏，这样就增强了Web服务器的安全性。
###

https://baijiahao.baidu.com/s?id=1763970559392417697&wfr=spider&for=pc
正向代理
同学A急需一笔钱，他直接向富豪马云借钱，但是他俩之间毫无关系，结果当然是没有借到。经过一番打听，同学A的老师王先生是马云的好朋友，于是A同学请求王老师，让王老师帮忙向马云借钱，最终马云同意借钱给王老师，王老师把这笔钱转交给了A同学。
上文就相当于一个正向代理的过程，A同学为客户端，马云为服务器，王老师为正向代理。A同学请求王老师向马云借钱，这个过程中A同学隐藏了自己的角色，马云事实上是不知道到底是谁借的钱。相当于服务器不知道真正发起请求的客户端是谁。
反向代理
如果遇到困难需要拨打10086客服电话，可能一个地区的10086客服有几十个，但是我们不需要关心电话那头的人是谁。只需要拨通10086的总机号码，电话那头总有客服会回应。
这里的10086总机号码就相当于反向代理，客户端不知道真正提供服务的人是谁。

启发式缓存
HTTP 旨在尽可能多地缓存，因此即使没有给出 Cache-Control，如果满足某些条件，响应也会被存储和重用。这称为启发式缓存。

基于 age 的缓存策略:
存储的 HTTP 响应有两种状态：fresh 和 stale。fresh 状态通常表示响应仍然有效，可以重复使用，而 stale 状态表示缓存的响应已经过期。
确定响应何时是 fresh 的和何时是 stale 的标准是 age。在 HTTP 中，age 是自响应生成以来经过的时间。这类似于其他缓存机制中的 TTL (en-US)。
Time To Live (TTL) can refer to either the lifetime of a packet in a network, or the expiry time of cached data.
HTTP/1.1 200 OK
Content-Type: text/html
Content-Length: 1024
Date: Tue, 22 Feb 2022 22:22:22 GMT
Cache-Control: max-age=604800

<!doctype html>
…
存储示例响应的缓存会计算响应生成后经过的时间，并将结果用作响应的 age。
对于该示例的响应，max-age 的含义如下:
如果响应的 age 小于一周，则响应为 fresh。
如果响应的 age 超过一周，则响应为 stale。
只要存储的响应保持新鲜（fresh），它将用于兑现客户端请求。
当响应存储在共享缓存中时，有必要通知客户端响应的 age。继续看示例，如果共享缓存将响应存储了一天，则共享缓存将向后续客户端请求发送以下响应。
HTTP/1.1 200 OK
Content-Type: text/html
Content-Length: 1024
Date: Tue, 22 Feb 2022 22:22:22 GMT
Cache-Control: max-age=604800
Age: 86400

<!doctype html>
…
收到该响应的客户端会发现它在剩余的 518400 秒内是新鲜（fresh）的，这是响应的 max-age 和 Age 之间的差异。

Expires 或 max-age:
在 HTTP/1.0 中，新鲜度过去由 Expires 标头指定。
Expires 标头使用明确的时间而不是通过指定经过的时间来指定缓存的生命周期。
但是时间格式难以解析，也发现了很多实现的错误，有可能通过故意偏移系统时钟来诱发问题；因此，在 HTTP/1.1 中，Cache-Control 采用了 max-age——用于指定经过的时间。
如果 Expires 和 Cache-Control: max-age 都可用，则将 max-age 定义为首选。因此，由于 HTTP/1.1 已被广泛使用，无需特地提供 Expires。

Vary 响应:
区分响应的方式本质上是基于它们的 URL
但是响应的内容并不总是相同的，即使它们具有相同的 URL。特别是在执行内容协商时，来自服务器的响应可能取决于 Accept、Accept-Language 和 Accept-Encoding 请求标头的值。
例如，对于带有 Accept-Language: en 标头并已缓存的英语内容，不希望再对具有 Accept-Language: ja 请求标头的请求重用该缓存响应。在这种情况下，你可以通过在 Vary 标头的值中添加“Accept-Language”，根据语言单独缓存响应。
这会导致缓存基于响应 URL 和 Accept-Language请求标头的组合进行键控——而不是仅仅基于响应 URL
此外，如果你基于用户代理提供内容优化（例如，响应式设计），你可能会想在 Vary 标头的值中包含“User-Agent”。但是，User-Agent 请求标头通常具有非常多的变体，这大大降低了缓存被重用的机会。因此，如果可能，请考虑一种基于特征检测而不是基于 User-Agent 请求标头来改变行为的方法。
对于使用 cookie 来防止其他人重复使用缓存的个性化内容的应用程序，你应该指定 Cache-Control: private 而不是为 Vary 指定 cookie。

验证响应:
过时的响应不会立即被丢弃。HTTP 有一种机制，可以通过询问源服务器将陈旧的响应转换为新的响应。这称为验证，有时也称为重新验证。
验证是通过使用包含 If-Modified-Since 或 If-None-Match 请求标头的条件请求完成的。

If-Modified-Since
以下响应在 22:22:22 生成，max-age 为 1 小时，因此你知道它在 23:22:22 之前是新鲜的。
HTTP/1.1 200 OK
Content-Type: text/html
Content-Length: 1024
Date: Tue, 22 Feb 2022 22:22:22 GMT
Last-Modified: Tue, 22 Feb 2022 22:00:00 GMT
Cache-Control: max-age=3600

<!doctype html>
…

到 23:22:22 时，响应会过时并且不能重用缓存。因此，下面的请求显示客户端发送带有 If-Modified-Since 请求标头的请求，以询问服务器自指定时间以来是否有任何的改变。
GET /index.html HTTP/1.1
Host: example.com
Accept: text/html
If-Modified-Since: Tue, 22 Feb 2022 22:00:00 GMT
如果内容自指定时间以来没有更改，服务器将响应 304 Not Modified。
由于此响应仅表示“没有变化”，因此没有响应主体——只有一个状态码——因此传输大小非常小。
HTTP/1.1 304 Not Modified
Content-Type: text/html
Date: Tue, 22 Feb 2022 23:22:22 GMT
Last-Modified: Tue, 22 Feb 2022 22:00:00 GMT
Cache-Control: max-age=3600
收到该响应后，客户端将存储的陈旧响应恢复为新鲜的，并可以在剩余的 1 小时内重复使用它。
服务器可以从操作系统的文件系统中获取修改时间，这对于提供静态文件的情况来说是比较容易做到的。但是，也存在一些问题；例如，时间格式复杂且难以解析，分布式服务器难以同步文件更新时间。
为了解决这些问题，ETag 响应标头被标准化作为替代方案。

ETag/If-None-Match:
ETag 响应标头的值是服务器生成的任意值。服务器对于生成值没有任何限制，因此服务器可以根据他们选择的任何方式自由设置值——例如主体内容的哈希或版本号。
如果 ETag 标头使用了 hash 值，index.html 资源的 hash 值是 deadbeef
HTTP/1.1 200 OK
Content-Type: text/html
Content-Length: 1024
Date: Tue, 22 Feb 2022 22:22:22 GMT
ETag: "deadbeef"
Cache-Control: max-age=3600

<!doctype html>
…

如果该响应是陈旧的，则客户端获取缓存响应的 ETag 响应标头的值，并将其放入 If-None-Match 请求标头中，以询问服务器资源是否已被修改
GET /index.html HTTP/1.1
Host: example.com
Accept: text/html
If-None-Match: "deadbeef"
如果服务器为请求的资源确定的 ETag 标头的值与请求中的 If-None-Match 值相同，则服务器将返回 304 Not Modified。
但是，如果服务器确定请求的资源现在应该具有不同的 ETag 值，则服务器将其改为 200 OK 和资源的最新版本进行响应。

在评估如何使用 ETag 和 Last-Modified 时，请考虑以下几点：在缓存重新验证期间，如果 ETag 和 Last-Modified 都存在，则 ETag 优先。
因此，如果你只考虑缓存，你可能会认为 Last-Modified 是不必要的。然而，Last-Modified 不仅仅对缓存有用；相反，它是一个标准的 HTTP 标头，内容管理 (CMS) 系统也使用它来显示上次修改时间，由爬虫调整爬取频率，以及用于其他各种目的。所以考虑到整个 HTTP 生态系统，最好同时提供 ETag 和 Last-Modified。

强制重新验证:
如果你不希望重复使用响应，而是希望始终从服务器获取最新内容，则可以使用 no-cache 指令强制验证。
通过在响应中添加 Cache-Control: no-cache 以及 Last-Modified 和 ETag
如果请求的资源已更新，客户端将收到 200 OK 响应，否则，如果请求的资源尚未更新，则会收到 304 Not Modified 响应。
HTTP/1.1 200 OK
Content-Type: text/html
Content-Length: 1024
Date: Tue, 22 Feb 2022 22:22:22 GMT
Last-Modified: Tue, 22 Feb 2022 22:00:00 GMT
ETag: deadbeef
Cache-Control: no-cache

<!doctype html>
…
max-age=0 和 must-revalidate 的组合与 no-cache 具有相同的含义。
Cache-Control: max-age=0, must-revalidate
max-age=0 意味着响应立即过时，而 must-revalidate 意味着一旦过时就不得在没有重新验证的情况下重用它——因此，结合起来，语义似乎与 no-cache 相同。
然而，max-age=0 的使用是解决 HTTP/1.1 之前的许多实现无法处理 no-cache 这一指令——因此为了解决这个限制，max-age=0 被用作解决方法。
但是现在符合 HTTP/1.1 的服务器已经广泛部署，没有理由使用 max-age=0 和 must-revalidate 组合——你应该只使用 no-cache。

不使用缓存:
no-cache 指令不会阻止响应的存储
如果你不希望将响应存储在任何缓存中，请使用 no-store。
Cache-Control: no-store

不与其他用户共享:
如果具有个性化内容的响应意外地对缓存的其他用户可见，那将是有问题的。
在这种情况下，使用 private 指令将导致个性化响应仅与特定客户端一起存储，而不会泄露给缓存的任何其他用户。
Cache-Control: private
在这种情况下，即使设置了 no-store，也必须设置 private。

每次都提供最新的内容:
no-store 指令阻止存储响应，但不会删除相同 URL 的任何已存储响应。
换句话说，如果已经为特定 URL 存储了旧响应，则返回 no-store 不会阻止旧响应被重用。
但是，no-cache 指令将强制客户端在重用任何存储的响应之前发送验证请求。
Cache-Control: no-cache
如果服务端不支持条件请求，你可以强制客户端每次都访问服务端，总是得到最新的 200 OK 响应。

不建议随意授予 no-store，因为你失去了 HTTP 和浏览器所拥有的许多优势，包括浏览器的后退/前进缓存。

重新加载和强制重新加载:
重新加载和强制重新加载操作是从浏览器端执行验证的常见示例。
重新加载:
为了从页面错误中恢复或更新到最新版本的资源，浏览器为用户提供了重新加载功能。
在浏览器重新加载期间发送的 HTTP 请求
GET / HTTP/1.1
Host: example.com
Cache-Control: max-age=0
If-None-Match: "deadbeef"
If-Modified-Since: Tue, 22 Feb 2022 20:20:20 GMT
请求中的 max-age=0 指令指定“重用 age 为 0 或更少的响应”——因此，中间存储的响应不会被重用。
请求通过 If-None-Match 和 If-Modified-Since 进行验证。
该行为也在 Fetch 标准中定义，并且可以通过在缓存模式设置为 no-cache 的情况下，在 JavaScript 中调用 fetch() 来重现（注意 reload 不是这种情况下的正确模式）
// 注意：“reload”不是正常重新加载的正确模式；“no-cache”才是
fetch("/", { cache: "no-cache" });
强制重新加载:
出于向后兼容的原因，浏览器在重新加载期间使用 max-age=0——因为在 HTTP/1.1 之前的许多过时的实现中不理解 no-cache。
但是在这个用例中，no-cache 已被支持，并且强制重新加载是绕过缓存响应的另一种方法。
浏览器强制重新加载期间的 HTTP 请求
GET / HTTP/1.1
Host: example.com
Pragma: no-cache
Cache-Control: no-cache
由于这不是带有 no-cache 的条件请求，因此你可以确定你会从源服务器获得 200 OK。
该行为也在 Fetch 标准中定义，并且可以通过在缓存模式设置为 reload 的情况下，在 JavaScript 中调用 fetch() 来重现（注意它不是 force-reload）
// 注意：“reload”——而不是“no-cache”——是“强制重新加载”的正确模式
fetch("/", { cache: "reload" });

避免重新验证:
永远不会改变的内容应该被赋予一个较长的 max-age，方法是使用缓存破坏——也就是说，在请求 URL 中包含版本号、哈希值等。
但是，当用户重新加载时，即使服务器知道内容是不可变的，也会发送重新验证请求。
为了防止这种情况，immutable 指令可用于明确指示不需要重新验证，因为内容永远不会改变。
Cache-Control: max-age=31536000, immutable
这可以防止在重新加载期间进行不必要的重新验证。

请求折叠:
共享缓存主要位于源服务器之前，旨在减少到源服务器的流量。
如果多个相同的请求同时到达共享缓存，中间缓存将代表自己将单个请求转发到源，然后源可以将结果重用于所有客户端。这称为请求折叠。
当请求同时到达时会发生请求折叠，因此即使响应中给出了 max-age=0 或 no-cache，它也会被重用。

常见的缓存模式:
1.默认设置
缓存的默认行为（即对于没有 Cache-Control 的响应）不是简单的“不缓存”，而是根据所谓的“启发式缓存”进行隐式缓存。
为了避免这种启发式缓存，最好显式地为所有响应提供一个默认的 Cache-Control 标头。
为确保默认情况下始终传输最新版本的资源，通常的做法是让默认的 Cache-Control 值包含 no-cache
另外，如果服务实现了 cookie 或其他登录方式，并且内容是为每个用户个性化的，那么也必须提供 private，以防止与其他用户共享
Cache-Control: no-cache, private
2.缓存破坏
最适合缓存的资源是静态不可变文件，其内容永远不会改变。而对于会变化的资源，通常的最佳实践是每次内容变化时都改变 URL，这样 URL 单元可以被缓存更长的时间。
<script src="bundle.js"></script>
<link rel="stylesheet" href="build.css" />
<body>
  hello
</body>
在现代 Web 开发中，JavaScript 和 CSS 资源会随着开发的进展而频繁更新。此外，如果客户端使用的 JavaScript 和 CSS 资源的版本不同步，则显示将中断。
所以上面的 HTML 用 max-age 缓存 bundle.js 和 build.css 变得很困难。
你可以使用包含基于版本号或哈希值的更改部分的 URL 来提供 JavaScript 和 CSS。一些方法如下所示。
# version in filename
bundle.v123.js

# version in query
bundle.js?v=123

# hash in filename
bundle.YsAIAAAA-QG4G6kCMAMBAAAAAAAoK.js

# hash in query
bundle.js?v=YsAIAAAA-QG4G6kCMAMBAAAAAAAoK
由于缓存根据它们的 URL 来区分资源，因此如果在更新资源时 URL 发生变化，缓存将不会再次被重用。
<script src="bundle.v123.js"></script>
<link rel="stylesheet" href="build.v123.css" />
<body>
  hello
</body>
通过这种设计，JavaScript 和 CSS 资源都可以被缓存很长时间。
QPACK 是一种用于压缩 HTTP 标头字段的标准，其中定义了常用字段值表。
一些常用的缓存头值如下所示。
36 cache-control max-age=0
37 cache-control max-age=604800
38 cache-control max-age=2592000
39 cache-control no-cache
40 cache-control no-store
41 cache-control public, max-age=31536000
如果你选择其中一个编号选项，则可以在通过 HTTP3 传输时将值压缩为 1 个字节。
数字“37”、“38”和“41”分别代表一周、一个月和一年。
3.验证响应
不要忘记设置 Last-Modified 和 ETag 标头，以便在重新加载时不必重新传输资源。对于预构建的静态文件生成这些标头很容易。
这里的 ETag 值可能是文件的哈希值。
# response for bundle.v123.js
Last-Modified: Tue, 22 Feb 2022 20:20:20 GMT
ETag: YsAIAAAA-QG4G6kCMAMBAAAAAAAoK
可以添加 immutable 以防止重新加载时验证。
# bundle.v123.js
200 OK HTTP/1.1
Content-Type: application/javascript
Content-Length: 1024
Cache-Control: public, max-age=31536000, immutable
Last-Modified: Tue, 22 Feb 2022 20:20:20 GMT
ETag: YsAIAAAA-QG4G6kCMAMBAAAAAAAoK
缓存破坏是一种通过在内容更改时更改 URL 来使响应在很长一段时间内可缓存的技术。该技术可以应用于所有子资源，例如图像。
4.主要资源
与子资源不同，主资源不能使用缓存破坏，因为它们的 URL 不能像子资源 URL 一样被修饰。
如果存储以下 HTML 本身，即使在服务器端更新内容，也无法显示最新版本。
<script src="bundle.v123.js"></script>
<link rel="stylesheet" href="build.v123.css" />
<body>
  hello
</body>
对于这种情况，no-cache 将是合适的——而不是 no-store
此外，添加 Last-Modified 和 ETag 将允许客户端发送条件请求，如果 HTML 没有更新，则可以返回 304 Not Modified：
200 OK HTTP/1.1
Content-Type: text/html
Content-Length: 1024
Cache-Control: no-cache
Last-Modified: Tue, 22 Feb 2022 20:20:20 GMT
ETag: AAPuIbAOdvAGEETbgAAAAAAABAAE
该设置适用于非个性化 HTML，但对于使用 cookie 进行个性化的响应（例如，在登录后），不要忘记同时指定 private
200 OK HTTP/1.1
Content-Type: text/html
Content-Length: 1024
Cache-Control: no-cache, private
Last-Modified: Tue, 22 Feb 2022 20:20:20 GMT
ETag: AAPuIbAOdvAGEETbgAAAAAAABAAE
Set-Cookie: __Host-SID=AHNtAyt3fvJrUL5g5tnGwER; Secure; Path=/; HttpOnly

大多数 Web 内容都可以通过上述两种模式的组合来覆盖。

==================================================HTTP 条件请求
在 HTTP 协议中有一个“条件式请求”的概念，在这类请求中，请求的结果，甚至请求成功的状态，都会随着验证器与受影响资源的比较结果的变化而变化。
这类请求可以用来验证缓存的有效性，省去不必要的控制手段，以及验证文件的完整性，例如在断点续传的场景下或者在上传或者修改服务器端的文件的时候避免更新丢失问题。

基本原理:
在 HTTP 协议中，条件请求指的是请求的执行结果会因特定首部的值不同而不同。这些首部规定了请求的前置条件，请求结果则视条件匹配与否而有所不同。
请求引发的不同的反应取决于请求所使用的方法，以及组成前置条件首部集合:
对于安全（safe）方法来说，例如 GET，通常用来获取文件，条件请求可以被用来限定仅在满足条件的情况下返回文件。这样可以节省带宽。
对于非安全（unsafe）方法来说，例如 PUT 方法，通常用来上传文件，条件请求可以被用来限定仅在满足文件的初始版本与服务器上的版本相同的条件下才会将其上传。

验证器:
所有的条件请求首部都是试图去检测服务器上存储的资源是否与某一特定版本相匹配。为了达到这个目的，条件请求需要指明资源的版本。
由于逐个字节去比较完整资源是不切实际的，况且这也并非总是想要的结果，所以在请求中会传递一个描述资源版本的值。这些值称为“验证器”，并且分为两大类:
文件的最后修改时间，即 last-modified（最后修改）时间。
一个意义模糊的字符串，指代一个独一无二的版本，称为“实体标签”，或者 etag。

比较同一份资源的不同版本有一定的技巧性：取决于上下文环境的不同，有两种不同的等值检查（equality checks）类型:
强验证类型（Strong validation）应用于需要逐个字节相对应的情况，例如需要进行断点续传的时候。
弱验证类型（Weak validation）应用于用户代理只需要确认资源内容相同即可。即便是有细微差别也可以接受，比如显示的广告不同，或者是页脚的时间不同。
验证类型与验证器的类型是相互独立的。 Last-Modified 和 ETag 首部均可应用于两种验证类型，尽管在服务器端实现的复杂程度可能会有所不同。HTTP 协议默认使用强验证类型，可以指定何时使用弱验证类型。

强验证类型:
强验证类型的作用在于确保要比较的资源与其相比较的对象之间每一个字节都相同。对于有些首部来说需要明确指定该验证类型，而对于另外一些来说则是默认值就是强验证类型。强验证类型的要求相当严格，在服务器层面来说可能较难保证。但是它确保了数据在任何时候都没有缺损，有时候则需要以牺牲性能为代价。
使用 Last-Modified 首部很难为强验证类型提供一个唯一标识。通常这是由 ETag 首部来完成的，该首部可以提供使用 MD5 算法获取的资源（或其衍生品）的散列值。

弱验证类型:
弱验证类型与强验证类型不同，因为它会把内容相同的两份文件看做是一样的。例如，使用弱验证类型，一个页面与另外一个页面只是在页脚显示的时间上有所不同，或者是展示的广告不相同，那么就会被认为是相同的。
但是在使用强验证的情况下，二者是不同的。构建应用于弱验证类型的标签（etag）体系可能会比较复杂，因为这会涉及到对页面上不同的元素的重要性进行排序，但是会对缓存性能优化相当有帮助。

条件首部:
一些被称为条件首部的 HTTP 首部，可以引发条件请求。它们是:
If-Match
如果远端资源的实体标签与在 ETag 这个首部中列出的值相同的话，表示条件匹配成功。默认地，除非实体标签带有 'W/' 前缀，否者它将会执行强验证。

If-None-Match
如果远端资源的实体标签与在 ETag 这个首部中列出的值都不相同的话，表示条件匹配成功。默认地，除非实体标签带有 'W/' 前缀，否者它将会执行强验证。

If-Modified-Since
如果远端资源的 Last-Modified 首部标识的日期比在该首部中列出的值要更晚，表示条件匹配成功。

If-Unmodified-Since
如果远端资源的 HTTPHeader("Last-Modified")}} 首部标识的日期比在该首部中列出的值要更早或相同，表示条件匹配成功。

If-Range
与 If-Match 或 If-Unmodified-Since 相似，但是只能含有一个实体标签或者日期值。如果匹配失败，则条件请求宣告失败，此时将不会返回 206 Partial Content 响应码，而是返回 200 OK 响应码，以及完整的资源。

应用场景
缓存更新:
条件式请求最常见的应用场景是更新缓存。假如缓存为空，或者是没有缓存的话，被请求资源会以状态码 200 OK 返回。
验证器会同资源一起返回，它们出现在首部字段中。在这个例子中， Last-Modified 与 ETag 都被返回，不过如果只返回其中的一个也是可以的。这些验证器会同资源一起被缓存起来（与所有的首部一样），并在在缓存失效的时候用来发起条件式请求。
只要缓存未失效，就不会发起任何请求。但是一旦失效——主要是由 Cache-Control 首部控制——客户端就不会采用缓存值而是发起条件式请求。验证器的值会用作 If-Modified-Since 和 If-Match 首部字段的参数。
假如资源未发生变化，服务器就返回状态码为 304 Not Modified 的响应。这样相当于对缓存资源进行了刷新，而客户端则采用被缓存的资源。尽管这里有一次请求/响应往返会消耗一定的资源，但是这样做比将整个资源通过网络再传输一遍更高效。
假如资源发生了变化，服务器就直接返回 200 OK 响应码，连同新版本的资源，就像是没有应用条件式请求一样；客户端则采用新版本资源（并将其缓存起来）。
除了需要在服务器端对验证器进行设置以外，该机制是透明的：所有的浏览器都会对缓存资源进行管理，在不需要 Web 开发者进行任何特殊处理的情况下发送条件式请求。

增量下载的完整性:
文件的增量下载是 HTTP 协议规定的一项功能，它允许恢复先前的操作，通过保存先前已经获得的信息来节省带宽和时间
支持增量下载的服务器会通过 Accept-Ranges 首部来广播这项能力。此后客户端就可以通过发送 Ranges (en-US) 首部字段以及缺失的范围值来进行断点续传了
基本原理很简单，但是这里有一个潜在的问题：如果要下载的资源在两次下载之间进行了修改，得到的数据范围就会对应该资源的两个不同的版本，那么最终获得的文件是损坏的。
为了防止这种情况的发生，需要使用条件式请求。对于范围请求来说，有两种方法可以实现这个目的。更灵活一些的方法是使用 If-Modified-Since 和 If-Match 首部，假如前置条件失败，服务器端会返回错误提示，然后客户端可以从头开始重新下载资源
尽管这种方法行得通，但是它在文件发生变化的情况下增加了一次额外的请求/响应往返。这一点会影响性能。为此 HTTP 协议规定了一个特定的首部—— If-Range ——来避免这种情况的发生
该方法更高效，但是缺乏一定的灵活性，因为条件值只能是实体标签。不过这种额外的灵活性很少会需要。

处理资源的首次上传问题:
资源的首次上传问题是前面所描述的情况的一个极端情况。
与任何资源更新问题一样，当两个客户端在大致相同的时间进行上传操作的时候，就会遇到竞态条件。
为了防止这种情况的发生，可以使用条件式请求：添加 If-None-Match 首部，并将其值设置为'*', 表示任意实体标签。
当且仅当资源先前并不存在的情况下请求的操作才会成功执行
If-None-Match 首部只可应用于兼容 HTTP/1.1（及后续版本）的服务器。假如不确定所访问的服务器是否兼容，需要首先向要访问的资源发送一次 HEAD 请求来进行确认。

==================================================HTTP 数据压缩
数据压缩是提高 Web 站点性能的一种重要手段

数据压缩会在三个不同的层面发挥作用:
首先某些格式的文件会采用特定的优化算法进行压缩，
其次在 HTTP 协议层面会进行通用数据加密，即数据资源会以压缩的形式进行端到端传输，
最后数据压缩还会发生在网络连接层面，即发生在 HTTP 连接的两个节点之间。

文件格式压缩
每一种文件类型都会存有冗余，也就是浪费的空间。
程师们设计了可以应用于特定用途的文件类型的经过优化的算法。用于文件的压缩算法可以大致分为两类:
无损压缩。在压缩与解压缩的循环期间，不会对要恢复的数据进行修改。复原后的数据与原始数据是一致的（比特与比特之间一一对应）。对于图片文件来说，gif 或者 png 格式的文件就是采用了无损压缩算法。
有损压缩。在压缩与解压缩的循环期间，会对原始数据进行修改，但是会（希望）以用户无法觉察的方式进行。网络上的视频文件通常采用有损压缩算法，jpeg 格式的图片也是有损压缩。

一些特定的文件格式既可以采用无损压缩算法，又可以采用有损压缩算法，例如 webp，并且有损压缩算法可以对压缩比率进行配置，当然这会导致压缩品质的不同。

端到端压缩技术:
对于各种压缩手段来说，端到端压缩技术是 Web 站点性能提升最大的地方。端到端压缩技术指的是消息主体的压缩是在服务器端完成的，并且在传输过程中保持不变，直到抵达客户端。
不管途中遇到什么样的中间节点，它们都会使消息主体保持原样。
如今只有两种算法有着举足轻重的地位：gzip 应用最广泛，br 则是新的挑战者。
为了选择要采用的压缩算法，浏览器和服务器之间会使用主动协商机制。
浏览器发送 Accept-Encoding 标头，其中包含有它所支持的压缩算法，以及各自的优先级，服务器则从中选择一种，使用该算法对响应的消息主体进行压缩，并且发送 Content-Encoding 标头来告知浏览器它选择了哪一种算法。
由于该内容协商过程是基于编码类型来选择资源的展现形式的，在响应时，服务器至少发送一个包含 Accept-Encoding 的 Vary 标头以及该标头；这样的话，缓存服务器就可以对资源的不同展现形式进行缓存。

由于压缩技术可以带来很大的性能提升，建议对除了已经经过压缩的文件如图片、音频和视频文件之外的其他类型的文件均进行压缩。

逐跳压缩技术:
逐跳压缩技术尽管与端到端压缩技术有些类似，但是它们在一点上有着本质的区别：即这里的压缩指的不是对源头服务器上的资源的压缩，以此来创建一份特定的展现形式然后进行传输，而是对客户端与服务器端之间的任意两个节点之间传递的消息的主体的压缩。在两个相邻的中间节点之间的连接上，可能会应用不同的压缩方式。
为了实现这个目的，HTTP 协议中采用了与端到端压缩技术所使用的内容协商机制相类似的机制：节点发送请求，使用 TE 标头来宣告它的意愿，另外一个节点则从中选择合适的方法，进行应用，然后在 Transfer-Encoding 标头中指出它所选择的方法。
在实际应用中，逐跳压缩对于服务器和客户端来说是不可见的，并且很少使用。TE 标头和 Transfer-Encoding 标头最常用来发送分块响应，允许在获得资源的确切长度之前就可以开始传输。

==================================================内容协商
在 HTTP 协议中，内容协商是一种机制，用于为同一 URI 提供资源不同的表示形式，以帮助用户代理指定最适合用户的表示形式（例如，哪种文档语言、哪种图片格式或者哪种内容编码）。
一份特定的文件被称为一项资源。当客户端获取资源的时候，会使用其对应的 URL 发送请求。服务器通过这个 URL 来选择它指向的资源的某一可用的变体——每一个变体称为一种表示形式——然后将这个选定的表示形式返回给客户端。
整个资源，以及它的各种表示形式，共享一个特定的 URL。当访问某项资源的时候，内容协商会决定如何选择一种指定的表示形式。客户端和服务器端之间存在多种协商方式。

最佳表示形式的选取可以通过两种机制实现:
客户端设置特定的 HTTP 标头（又称为服务端驱动型内容协商或者主动内容协商），这是进行内容协商的标准方式。
服务器返回 300（Multiple Choices）或者 406（Not Acceptable）、415（Unsupported Media Type）HTTP 响应状态码 （又称为代理驱动型协商或者响应式协商），这种方式一般用作备选方案。

服务端驱动型内容协商机制:
浏览器（或者其他任何类型的用户代理）会随同 URL 发送一系列的 HTTP 标头。这些标头描述了用户倾向的选择。服务器则以此为线索，通过内部算法来选择最佳方案提供给客户端。
如果它不能提供一个合适的资源，它可能使用 406（Not Acceptable）、415（Unsupported Media Type）进行响应并为其支持的媒体类型设置标头（例如，分别对 POST 和 PATCH 请求使用 Accept-Post (en-US) 或 Accept-Patch 标头）。
HTTP/1.1 规范指定了一系列的标准标头用于启动服务端驱动型内容协商（Accept、Accept-Charset、Accept-Encoding、Accept-Language）。
尽管严格来说 User-Agent 并不在此列，有时候它还是会被用来确定给客户端发送的所请求资源的特定表示形式，不过这种做法不提倡使用。
服务器会使用 Vary 标头来说明实际上哪些标头被用作内容协商的参考依据（确切来说是与之相关的响应标头），这样可以使缓存的运作更有效。
存在如下几个缺点:
服务器对浏览器并非全知全能。即便是有了客户端示意扩展，也依然无法获取关于浏览器能力的全部信息。
客户端提供的信息相当冗长（HTTP/2 协议的标头压缩机制缓解了这个问题）
因为给定的资源需要返回不同的表示形式，共享缓存的效率会降低，而服务器端的实现会越来越复杂

Accept 标头:
Accept 标头列举了用户代理希望接收的媒体资源的 MIME 类型。其中不同的 MIME 类型之间用逗号分隔，同时每一种 MIME 类型会配有一个品质因数（quality factor），该参数明确了不同 MIME 类型之间的相对优先级。
https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Content_negotiation/List_of_default_Accept_values

Accept-Encoding 标头:
Accept-Encoding 标头明确说明了（接收端）可以接受的内容编码形式（所支持的压缩算法）。该标头的值是一个 Q 因子清单（例如 br, gzip;q=0.8），用来提示不同编码类型值的优先级顺序。默认值 identity 的优先级最低（除非声明为其他优先级）。
将 HTTP 消息进行压缩是一种最重要的提升 Web 站点性能的方法。该方法会减小所要传输的数据量的大小，节省可用带宽。浏览器总是会发送该标头，服务器则应该配置为接受它，并且采用一定的压缩方案。

Accept-Language 标头:
Accept-Language 标头用来提示用户期望获得的自然语言的优先顺序。该标头的值是一个 Q 因子清单（例如 de, en;q=0.7）。用户代理的图形界面上所采用的语言通常可以用来设置为默认值，但是大多数浏览器允许设置不同优先级的语言选项。

User-Agent 标头:
尽管使用该标头来进行内容选择是合理的，但是依赖这个标头来确定用户代理都支持哪些功能特性通常被认为是一个糟糕的做法。
User-Agent 标头可以用来识别发送请求的浏览器。该字符串中包含有用空格间隔的产品标记符及注释的清单。
产品标记符由产品名称、后面紧跟的“/”以及产品版本号构成，例如 Firefox/4.0.1。

Vary 响应标头:
与前面列举的 Accept-* 形式的由客户端发送的标头相反，Vary 标头是由服务器在响应中发送的。
它指示了服务器在服务端驱动型内容协商阶段所使用的标头清单。Vary 标头是必要的，它用于将决策的规范告知缓存，这样它就可以进行复现。这将使缓存发挥它的作用，同时确保缓存可以向用户提供正确的内容。
特殊值“*”意味着在服务端驱动型内容协商过程中同时采纳了未在标头中传递的信息来选择合适的内容。
Vary 标头是在 HTTP 协议的 1.1 版本中新添加的，它是为了使缓存恰当地工作。缓存为了能够与服务端驱动型内容协商机制协同工作，需要知道服务器选择传送内容的规范。这样的话，缓存服务器就可以重复该算法，直接提供恰当的内容，而不需要向服务器发送更多的请求。显然，通配符“*”阻碍了缓存机制发挥作用，因为缓存并不知道该通配符究竟指代哪些元素。

==================================================Vary
Vary 是一个 HTTP 响应头部信息，它决定了对于未来的一个请求头，应该用一个缓存的回复 (response) 还是向源服务器请求一个新的回复。
它被服务器用来表明在 content negotiation algorithm（内容协商算法）中选择一个资源代表的时候应该使用哪些头部信息（headers）.

在响应状态码为 304 Not Modified 的响应中，也要设置 Vary 首部，而且要与相应的 200 OK 响应设置得一模一样。

Vary: *
Vary: <header-name>, <header-name>, ...

*
所有的请求都被视为唯一并且非缓存的，使用Cache-Control: no-store,来实现则更适用，这样用于说明不存储该对象更加清晰。

<header-name>
逗号分隔的一系列 http 头部名称，用于确定缓存是否可用。

例子: 动态服务
对于 User-Agent 头部信息，例如你提供给移动端的内容是不同的，可用防止你客户端误使用了用于桌面端的缓存。
Vary: User-Agent

==================================================HTTP Cookie
HTTP Cookie（也叫 Web Cookie 或浏览器 Cookie）是服务器发送到用户浏览器并保存在本地的一小块数据。
浏览器会存储 cookie 并在下次向同一服务器再发起请求时携带并发送到服务器上。
通常，它用于告知服务端两个请求是否来自同一浏览器——如保持用户的登录状态。Cookie 使基于无状态的 HTTP 协议记录稳定的状态信息成为了可能。

Cookie 主要用于以下三个方面:
会话状态管理
如用户登录状态、购物车、游戏分数或其他需要记录的信息

个性化设置
如用户自定义设置、主题和其他设置

浏览器行为跟踪
如跟踪分析用户行为等

Cookie 曾一度用于客户端数据的存储，因当时并没有其他合适的存储办法而作为唯一的存储手段，但现在推荐使用现代存储 API。
由于服务器指定 Cookie 后，浏览器的每次请求都会携带 Cookie 数据，会带来额外的性能开销（尤其是在移动环境下）。新的浏览器 API 已经允许开发者直接将数据存储到本地，如使用 Web storage API（localStorage 和 sessionStorage）或 IndexedDB 。

要查看 Cookie 存储（或网页上能够使用其他的存储方式），你可以在开发者工具中启用存储查看器（Storage Inspector）功能，并在存储树上选中 Cookie。

创建 Cookie:
服务器收到 HTTP 请求后，服务器可以在响应标头里面添加一个或多个 Set-Cookie 选项。浏览器收到响应后通常会保存下 Cookie，并将其放在 HTTP Cookie 标头内，向同一服务器发出请求时一起发送。
你可以指定一个过期日期或者时间段之后，不能发送 cookie。你也可以对指定的域和路径设置额外的限制，以限制 cookie 发送的位置。

Set-Cookie 和 Cookie 标头
服务器使用 Set-Cookie 响应头部向用户代理（一般是浏览器）发送 Cookie 信息。一个简单的 Cookie 可能像这样:
Set-Cookie: <cookie-name>=<cookie-value>
现在，对该服务器发起的每一次新请求，浏览器都会将之前保存的 Cookie 信息通过 Cookie 请求头部再发送给服务器。
GET /sample_page.html HTTP/1.1
Host: www.example.org
Cookie: yummy_cookie=choco; tasty_cookie=strawberry

定义 Cookie 的生命周期:
Cookie 的生命周期可以通过两种方式定义:
会话期 Cookie 会在当前的会话结束之后删除。浏览器定义了“当前会话”结束的时间，一些浏览器重启时会使用会话恢复。这可能导致会话 cookie 无限延长。
持久性 Cookie 在过期时间（Expires）指定的日期或有效期（Max-Age）指定的一段时间后被删除。

Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT;
当 Cookie 的过期时间（ Expires）被设定时，设定的日期和时间只与客户端相关，而不是服务端。
如果你的站点对用户进行身份验证，则每当用户进行身份验证时，它都应重新生成并重新发送会话 Cookie，甚至是已经存在的会话 Cookie。

限制访问 Cookie:
有两种方法可以确保 Cookie 被安全发送，并且不会被意外的参与者或脚本访问：Secure 属性和 HttpOnly 属性。
标记为 Secure 的 Cookie 只应通过被 HTTPS 协议加密过的请求发送给服务端。
它永远不会使用不安全的 HTTP 发送（本地主机除外），这意味着中间人攻击者无法轻松访问它。
不安全的站点（在 URL 中带有 http:）无法使用 Secure 属性设置 cookie。但是，Secure 不会阻止对 cookie 中敏感信息的访问。
例如，有权访问客户端硬盘（或，如果未设置 HttpOnly 属性，则为 JavaScript）的人可以读取和修改它。

JavaScript Document.cookie API 无法访问带有 HttpOnly 属性的 cookie；此类 Cookie 仅作用于服务器。
例如，持久化服务器端会话的 Cookie 不需要对 JavaScript 可用，而应具有 HttpOnly 属性。此预防措施有助于缓解跨站点脚本（XSS） (en-US)攻击。

Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; Secure; HttpOnly

定义 Cookie 发送的位置:
Domain 和 Path 标识定义了 Cookie 的作用域：即允许 Cookie 应该发送给哪些 URL。
1.Domain 属性
Domain 指定了哪些主机可以接受 Cookie。如果不指定，该属性默认为同一 host 设置 cookie，不包含子域名。如果指定了 Domain，则一般包含子域名。因此，指定 Domain 比省略它的限制要少。但是，当子域需要共享有关用户的信息时，这可能会有所帮助。
例如，如果设置 Domain=mozilla.org，则 Cookie 也包含在子域名中（如 developer.mozilla.org）。
2.Path 属性
Path 属性指定了一个 URL 路径，该 URL 路径必须存在于请求的 URL中，以便发送 Cookie 标头。以字符 %x2F (“/”) 作为路径分隔符，并且子路径也会被匹配。
例如，设置 Path=/docs，则以下地址都会匹配:
/docs
/docs/
/docs/Web/
/docs/Web/HTTP
但是这些请求路径不会匹配以下地址:
/
/docsets
/fr/docs
3.SameSite 属性
SameSite 属性允许服务器指定是否/何时通过跨站点请求发送（其中站点由注册的域和方案定义：http 或 https）。这提供了一些针对跨站点请求伪造攻击（CSRF）的保护。它采用三个可能的值：Strict、Lax 和 None。
使用 Strict，cookie 仅发送到它来源的站点。Lax 与 Strict 相似，只是在用户导航到 cookie 的源站点时发送 cookie。例如，通过跟踪来自外部站点的链接。None 指定浏览器会在同站请求和跨站请求下继续发送 cookie，但仅在安全的上下文中（即，如果 SameSite=None，且还必须设置 Secure 属性）。如果没有设置 SameSite 属性，则将 cookie 视为 Lax。
Set-Cookie: mykey=myvalue; SameSite=Strict
与 SameSite 相关的标准最近发生了变化:
如果 SameSite 未指定，则 SameSite=Lax 时新的默认值。以前，默认情况下会为有请求发送 cookie。
SameSite=None 的 cookie 还必须指定 Secure 属性（它们需要安全上下文）。
cookie 使用不同的方案（http: 或 https:）发送来自同一域的 cookie，则不再视为来自同一站点。
4.Cookie 前缀
cookie 的机制使得服务器无法确认 cookie 是在安全来源上设置的，甚至无法确定 cookie 最初是在哪里设置的。
作为深度防御措施，可以使用 cookie 前缀来断言有关 cookie 的特定事实。有两个前缀可用:
__Host-
如果 cookie 名称具有此前缀，则仅当它也用 Secure 属性标记、从安全来源发送、不包括 Domain 属性，并将 Path 属性设置为 / 时，它才在 Set-Cookie 标头中接受。这样，这些 cookie 可以被视为“domain-locked”。
__Secure-
如果 cookie 名称具有此前缀，则仅当它也用 Secure 属性标记，是从安全来源发送的，它才在 Set-Cookie 标头中接受。该前缀限制要弱于 __Host- 前缀。
带有这些前缀的 Cookie，如果不符合其限制的会被浏览器拒绝。请注意，这确保了如果子域要创建带有前缀的 cookie，那么它将要么局限于该子域，要么被完全忽略。
由于应用服务器仅在确定用户是否已通过身份验证或 CSRF 令牌正确时才检查特定的 cookie 名称，因此，这有效地充当了针对会话劫持的防御措施。

JavaScript 通过 Document.cookie 访问 Cookie:
通过 Document.cookie 属性可创建新的 Cookie。如果未设置 HttpOnly 标记，你也可以从 JavaScript 访问现有的 Cookie。
document.cookie = "yummy_cookie=choco";
document.cookie = "tasty_cookie=strawberry";
console.log(document.cookie);
// logs "yummy_cookie=choco; tasty_cookie=strawberry"
通过 JavaScript 创建的 Cookie 不能包含 HttpOnly 标志。
JavaScript 可以通过跨站脚本攻击（XSS）的方式来窃取 Cookie。
备注: 当你存储信息到 Cookie 中时，需要明白 cookie 的值是可以被访问，且可以被终端用户所修改的。
根据应用程序的不同，可能需要使用服务器查找的不透明标识符，或者研究诸如 JSON Web Tokens 之类的替代身份验证/机密机制。当机器处于不安全环境时，切记不能通过 HTTP Cookie 存储、传输敏感信息。
缓解涉及 Cookie 的攻击的方法:
使用 HttpOnly 属性可防止通过 JavaScript 访问 cookie 值。
用于敏感信息（例如指示身份验证）的 Cookie 的生存期应较短，并且 SameSite 属性设置为 Strict 或 Lax。（请参见上方的 SameSite 属性。）在支持 SameSite 的浏览器中，这样做的作用是确保不与跨站点请求一起发送身份验证 cookie。因此，这种请求实际上不会向应用服务器进行身份验证。

跟踪和隐私:
1.第三方 Cookie
Cookie 与特定域和方案（例如，http 或 https）相关联，如果设置了 Set-Cookie Domain 属性，也可能与子域相关联。如果该 cookie 域和方案匹配当前的页面，则认为该 cookie 和该页面来自同一站点，则称为第一方 cookie（first-party cookie）。
如果域和方案不同，则它不认为来自同一个站点，被称为第三方 cookie（third-party cookie）。虽然托管网页的服务器设置第一方 Cookie 时，但该页面可能包含存储在其他域中的服务器上的图像或其他组件（例如，广告横幅），这些图像或其他组件可能会设置第三方 Cookie。
这些主要用于在网络上进行广告和跟踪。
第三方服务器可以基于同一浏览器在访问多个站点时发送给它的 cookie 来建立用户浏览历史和习惯的配置文件。Firefox 默认情况下会阻止已知包含跟踪器的第三方 cookie。第三方 cookie（或仅跟踪 cookie）也可能被其他浏览器设置或扩展程序阻止。阻止 Cookie 会导致某些第三方组件（例如社交媒体窗口小部件）无法正常运行。
备注： 服务器可以（并且应该）设置 cookie SameSite 属性以指定是否可以将 cookie 发送到第三方站点。
2.Cookie 相关规定:
涉及使用 Cookie 的法律或法规包括:
欧盟通用数据隐私法规（GDPR）
欧盟的电子隐私权指令
加州消费者隐私法
这些法规包括以下要求:
向用户表明你的站点使用 cookie。
允许用户选择不接收某些或所有 cookie。
允许用户在不接收 Cookie 的情况下使用大部分服务。

在浏览器中存储信息的其他方式:
在浏览器中存储数据的另一种方法是 Web Storage API。window.sessionStorage 和 window.localStorage 属性与持续时间中的会话和永久 cookie 相对应，但是存储限制比 cookie 大，并且永远不会发送到服务器。

==================================================HTTP 请求范围
HTTP 协议范围请求允许服务器只发送 HTTP 消息的一部分到客户端。范围请求在传送大的媒体文件，或者与文件下载的断点续传功能搭配使用时非常有用。
检测服务器端是否支持范围请求
假如在响应中存在 Accept-Ranges 首部（并且它的值不为“none”），那么表示该服务器支持范围请求。例如，你可以使用 cURL 发送一个 HEAD 请求来进行检测。
curl -I http://i.imgur.com/z4d4kWk.jpg
HTTP/1.1 200 OK
...
Accept-Ranges: bytes
Content-Length: 146515

在上面的响应中， Accept-Ranges: bytes 表示界定范围的单位是 bytes。这里 Content-Length 也是有效信息，因为它提供了要检索的图片的完整大小。

如果站点未发送 Accept-Ranges 首部，那么它们有可能不支持范围请求。一些站点会明确将其值设置为 "none"，以此来表明不支持。
curl -I https://www.youtube.com/watch?v=EwTZ2xpQwpA
HTTP/1.1 200 OK
...
Accept-Ranges: none

从服务器端请求特定的范围:
假如服务器支持范围请求的话，你可以使用 Range 首部来生成该类请求。该首部指示服务器应该返回文件的哪一或哪几部分。
1.单一范围
我们可以请求资源的某一部分。这次我们依然用 cURL 来进行测试。"-H" 选项可以在请求中追加一个首部行，在这个例子中，是用 Range 首部来请求图片文件的前 1024 个字节。
curl http://i.imgur.com/z4d4kWk.jpg -i -H "Range: bytes=0-1023"
这样生成的请求如下:
GET /z4d4kWk.jpg HTTP/1.1
Host: i.imgur.com
Range: bytes=0-1023

服务器端会返回状态码为 206 Partial Content 的响应:
HTTP/1.1 206 Partial Content
Content-Range: bytes 0-1023/146515
Content-Length: 1024
...
(binary content)
在这里，Content-Length 首部现在用来表示先前请求范围的大小（而不是整张图片的大小）。Content-Range 响应首部则表示这一部分内容在整个资源中所处的位置。

2.多重范围
Range 头部也支持一次请求文档的多个部分。请求范围用一个逗号分隔开。
curl http://www.example.com -i -H "Range: bytes=0-50, 100-150"
服务器返回 206 Partial Content 状态码和 Content-Type：multipart/byteranges; boundary=3d6b6a416f9b5 头部，Content-Type：multipart/byteranges 表示这个响应有多个 byterange。每一部分 byterange 都有他自己的 Content-type 头部和 Content-Range，并且使用 boundary 参数对 body 进行划分。
HTTP/1.1 206 Partial Content
Content-Type: multipart/byteranges; boundary=3d6b6a416f9b5
Content-Length: 282

--3d6b6a416f9b5
Content-Type: text/html
Content-Range: bytes 0-50/1270

<!doctype html>
<html>
<head>
    <title>Example Do
--3d6b6a416f9b5
Content-Type: text/html
Content-Range: bytes 100-150/1270

eta http-equiv="Content-type" content="text/html; c
--3d6b6a416f9b5--

3.条件式范围请求
当（中断之后）重新开始请求更多资源片段的时候，必须确保自从上一个片段被接收之后该资源没有进行过修改。
The If-Range 请求首部可以用来生成条件式范围请求：假如条件满足的话，条件请求就会生效，服务器会返回状态码为 206 Partial 的响应，以及相应的消息主体。
假如条件未能得到满足，那么就会返回状态码为 200 OK 的响应，同时返回整个资源。该首部可以与 Last-Modified 验证器或者 ETag 一起使用，但是二者不能同时使用。
If-Range: Wed, 21 Oct 2015 07:28:00 GMT

范围请求的响应:
与范围请求相关的有三种状态:
在请求成功的情况下，服务器会返回 206 Partial Content 状态码。
在请求的范围越界的情况下（范围值超过了资源的大小），服务器会返回 416 Requested Range Not Satisfiable （请求的范围无法满足）状态码。
在不支持范围请求的情况下，服务器会返回 200 OK 状态码。

与分块传输编码的对比
Transfer-Encoding 首部允许分块编码，这在数据量很大，并且在请求未能完全处理完成之前无法知晓响应的体积大小的情况下非常有用。
服务器会直接把数据发送给客户端而无需进行缓冲或确定响应的精确大小——后者会增加延迟。范围请求与分块传输是兼容的，可以单独或搭配使用。

==================================================HTTP 的重定向
URL 重定向（也称为 URL 转发）是一种为页面、表单或者整个 Web 站点/应用提供多个 URL 地址的技术。
HTTP 对此操作有一种特殊类型的响应，称为 HTTP 重定向（HTTP redirect）。

重定向可实现许多目标:
站点维护或停机期间的临时重定向。
永久重定向将在更改站点的 URL 后，保留现有的链接/书签、上传文件时表示进度的页面等。

原理
在 HTTP 协议中，重定向操作由服务器向请求发送特殊的重定向响应而触发。重定向响应包含以 3 开头的状态码，以及 Location 标头，其保存着重定向的 URL。
浏览器在接收到重定向时，它们会立刻加载 Location 标头中提供的新 URL。除了额外的往返操作中会有一小部分性能损失之外，重定向操作对于用户来说是不可见的。

不同类型的重定向映射可以划分为三个类别:
永久重定向
临时重定向
特殊重定向

永久重定向
这种重定向操作是永久性的。它表示原 URL 不应再被使用，而选用新的 URL 替换它。搜索引擎机器人、RSS 阅读器以及其他爬虫将更新资源原始的 URL。
状态码	状态文本	处理方法	典型应用场景
301	Moved Permanently	GET 方法不会发生变更。其他方法有可能会变更为 GET 方法。[1]	网站重构。
308	Permanent Redirect	方法和消息主体都不发生变化。	使用用于非 GET 链接/操作重组网站。
该规范无意使方法发生改变，但在实际应用中用户代理会更改其方法。308 状态码被创建用来消除在使用非 GET 方法时行为的歧义。

临时重定向
有时候请求的资源无法从其标准地址访问，但是却可以从另外的地方访问。在这种情况下，可以使用临时重定向。
搜索引擎和其他爬虫不会记录新的、临时的 URL。在创建、更新或者删除资源的时候，临时重定向也可以用于显示临时性的进度页面。
状态码	状态文本	处理方法	典型应用场景
302	Found	GET 方法不会发生变更。其他方法有可能会变更为 GET 方法。[2]	由于不可预见的原因该页面暂不可用。
303	See Other	GET 方法不会发生变更，其他方法会变更为 GET 方法（消息主体丢失）。	用于 PUT 或 POST 请求完成之后重定向，来防止由于页面刷新导致的操作的重复触发。
307	Temporary Redirect	方法和消息主体都不发生变化。	由于不可预见的原因该页面暂不可用。当站点支持非 GET 方法的链接或操作的时候，该状态码优于 302 状态码。
该规范无意使方法发生改变，但在实际应用中用户代理会改变其方法。307 状态码被创建用来消除在使用非 GET 方法时行为的歧义。

特殊重定向
304（Not Modified）会使页面跳转到本地的缓存副本中（可能已过时），而 300（Multiple Choice）则是一种手动重定向：将消息主体以 Web 页面形式呈现在浏览器中，列出了可能的重定向链接，用户可以从中进行选择。
状态码	状态文本	典型应用场景
300	Multiple Choice	不常用：所有的选项在消息主体的 HTML 页面中列出。鼓励在 Link 标头中加入机器可读的 rel=alternate
304	Not Modified	发送用于重新验证的条件请求。表示缓存的响应仍然是新的并且可以使用。

指定重定向的其他方式:
HTTP 重定向不是定义重定向的唯一方法。还有两个:
借助 HTML 的 <meta> 元素的 HTML 重定向机制
借助 DOM 的 JavaScript 重定向机制。

HTML 重定向机制:
HTTP 重定向是创建重定向的最佳方式，但是有时候你并不能控制服务器。针对这些特定的应用情景，可以尝试在页面的 <head> 中添加一个 <meta> 元素，并将其 http-equiv 属性的值设置为 refresh。
当显示页面的时候，浏览器会检测该元素，然后跳转到指定的页面。
<head>
  <meta http-equiv="Refresh" content="0; URL=http://example.com/" />
</head>
content 属性的值开头是一个数字，指示浏览器在等待该数字表示的秒数之后再进行跳转。建议始终将其设置为 0 来获取更好的无障碍体验。
显然，该方法仅适用于 HTML 页面（或类似的页面），然而并不能应用于图片或者其他类型的内容。

JavaScript 重定向机制:
在 JavaScript 中，重定向机制的原理是设置 window.location 的属性值，然后加载新的页面。
window.location = "https://example.com/";
与 HTML 重定向机制类似，这种方式并不适用于所有类型的资源，并且显然只有在执行 JavaScript 的客户端上才能使用。另外一方面，它也提供了更多的可能性：比如在只有满足了特定的条件的情况下才可以触发重定向机制的场景。

优先级:
由于存在上述三种 URL 重定向机制，那么在多种方法同时设定的情况下，哪种方法会首先起作用呢？
HTTP 协议的重定向机制永远最先触发——它们甚至在没有传输页面的情况下就已经存在。
HTML 的重定向机制 (<meta>) 会在没有任何 HTTP 协议重定向的情况下触发。
JavaScript 的重定向机制总是作为最后诉诸的手段，并且只有在客户端开启了 JavaScript 的情况下才起作用。

应用场景:
有以下几种应用场景可以使用重定向机制，但是需要注意应该尽可能地限制其使用数量，因为每一次重定向都会带来性能上的开销。
1.域名别称
理想情况下，一项资源只有一个访问位置，也就是只有一个 URL。但是由于种种原因，需要为资源设定不同的名称:
扩大站点的用户覆盖面
一个常见的场景是，假如站点位于 www.example.com 域名下，那么通过 example.com 也应该可以访问到。这种情况下，可以建立从 example.com 的页面到 www.example.com 的重定向。此外还可以提供你域名常见的同义词，或者该域名容易导致的拼写错误的别称来重定向到你的网站。
迁移到新的域名
例如，公司改名后，你希望用户在搜索旧名称的时候，依然可以访问到应用了新名称的站点。
强制使用 HTTPS
对你网站的 http:// 版本的请求将重定向到你网站的 https:// 版本。

2.保持链接有效
当你重构 Web 站点的时候，资源的 URL 会发生改变。即便是你更新站点内部的链接来匹配新的 URL，也无法控制被外部资源使用的 URL。
你并不想因此而使旧链接失效，因为它们会为你带来宝贵的用户并且帮助优化你的 SEO，所以需要建立从旧链接到新链接的重定向映射。

3.对于不安全请求的临时响应
不安全的请求会修改服务器端的状态，应该避免用户无意的重复发送它们。
通常，你并不想要你的用户重复发送 PUT、POST 或 DELETE 请求。假如你为该类请求返回响应的话，简单地点击刷新按钮就会导致请求的重复发送（可能在确认消息之后）。
在这种情况下，服务器可以为 URL 发回一个 303（See Other）响应，其中含有正确的响应信息。如果刷新按钮被点击的话，只会导致该页面被刷新，而不会重复提交不安全的请求。

4.对于耗时请求的临时响应
一些请求的处理会需要比较长的时间，比如有时候 DELETE 请求会被安排为稍后处理。
在这种情况下，会返回一个 303（See Other）重定向响应，该响应链接到一个页面，表示请求的操作已经被列入计划，并且最终会通知用户操作的进展情况，或者允许用户将其取消。
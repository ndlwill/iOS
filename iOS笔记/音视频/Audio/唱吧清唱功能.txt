https://www.jianshu.com/p/e5df9ad08303

在iOS上多媒体的处理主要依赖的是AVFoundation框架，而AVFoundation是基于CoreAudio、CoreVideo、CoreMedia、CoreAnimation之上高层框架，在AVFoundation框架之上苹果还提供给我们更高层一些处理媒体数据的框架。

AVAudioEngine:
AVAudioEngine是Objective-C的音频API接口，具有低延迟(low-latency)和实时(real-time)的音频功能，并且具有如下特点：
读写所有Core Audio支持的格式音频文件
播放和录音使用 (files) 和音频缓冲区 (buffers)
动态配置音频处理模块 (audio processing blocks)
可以进行音频挖掘处理 (tap processing)
可以进行立体声音频信号混合和3d效果的混合
音乐设备数字接口MIDI 回放和控制，通过乐器的采样器


AVAudioEngine的工作原理可以简单的分为三个部分
AVAudioEngine的每一步操作都是一个音频操作节点(Node)，每个完整的操作都包含输入节点和输出节点以及经中间的若干个处理节点，包括但不限于，添加音效、混音、音频处理等。
整体的流程和GPUImage的流程差不多，都是链式结构，通过节点来链接成一个完整的流水线，其中每个节点都有自己特有的属性，可以通过改变属性的值来改变经由该节点后的音频输出效果


原理:
清唱的功能很简单，就是通过麦克风录制声音，然后添加音效或者做一些处理之后再输出，因为不要配乐，但是有一个问题就是耳返，也叫返送.
这个东西是必不可少的，因为有了耳返你就可以实时调整自己的声音，极大的降低了走调的风险和尴尬


唱吧清唱使用的是AudioUnit
声音（Sound），是由物体的振动产生的。一切正在发声的物体都在振动。

我们说话的时候，是声带在振动

蜜蜂飞过时发出嗡嗡嗡的声音，是翅膀在快速振动

声音的本质:
https://www.khanacademy.org/science/high-school-physics/x2a2d643227022488:waves/introduction-to-sound/v/production-of-sound

扬声器发声时是振膜在振动
振膜的振动会导致振膜旁边的空气振动，然后导致更大范围的空气跟着一起振动，最后耳朵旁边的空气也开始振动。
空气的振动带来了动能（Kinetic Energy），能量传入了耳朵中，最后就听到了声音。
所以，扬声器可以通过空气来传播能量，而不是传播空气本身。
如果传播的是空气，那么表现出来的形式就不是声音，而是风（Wind）。
声音与波有着相同的关键特征：可以通过介质传播能量，而不是传播介质本身。
我们也把声音称为声波

声音的传播介质可以是气体、液体、固体，比如:
2个人面对面交流时，声音是通过空气传播到对方耳中

人耳又是如何听到声音的呢？大概过程是:
声源 → 耳廓（收集声波） → 外耳道（传递声波） → 鼓膜（将声波转换成振动） → 听小骨（放大振动） → 耳蜗（将振动转换成电信号） → 听觉神经（传递电信号） → 大脑（形成听觉）

振幅:
如果只关注单个空气分子，可以发现：它来回振动的轨迹，就是一个正弦或余弦函数的曲线图。
横轴：代表时间。（对于上面的振幅而言，x轴）
纵轴：代表空气分子来回振动时产生的位移。
（平衡位置，Equilibrium Position，即x轴）：代表该空气分子的未受振动干扰时的位置。
从平衡位置到最大位移位置之间的距离，叫做振幅（Amplitude）。即0到1或者0到-1，即1


周期：
空气分子完全来回振动一次所花费的时间，叫做周期（Period），单位是秒（s）。即经历两个波峰之间所花费的时间


频率：
物体每秒来回振动的次数，叫做频率（Frequency），也就是周期分之一。
单位是秒分之一（1/s），也称为赫兹（Hz）
比如440Hz代表物体每秒来回振动440次
因此，频率用来表示物体振动的快慢

理论上，人类的发声频率是85Hz ~ 1100Hz，人类只能听见20Hz ~ 20000Hz之间的声音。
低于20Hz的称为：次声波（Infrasound）
高于20000Hz的称为：超声波（Ultrasound）

音调：
频率越高，音调就越高
频率越低，音调就越低

响度：
当提高声音的响度（音量，大小）时，振动的幅度会变大
我们常用dB（分贝）来描述声音的响度
分贝	情景
0	刚能听到的声音
15以下	感觉安静
30	耳语的音量大小
40	冰箱的嗡嗡声
60	正常交谈的声音
70	相当于走在闹市区
85	汽车穿梭的马路上
95	摩托车启动声音
100	装修电钻的声音
110	卡拉OK、大声播放MP3的声音
120	飞机起飞时的声音
150	燃放烟花爆竹的声音


音色：
音色（Timbre）是指声音的特色。
不同的声源由于其材料、结构不同，则发出声音的音色也不同
我们之所以能够根据声音区分出不同的乐器、不同的人，都是因为它们的音色不同
不同音色的声音，即使在同一响度和同一音调的情况下，也能让人区分开来
微信的声音登录功能，就是基于不同人不同音色的原理，为每一个人私人定制一把声音锁。
原理：
通常声源的振动产生的并不是单一频率的声波，而是由基音和不同频率的泛音组成的复合声音。
当声源的主体振动时会发出一个基音（基本频率，基频，Fundamental Frequency）
同时其余各部分也有复合的声源，这些声源组合产生泛音
泛音（Overtone）其实就是物理学上的谐波（Harmonic）

音调是由基音决定的，而音色主要取决于泛音。
音色不同，波形也就不同。
声音的最终波形是由多个不同的波形组合而成的

噪音：
从物理学角度上讲，噪音（噪声，Noise），是指声源作无规则振动时发出的声音（频率、强弱变化无规律）。


PCM:
录音的原理可以简单理解为：把声源的振动记录下来，需要时再让某个物体按照记录下来的振动规律去振动，就会产生与原来一样的声音。

如何把声音（声源的振动）记录下来呢？声音属于模拟信号，但更便于计算机处理和存储的是数字信号（二进制编码），所以需要将模拟信号（Analog Signal）转成数字信号（Digital Signal）后进行存储。
这一过程，我们可以称之为：音频数字化。


将音频数字化的常见技术方案是脉冲编码调制（PCM，Pulse Code Modulation），主要过程是：采样 → 量化 → 编码。

采样:
模拟信号的波形是无限光滑的，可以看成由无数个点组成，由于存储空间是相对有限的，数字编码过程中，必须要对波形的点进行采样。
采样（Sampling）：每隔一段时间采集一次模拟信号的样本，是一个在时间上将模拟信号离散化（把连续信号转换成离散信号）的过程。

采样率:
每秒采集的样本数量，称为采样率（采样频率，采样速率，Sampling Rate）。比如，采样率44.1kHz表示1秒钟采集44100个样本。

采样定理:
https://zh.wikipedia.org/wiki/%E9%87%87%E6%A0%B7%E5%AE%9A%E7%90%86
根据采样定理（奈奎斯特–香农采样定理，Nyquist-Shannon sampling theorem）得知：
只有当采样率高于声音信号最高频率的2倍时，才能把采集的声音信号唯一地还原成原来的声音。
人耳能够感觉到的最高声音频率为20000Hz，因此为了满足人耳的听觉要求，需要至少每秒进行40000次采样（40kHz采样率）。
这就是为什么常见的CD的采样率为44.1kHz。电话、无线对讲机、无线麦克风等的采样率是8kHZ。


量化:
量化（Quantization）：将每一个采样点的样本值数字化。

位深度:
位深度（采样精度，采样大小，Bit Depth）：
使用多少个二进制位来存储一个采样点的样本值。
位深度越高，表示的振幅越精确。
常见的CD采用16bit的位深度，能表示65536（216）个不同的值。
DVD使用24bit的位深度，大多数电话设备使用8bit的位深度。


编码
编码：将采样和量化后的数字数据转成二进制码流。

声道（Channel）:
单声道产生一组声波数据，双声道（立体声）产生两组声波数据。
采样率44.1kHZ、位深度16bit的1分钟立体声PCM数据有多大？
采样率 * 位深度 * 声道数 * 时间
44100 * 16 * 2 * 60 / 8 ≈ 10.34MB

1分钟10.34MB，这对于大部分用户来说是不能接受的。要想在不改变音频时长的前提下，降低音频数据的大小，只有2种方法：
降低采样指标、压缩。
降低采样指标是不可取的，会导致音频质量下降，用户体验变差，因此专家们研发了各种压缩方案。


比特率:
比特率（Bit Rate），指单位时间内传输或处理的比特数量，单位是：
比特每秒（bit/s或bps）
还有：千比特每秒（Kbit/s或Kbps）
兆比特每秒（Mbit/s或Mbps）
吉比特每秒（Gbit/s或Gbps）
太比特每秒（Tbit/s或Tbps）。

采样率44.1kHZ、位深度16bit的立体声PCM数据的比特率是多少？
采样率 * 位深度 * 声道数
44100 * 16 * 2 = 1411.2Kbps

通常，采样率、位深度越高，数字化音频的质量就越好。
从比特率的计算公式可以看得出来：比特率越高，数字化音频的质量就越好。

信噪比:
信噪比（Signal-to-noise ratio，SNR，S/N，讯噪比），指信号与噪声的比例，用于比较所需信号的强度与背景噪声的强度，以分贝（dB）为单位。
位深度限制了信噪比的最大值



音频的编码与解码:
编码（Encode）
PCM数据可以理解为是：未经压缩的原始音频数据，体积比较大，为了更便于存储和传输，一般都会使用某种音频编码对它进行编码压缩，然后再存成某种音频文件格式。

压缩分为无损压缩和有损压缩。
无损压缩:
解压后可以完全还原出原始数据
压缩比小，体积大

有损压缩:
解压后不能完全还原出原始数据，会丢失一部分信息
压缩比大，体积小
压缩比越大，丢失的信息就越多，还原后的信号失真就会越大
一般是通过舍弃原始数据中对人类听觉不重要的部分，达成压缩成较小文件的目的

压缩比 = 未压缩大小 / 压缩后大小


解码（Decode）:
当需要播放音频时，得先解码（解压缩）出PCM数据，然后再进行播放。

常见的音频编码和文件格式:
需要注意的是：音频文件格式并不等于音频编码。比如：
WAV只是一种文件格式，并不是一种编码
FLAC既是一种文件格式，又是一种编码

无损:
Monkey's Audio
Monkey's Audio，是一种无损的音频编码和文件格式，文件扩展名为 .ape，压缩率一般在55%左右。

FLAC
FLAC（Free Lossless Audio Codec），是一种无损的音频编码和文件格式，文件扩展名为 .flac。虽然压缩率稍有不及Monkey's Audio，但FLAC技术更先进，占用资源更低，有更多的平台及硬件产品支持FLAC。

ALAC
ALAC（Apple Lossless Audio Codec），是由Apple开发的一种无损的音频编码，文件扩展名为 .m4a、.caf。

有损:
MP3
MP3（MPEG Audio Layer III），是非常流行的一种有损音频编码和文件格式，文件扩展名为 .mp3。
第1版是：MPEG-1 Audio Layer III，属于国际标准ISO/IEC 11172-3 // https://www.iso.org/standard/22412.html
第2版是：MPEG-2 Audio Layer III，属于国际标准ISO/IEC 13818-3
第3版是：MPEG-2.5 Audio Layer III，并不是由MPEG官方开发的，不是公认的标准

WMA
WMA（Windows Media Audio），是由Microsoft开发的音频编码和文件格式，文件扩展名为**.wma**。包括4种类型：
WMA：原始的WMA编解码器，作为MP3的竞争者，属于有损音频编码
WMA Pro：支持更多声道和更高质量的音频，属于有损音频编码
WMA Lossless：属于无损音频编码
WMA Voice：属于有损音频编码

AAC
AAC（Advanced Audio Coding），是由Fraunhofer IIS、杜比实验室、AT&T、Sony、Nokia等公司共同开发的有损音频编码和文件格式，压缩比通常为18:1。
AAC被设计为MP3格式的后继产品，通常在相同的比特率下可以获得比MP3更高的声音质量，是iPhone、iPod、iPad、iTunes的标准音频格式。
AAC编码的文件扩展名主要有3种：
.acc：传统的AAC编码，使用MPEG-2 Audio Transport Stream（ADTS）容器
.mp4：使用了MPEG-4 Part 14的简化版即3GPP Media Release 6 Basic（3gp6）进行封装的AAC编码
.m4a：为了区别纯音频MP4文件和包含视频的MP4文件而由Apple公司使用的扩展名
Apple iTunes对纯音频MP4文件采用了**.m4a**文件扩展名
M4A的本质和音频MP4相同，故音频MP4文件可以直接更改文件扩展名为**.m4a**

Vorbis
Vorbis，是由Xiph.Org基金会开发的一种有损音频编码。通常以Ogg作为容器格式，所以常合称为Ogg Vorbis，文件扩展名为 .ogg 。

Speex
Speex，是由Xiph.Org基金会开发的一种有损音频编码和文件格式，文件扩展名为 .spx。

Opus
Opus，是由Xiph.Org基金会开发的一种有损音频编码和文件格式，文件扩展名为 .opus 。
用以取代Vorbis和Speedx。经过多次盲听测试，在任何给定的比特率下都比其他标准音频格式具有更高的质量，包括MP3、AAC。


文件格式：
Ogg
Ogg是一种多媒体文件格式，由Xiph.Org基金会所维护，可以纳入各式各样的音视频编码（音频、视频都可以），文件扩展名常为 .ogg。
Ogg常用的音频编码有：
有损压缩：Speex、Vorbis、Opus
无损压缩：FLAC
未压缩：PCM

WAV
WAV（Waveform Audio File Format），是由IBM和Microsoft开发的音频文件格式，扩展名是 .wav，通常采用PCM编码，常用于Windows系统中。
WAV的文件格式，前面有44个字节的文件头，紧跟在后面的就是音频数据（比如PCM数据）。
NumChannels：声道数
SampleRate：采样率（Hz）
ByteRate：每秒多少个字节（Byte/s）
BitsPerSample：位深度

AIFF
AIFF（Audio Interchange File Format），由Apple开发的音频文件格式，扩展名是 .aiff 、.aif。跟WAV一样，通常采用PCM编码，常用于Mac系统中。


根据采样率和位深度可以得知：相对于自然界的信号，音频编码最多只能做到无限接近，任何数字音频编码方案都是有损的，因为无法完全还原。
目前能够达到最高保真水平的就是PCM编码，因此，PCM约定俗成叫做 无损 音频编码，被广泛用于素材保存及音乐欣赏，CD、DVD以及常见的 WAV 文件中均有应用。
但并不意味着PCM就能够确保信号绝对保真，PCM也只能做到最大程度的无限接近。我们习惯性的把MP3列入有损音频编码范畴，是相对于PCM编码的。
要做到真正的无损是困难的，就像用数字去表达圆周率，不管精度多高，也只是无限接近，而不是真正等于圆周率的值。
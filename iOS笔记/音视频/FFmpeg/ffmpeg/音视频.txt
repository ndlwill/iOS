协议层（Protocol Layer）：该层处理的数据为符合特定流媒体协议规范的数据，例如http，rtmp，file等；
封装层（Format Layer）：该层处理的数据为符合特定封装格式规范的数据，例如mkv，mp4，flv，mpegts，avi等；
编码层（Codec Layer）：该层处理的数据为符合特定编码标准规范的数据，例如h264，h265，mpeg2，mpeg4等；
像素层（Pixel Layer）：该层处理的数据为符合特定像素格式规范的数据，例如yuv420p，yuv422p，yuv444p，rgb24等；


I帧是关键帧，解码时只需要本帧数据；
P帧是参考帧，表示这一帧与前一个关键帧（或P帧）的差别；
B帧是双向参考帧，表示本帧与前后帧的差别；（B帧压缩率高，解码复杂，直播中较少用）
IDR帧是第一个I帧，为的是和其他I帧区别开，方便控制编码和解码；
IDR会导致DPB（DecodedPictureBuffer 参考帧列表）清空，而I不会。
GOP（Group Of Picture）是图像组，是一组连续的画面；（直播实现秒开，关键就是CDN节点缓存GOP，编码器拿到第一个GOP后马上解码播放）
帧内压缩：当压缩一帧图像时，仅考虑本帧的数据而不考虑相邻帧之间的冗余信息；（帧内压缩一般达不到很高的压缩，跟编码jpeg差不多）
帧间压缩：利用相邻帧的相关性提高压缩量，减少冗余；（运动补偿和运动估计是常用的技术）

编码顺序
简单描述下编码的过程，假设我们处理的第一帧是DIR帧：
编码IDR帧
根据scenecut 和 min-keyint的设置，向后移动 min-keyint的距离，开始判定是否为scenechange，直到判定满足，或者到达keyint设置值的距离时候停止。同时记录判定条件不完全满足时候的位置。
编码找到的为指针，亦为IDR帧,GOP形成。
根据2步中得到的判定条件不完全满足的位置，将对应帧按时间顺序用I编码。
找到最头上IDR和离其最近的I帧形成的Sub-GOP（严格意义上说此处并非GOP因为GOP之间不能交换信息，）结合bframes的设定大小，推断P帧出现的位置。具体而言，按时间顺序走每一帧比较该帧用P编码和B编码时的视觉误差和复杂度何者更大，根据某些公式推导出此处应该用何种帧类型，再向后移一帧；如果直到bframes规定的值都未出现P，则强制插入一帧P。这样就决定了每个sub-GOP内P帧的位置。
最后一步，根据I/IDR/P形成的子区间，按时间顺序编码各帧为B帧。
举例：100-120帧这样的一段视频
第一步结束后编码完成 100帧
第二步结束后可能编码完成 120帧和110帧 （IDR帧）同时找出了104，108, 115帧应该编码为I
第四步结束后编码完成104 108 115 帧为I
第五步对 100-104 104- 108 108-110 110 – 115 115-120五个子区间，判断P帧出现的位置并编码有可能判断出102 113 118 为p帧
最后一步在编码之间的部分为B帧
于是解码过程的输出帧顺序其实是
100 110 104 108 102 101 103 105 106 109….


原始H.264码流包装成CMSampleBuffer时，我们可以按照以下步骤：（编码后的数据）
1、替换头字节长度；
2、用CMBlockBuffer把NALUnit包装起来；
3、把SPS和PPS包装成CMVideoFormatDescription；
4、添加CMTime时间；
5、创建CMSampleBuffer；

视频码率是视频数据（视频色彩量、亮度量、像素量）每秒输出的位数。一般用的单位是kbps。
由于不同的系统会有不同的模式，为了统一，规定在网络传输中使用大端模式，这就是网络字节序。



录制的aac音频和h264可以很方便的打包成mp4
ffmpeg -i abc.h264 -i abc.aac -vcodec copy -f mp4 abc.mp4
//
//  ViewController.swift
//  TestMetal
//
//  Created by youdun on 2023/8/24.
//

import UIKit
import Metal

// MARK: -
/**
 1.
 "render pass"（渲染通道）和 "render pipeline"（渲染管线）是两个不同但密切相关的概念，用于实现图形渲染。

 Render Pass (渲染通道)：
 渲染通道是指一系列的##图形渲染操作##，这些操作通常在一个渲染目标上执行，如屏幕或纹理。渲染通道中包含的操作可以包括清除渲染目标、设置视口（viewport）、设置裁剪区域等。
 渲染通道还包括渲染命令的执行，这些命令描述了渲染过程中所需的绘制操作，如绘制三角形、绘制线条等。这些命令可以包含多个绘制操作，以及与绘制操作相关的资源和状态设置。
 渲染通道可以用于将多个绘制操作合并为一个渲染过程，从而提高渲染效率。在 Metal 中，渲染通道通过 MTLRenderPassDescriptor 来描述，并且在命令缓冲区中提交。
 
 Render Pipeline (渲染管线)：
 渲染管线是一系列的##图形处理阶段##，用于将输入数据转换为最终的图像输出。在渲染管线中，数据经过顶点输入、顶点着色、裁剪、图元组装、几何着色、光栅化、片段着色等多个阶段的处理。
 渲染管线包括两个主要部分：图形管线（Graphics Pipeline）和计算管线（Compute Pipeline）。图形管线用于渲染三维图形，而计算管线用于通用计算。
 渲染管线的配置通过 MTLRenderPipelineDescriptor 来定义，它包括了各个阶段的着色器程序、资源配置、混合模式等信息。
 
 综上所述，渲染通道是执行渲染操作的一系列步骤，包括命令的执行和资源的配置，而渲染管线是一系列的图形处理阶段，负责将输入数据转换为最终的图像输出。这两个概念共同构成了 Metal 图形编程中的核心部分。
 
 2.
 ".tga" 是 ".Targa" 或 "Truevision TGA" 的缩写，是一种图像文件格式
 TGA 文件格式是一种比较老旧的格式，最初由 Truevision 开发，用于存储位图图像数据。
 
 3.
 TGA 文件头部包含了关于图像的元数据，如图像的宽度、高度、颜色深度等信息。通常，TGA 文件的前面一部分是这些头部信息。
 这些信息的具体解析和存储方式取决于 TGA 文件的版本和子类型。
 如果你需要处理 TGA 文件，需要根据 TGA 文件的规范来解析头部信息，以获得有关图像的各种属性。
 
 4.
 位图图像数据（Bitmap Image Data）是一种用于表示图像的数据格式，也称为栅格图像（Raster Image）。
 它是图像的一种基本表示方式，将图像分割成像素（或称为图像元素），并为每个像素分配颜色值。每个像素都是图像中最小的可见单元。

 位图图像数据通常以二维矩阵的形式表示，其中每个元素对应一个像素，并存储了该像素的颜色信息。
 颜色信息可以使用不同的方式表示，取决于图像的颜色深度。以下是几种常见的位图图像数据的表示方式：
 黑白图像：在黑白图像中，每个像素只有两种状态：黑色和白色。每个像素可以使用一个位（0或1）来表示。
 灰度图像：在灰度图像中，每个像素的颜色用一个灰度值来表示，通常是一个介于0到255之间的整数。
 真彩色图像：在真彩色图像中，每个像素的颜色由红、绿、蓝三个分量组成。每个分量通常使用一个8位的整数来表示，因此可以表示256个不同的强度值，从而可以组合出数百万种颜色。
 RGBA图像：在RGBA图像中，每个像素的颜色由红、绿、蓝三个分量和一个透明度分量（Alpha通道）组成。Alpha通道决定了像素的透明度，从而可以实现图像的透明效果。
 */

// MARK: - 多重采样（Multisampling）
/**
 多重采样（Multisampling）是一种图形渲染技术，用于改善图像的边缘平滑和减少锯齿效应，同时提升渲染的视觉质量。
 多重采样通过在像素级别上对颜色和深度信息进行采样，从而在渲染中消除或减轻锯齿和混叠等问题。

 在传统的单重采样渲染中，每个像素只有一个颜色和深度值。
 当多个几何体或图像被渲染到同一个像素时，可能会出现锯齿效应，也称为走样（aliasing）。
 多重采样通过在像素内部进行多次子采样，即在一个像素内部的不同位置对颜色和深度值进行采样，然后对这些采样结果进行合并，以获得更平滑的边缘和更准确的深度信息。

 多重采样的主要优点包括：
 抗锯齿： 多重采样可以有效地减少锯齿效应，使得边缘变得更加平滑，从而提升渲染图像的视觉质量。
 减少混叠： 多重采样可以降低混叠（Z-fighting）现象的发生，深度测试更准确，从而避免近似深度值导致的问题。
 视觉质量提升： 多重采样可以改善渲染图像的视觉效果，使图像看起来更加真实和自然。

 在使用多重采样时，开发人员需要在渲染管线中进行适当的设置和配置，以便正确地启用和配置多重采样技术。
 
 "16x16 subpixels" 意味着将一个像素分成 16x16 个小的子像素格子，以获得更精细的渲染效果。
 在图形渲染中，为了提高图像的视觉质量和平滑度，有时会将一个像素进一步细分为多个子像素，然后对这些子像素进行更精细的处理和渲染。
 通常情况下，一个像素在屏幕上显示为一个小的方块，其中包含一个或多个子像素。通过将一个像素细分为更小的子像素，可以在渲染过程中进行更精确的颜色和深度采样，从而提高图像的视觉质量，减少锯齿效应以及改善平滑度。
 在一些多重采样（Multisampling）技术中，像素可以被分割成多个子像素，并在每个子像素位置进行多次采样，然后合并这些采样结果，以达到更高的抗锯齿效果。这也可以应用于一些渲染技术，如抗锯齿、细节渲染等。
 */

// MARK: - "Pipeline render targets"（管线渲染目标）
/**
 "Pipeline render targets"（管线渲染目标）是指在图形渲染中，将渲染结果输出到的一组目标缓冲区或纹理。
 在渲染管线中，渲染目标是指用于存储渲染结果的图像、缓冲区或纹理，可以包括颜色附件、深度附件、模板附件等。

 通常情况下，渲染管线的最终结果会被输出到一个或多个渲染目标中，这些渲染目标一起组成了所谓的"pipeline render targets"。
 每个渲染目标都可以配置为存储不同类型的渲染结果，例如颜色、深度、模板等信息。

 在现代图形编程中，特别是在API（如Metal、Vulkan、DirectX）中，开发人员可以配置渲染管线以输出到不同的渲染目标，实现多重渲染目标（MRT，Multiple Render Targets）等技术。
 通过合理地配置管线渲染目标，开发人员可以实现多种效果，例如深度信息的捕捉、后期处理效果的组合等。

 总之，"pipeline render targets" 是指在图形渲染中，将渲染结果输出到的一组目标缓冲区或纹理，用于控制渲染管线的输出和实现不同的渲染效果。
 */

// MARK: - Mipmap（又称为纹理金字塔）
/**
 Mipmap 是一系列不同分辨率的纹理图像，从原始纹理图像开始，逐步减小分辨率，形成金字塔状结构。
 
 Mipmap 的主要目的是解决纹理映射时的采样问题。
 当一个纹理图像被映射到一个较大或较小的区域时，通常会产生纹理采样的不连续性，导致锯齿效应、失真和过滤问题。
 Mipmap 通过提供多个不同分辨率的图像，可以让采样时选择最合适的纹理级别，从而在不同的情况下获得更平滑的过渡和更准确的渲染结果。
 
 Mipmap 的构建过程通常是通过将原始纹理图像进行连续的缩小操作，每次缩小一半，直到达到某个最小分辨率。
 这些缩小后的图像就形成了 Mipmap 级别。
 当渲染对象距离摄像机较远时，可以使用较低分辨率的 Mipmap 级别，从而减少纹理采样的计算量。
 而当对象接近摄像机时，可以使用更高分辨率的 Mipmap 级别，获得更细节的纹理映射。
 
 在渲染时，GPU 可以根据纹理采样的情况自动选择合适的 Mipmap 级别。
 这种自动选择可以通过纹理坐标的变化来实现，距离摄像机较远时使用较低级别，距离较近时使用较高级别。

 总之，Mipmap 是一种用于提高纹理映射性能和质量的技术，通过构建一系列不同分辨率的纹理图像，可以在不同距离和尺寸下获得更平滑和准确的纹理映射效果。
 */

// MARK: - 渲染目标
/**
 渲染目标通常指的是帧缓冲区（Frame Buffer），它是图形渲染中用于存储渲染结果的一种数据结构。
 
 在图形渲染过程中，渲染目标用于存储像素的颜色、深度和模板等信息。
 渲染目标可以是一张纹理、一个缓冲区，或者是屏幕上的一部分（例如帧缓冲区中的一块区域）。
 渲染目标通常由图形渲染管线中的渲染流程（render pass）指定。
 
 帧缓冲区（Frame Buffer）是最常见的一种渲染目标，它是一个内存区域，用于存储渲染结果的像素数据。
 帧缓冲区通常包括颜色缓冲区（用于存储像素颜色值）、深度缓冲区（用于存储像素的深度值）和模板缓冲区（用于存储像素的模板值）。
 渲染到帧缓冲区后，可以将帧缓冲区的内容显示在屏幕上，或者用作后续渲染步骤的输入。
 */

// MARK: - 像素的模板值（Stencil Value）
/**
 用于在模板测试（Stencil Test）中进行判断和控制。模板测试是渲染管线中的一个阶段，用于根据模板值来决定是否允许像素通过渲染。
 
 模板值是一个单一的整数值，通常存储在模板缓冲区（Stencil Buffer）中。
 模板缓冲区是一种与颜色缓冲区和深度缓冲区类似的缓冲区，用于存储像素的模板值。
 每个像素对应一个模板值，这个值可以在渲染过程中被设置、读取和比较。
 
 在模板测试阶段，GPU 可以根据像素的模板值执行不同的操作，如增加、减少或保持模板值，或者根据模板值决定是否绘制像素。
 这使得开发人员可以实现一些特殊的渲染效果和控制逻辑，例如轮廓绘制、镂空效果、遮罩和模型剪裁等。
 
 模板测试通常与深度测试（Depth Test）和颜色混合（Color Blending）等渲染阶段一起使用，以实现复杂的渲染效果。
 模板测试的具体操作和效果会根据应用程序的需要而有所不同，开发人员可以根据模板值的比较结果来决定是否绘制像素、更新模板值或执行其他操作。
 
 总之，像素的模板值是存储在模板缓冲区中的整数值，用于在渲染管线的模板测试阶段决定像素是否通过渲染以及执行什么样的操作。
 */

// MARK: - 709 luma values
/**
 "709 luma values" 指的是 Rec. 709 色彩空间中的亮度（luma）值。
 Rec. 709，也称为 BT.709 或 ITU-R BT.709，是一种广泛用于高清电视和高清视频的标准色彩空间。
 在这个标准中，定义了一组亮度值（luma values）用于将颜色转换为灰度值，从而创建黑白图像。
 
 亮度值（luma values）通常是由彩色分量按照一定的权重组合而成的。在 Rec. 709 中，通常采用以下权重来计算亮度值：
 红色分量的权重：0.2126
 绿色分量的权重：0.7152
 蓝色分量的权重：0.0722
 计算公式为：Y = 0.2126 * R + 0.7152 * G + 0.0722 * B
 
 其中，Y 表示亮度值，R、G 和 B 分别表示红色、绿色和蓝色分量的值。
 通过使用这些权重，可以将彩色图像中的颜色信息转换为灰度图像，从而保留了亮度信息，同时舍弃了颜色信息。

 Rec. 709 luma values 在视频处理、色彩转换、图像编辑等领域中广泛用于将彩色图像转换为灰度图像，或者用于执行亮度相关的操作。
 */

// MARK: - 线程网格
/**
 "grid of threads"（线程网格）是指一组并行执行的线程，它们一起协同工作以完成并行计算任务。
 线程网格通常用于执行大规模的计算，例如在图像处理、物理模拟、计算机图形学等领域。
 
 在 Metal 中，计算任务通常是由一组线程协同完成的。这组线程被组织成一个三维的网格，称为线程网格。
 线程网格具有三个维度：X、Y 和 Z。每个维度上都有一个特定的范围，决定了每个维度上的线程数量。
 X 维度表示水平方向的线程数量。
 Y 维度表示垂直方向的线程数量。
 Z 维度表示深度方向的线程数量。
 这种线程网格的组织方式使得开发人员可以同时并行地处理多个计算任务，从而充分利用 GPU 的并行计算能力。
 
 例如，假设我们要对一组图像进行滤波操作，可以将每个像素作为一个计算任务，并将像素组织成线程网格。
 每个线程将处理一个像素的计算任务，而整个线程网格将并行地处理整个图像。
 */

// MARK: - 光栅化（Rasterization）
/**
 它是将矢量图形转换为栅格图像或像素的过程。
 这个过程是从图形的数学表示到实际屏幕上可见的像素表示的关键步骤之一。
 以下是关于光栅化的一些重要信息：
 
 从矢量到像素： 在计算机图形中，图形通常是以矢量形式表示的，这意味着它们由数学公式、线段、多边形等几何元素构成。
 然而，屏幕上的图像是由像素组成的，光栅化的任务就是将这些矢量图形转换为像素图像。
 
 扫描转换： 光栅化过程通常包括扫描转换（Scan Conversion）步骤。在扫描转换中，计算机将图形分割成小区域，然后决定哪些区域包含在最终的像素图像中。
 这个过程涉及到检查每个像素是否在图形内部或边界上。

 颜色填充： 一旦决定了每个像素是否包含在图像中，光栅化会决定每个像素的颜色。
 这通常涉及到在图形的纹理映射、着色和光照模型的基础上为每个像素分配一个颜色值。

 硬件加速： 光栅化通常在图形硬件中实现，以加速图形渲染过程。
 图形处理单元（GPU）在光栅化过程中发挥了重要作用，它可以同时处理大量的像素。

 消除隐藏表面： 光栅化还包括消除隐藏表面（Hidden Surface Removal）的步骤，以确定哪些图形在屏幕上是可见的，哪些是被其他图形遮挡的。

 Antialiasing： 为了减少锯齿状边缘（Jaggies）和伪影（Artifacts）等图像问题，光栅化还可以包括抗锯齿（Antialiasing）技术，用于平滑边缘和过渡区域。
 
 光栅化是计算机图形学中的一个关键步骤，它将矢量图形转换为像素图像，并包括扫描转换、颜色填充、隐藏表面消除等过程，以确保图形在屏幕上以最佳方式呈现。
 */

// MARK: - Pixels blit
/**
 "Pixels blit" 是一个计算机图形和图像处理领域的术语，通常指的是将一个像素或一组像素从一个图像复制到另一个图像的操作。
 "Blit" 是 "Bit Block Transfer" 的缩写，表示在图像处理中执行位块传输操作。
 
 "Pixels blit" 可以包括以下操作：
 复制（Copy）： 将一个图像的像素精确地复制到另一个图像上，通常是一对一的像素复制，无缩放或变换。
 缩放（Scale）： 将一个图像的像素按比例缩小或放大，以适应另一个图像的尺寸。
 透明度合成（Alpha Composition）： 在复制像素时，考虑像素的透明度信息，实现图像的混合或透明度融合效果。
 翻转和旋转（Flip and Rotate）： 将像素在水平或垂直方向上翻转，或按一定角度旋转。
 颜色映射（Color Mapping）： 在复制像素时，对颜色进行映射或转换，以实现色彩效果的改变。
 蒙版操作（Masking）： 使用蒙版（掩码）来控制哪些像素被复制到目标图像中。
 
 "Pixels blit" 是在图像编辑、图像合成、图像处理以及计算机游戏开发等领域常见的操作。
 它允许将不同图像元素组合在一起，创建新的图像效果或合成多个图像层，是图像处理中的基本操作之一。
 */

// MARK: - Draw call" 和 "Indexed draw call"
/**
 Draw Call（绘制调用）： 在普通的绘制调用中，每个顶点都是独立指定的，也就是说，每个顶点的位置、颜色、法线等信息都需要单独提供。
 这意味着在绘制过程中，会有大量的冗余数据传输，因为相同的顶点可能会在不同的三角形中多次使用。
 优点：易于理解和实现，适用于一些简单的场景。
 缺点：可能导致大量的数据传输和处理，浪费内存和性能。
 
 Indexed Draw Call（索引绘制调用）： 在索引绘制调用中，顶点数据被分成两部分：顶点属性数据和索引数据。
 顶点属性数据包含每个顶点的位置、颜色、法线等信息，而索引数据包含了描述如何连接这些顶点以构建三角形的索引。
 优点：减少了数据传输和存储开销，提高了性能，特别适用于大规模复杂的场景。
 缺点：需要额外的索引数据，稍微复杂一些。
 
 在实际应用中，当要渲染大规模场景或包含重复几何体的场景时，索引绘制通常更为高效，因为它减少了数据传输和存储开销。
 */

// MARK: - packed_float2 和 float2
/**
 packed_float2 和 float2 都是用于存储二维向量数据的类型，但它们之间有一些重要的区别。
 
 内存布局：
 packed_float2 是一种特殊的数据类型，它使用一种更紧凑的内存布局来存储向量数据。
 它将两个浮点数（32位单精度浮点数）紧密地打包在一个 32 位的内存单元中，以减少内存使用。
 float2 是 Metal 中的标准向量类型，它使用标准的 32 位浮点数布局，每个浮点数使用一个 32 位内存单元。
 
 精度：
 由于 packed_float2 使用更紧凑的内存布局，它可能会牺牲一些精度，特别是在对浮点数精度要求较高的情况下。这意味着在某些情况下，packed_float2 可能不适合需要较高精度的计算。
 
 使用场景：
 packed_float2 通常用于需要节省内存的情况，例如在 GPU 编程中，通过减少内存带宽要求来提高性能。
 float2 更适合需要较高精度的情况，例如涉及到几何计算、向量运算或需要高精度浮点数表示的算法中。
 */

// MARK: - mesh
/**
 它用来描述三维物体表面的结构
 一个 "mesh" 通常由多个顶点、边和面组成，用于表示和定义三维物体的外形和拓扑结构。
 
 顶点（Vertices）： 顶点是 "mesh" 的基本构建块，它们是三维空间中的点，通常包括位置坐标（x、y、z）以及可能的其他属性，如法线向量（用于光照计算）、纹理坐标（用于纹理映射）等。

 边（Edges）： 边是连接顶点的线段。它们定义了 "mesh" 的边界和拓扑结构，可以用于计算表面的曲率和平滑度。

 面（Faces）： 面是由多个相邻的顶点和边组成的多边形，通常是三角形或四边形。这些面定义了 "mesh" 的表面，它们决定了物体的外观。三角形是最常见的面类型，因为它们具有简单的拓扑结构和良好的性质，可以方便地进行图形计算和渲染。
 
 "mesh" 的主要作用是描述三维物体的形状和外观，以便计算机图形渲染引擎可以将其显示在屏幕上。
 这些 "mesh" 可以包括各种物体，从简单的几何体（如立方体或球体）到复杂的角色模型、建筑物或风景。
 建模师通常使用专业的建模软件来创建和编辑 "mesh"，然后将其导入到图形渲染引擎中以进行渲染。
 */

// MARK: - Metal
/**
 half4 和 vector_float4:
 用于表示颜色或向量的两种不同数据类型，它们之间的区别在于数据类型和精度：
 half4 使用更低的位数来表示浮点数，以节省存储和计算资源。它通常用于颜色表示，例如红、绿、蓝和透明度（RGBA）值，以及向量运算。half4 的精度相对较低
 vector_float4 使用更多的位数来表示浮点数，以提供更高的精度。它通常用于需要更高精度的计算，例如矩阵变换、物理模拟等。
 */

// MARK: - frames in flight
/**
 在图形学中，"frames in flight" 是一个术语，通常指的是在渲染过程中同时存在于不同阶段的渲染帧的数量。
 这个概念通常与图形渲染管道（Graphics Rendering Pipeline）和并行性有关。
 
 "Frames in flight" 的概念常见于以下情况：
 图形渲染：在图形应用程序中，帧是屏幕上的一个静态图像，通常由多个渲染步骤（例如几何处理、光栅化、着色等）组成。
 为了充分利用多核CPU或GPU的并行性，应用程序可以同时处理多个帧，即多个帧可以在不同的渲染阶段并行进行。
 "Frames in flight" 表示同时存在于不同渲染阶段的帧的数量。这有助于提高渲染性能和帧速率。

 多线程渲染：在一些图形引擎中，为了提高性能，渲染任务可能会并行执行，每个线程处理一个帧的不同部分。
 "Frames in flight" 表示同时由多个线程处理的帧的数量。

 帧同步：在某些情况下，帧需要按特定的顺序进行处理，以确保渲染正确。
 "Frames in flight" 的数量可以受到同步和调度的影响，以确保帧按照正确的顺序渲染。
 
 总之，"frames in flight" 是一个用于描述在图形应用程序中同时处理的帧的数量的概念，通常用于优化渲染性能和管理渲染任务的并行性。
 */

// MARK: - Uniforms
/**
 在图形学中，"Uniforms" 是一种用于将数据从应用程序传递到图形着色器（vertex shader、fragment shader等）的机制。
 Uniforms 是一种特殊类型的变量，它们在渲染过程中保持不变，因此在多个绘制调用之间保持恒定。
 */

// MARK: - 法线（Normal）
/**
 在图形学和计算机图形中，法线（Normal）是与表面垂直方向的矢量或向量。
 法线通常与三维模型的表面或顶点相关联，用于描述表面的方向和朝向。法线在图形渲染中具有重要的作用，主要用于以下几个方面：

 光照计算：法线是在光照计算中的关键因素。它们用于确定表面如何反射光线，从而影响表面的明暗、阴影和反射效果。
 在基于物理的渲染中，光线与法线的夹角决定了表面的明暗程度。

 阴影计算：法线可用于确定阴影的位置。当光线照射到表面时，法线用于确定该点是否位于阴影中。阴影通常取决于光线和法线之间的夹角。

 碰撞检测：在游戏开发和物理仿真中，法线通常用于检测物体之间的碰撞。
 通过比较法线方向，可以确定两个物体是否相交，以及在哪里相交。

 平滑和表面细节：法线也用于创建平滑的表面，以便更好地捕捉光照效果。
 法线贴图（Normal Map）是一种常见的技术，它将表面细节嵌入到纹理中，以改善渲染效果，而不必增加几何细节。

 法线变换：在对象变换中，法线也需要进行变换，以确保在对象旋转或缩放时，法线方向仍然正确。这是因为法线是与表面局部坐标系相关的。
 */
class ViewController: UIViewController {

    override func viewDidLoad() {
        super.viewDidLoad()
    }
    
    override func viewDidAppear(_ animated: Bool) {
        super.viewDidAppear(animated)
        
        if #available(iOS 14.0, *) {
            if let device = MTLCreateSystemDefaultDevice() {
                let counterSet1 = getCounterSet(MTLCommonCounterSet.timestamp, from: device)
                let counterSet2 = getCounterSet(MTLCommonCounterSet.stageUtilization, from: device)
                let counterSet3 = getCounterSet(MTLCommonCounterSet.statistic, from: device)
            }
        }
        
    }
    
    @available(iOS 14.0, *)
    func getCounterSet(_ commonCounterSetName: MTLCommonCounterSet,
                       from device: MTLDevice) -> MTLCounterSet? {
        let counterSetName = commonCounterSetName.rawValue

        guard let counterSets = device.counterSets else {
            print("GPU device \"\(device.name)\" doesn't support any counter sets.")
            return nil
        }

        for counterSet in counterSets {
            guard counterSet.name == counterSetName else { continue }

            print("GPU device \"\(device.name)\" supports the \"\(counterSetName)\" counter set.")
            return counterSet
        }

        print("GPU device \"\(device.name)\" doesn't support the \"\(counterSetName)\" counter set.")
        return nil
    }
    
    @available(iOS 14.0, *)
    func counterSet(_ counterSet: MTLCounterSet,
                    contains commonCounterName: MTLCommonCounter) -> Bool {

        let counterName = commonCounterName.rawValue
        for counter in counterSet.counters {
            guard counter.name == counterName else { continue }

            print("Counter set \"\(counterSet.name)\" contains the \"\(counterName)\" counter.")
            return true
        }

        print("Counter set \"\(counterSet.name)\" doesn't contain the \"\(counterName)\" counter.")
        return false
    }
    
    @IBAction func readingPixelData(_ sender: Any) {
        let sb = UIStoryboard(name: "Main", bundle: nil)
        if let vc = sb.instantiateViewController(withIdentifier: "ReadingPixelDataFromDrawableTexture") as? ReadingPixelDataFromDrawableTextureViewController {
            vc.modalPresentationStyle = .fullScreen
            self.present(vc, animated: true)
        }
    }
    
}


https://developer.apple.com/documentation/coreimage
Use built-in or custom filters to process still and video images.
Core Image is an image processing and analysis technology that provides high-performance processing for still and video images.

Use the many built-in image filters to process images and build complex effects by chaining filters. For details, see Core Image Filter Reference.
https://developer.apple.com/library/archive/documentation/GraphicsImaging/Reference/CoreImageFilterReference/index.html#//apple_ref/doc/uid/TP40004346

https://developer.apple.com/library/archive/documentation/GraphicsImaging/Conceptual/CoreImaging/ci_intro/ci_intro.html#//apple_ref/doc/uid/TP30001185-CH1-TPXREF101

You can also create new effects with custom filters and image processors; see Core Image Programming Guide.

==================================================Core Image Programming Guide.
https://developer.apple.com/library/archive/documentation/GraphicsImaging/Conceptual/CoreImaging/ci_intro/ci_intro.html#//apple_ref/doc/uid/TP30001185


==================================================Processing an Image Using Built-in Filters
----------class CIImage : NSObject
A representation of an image to be processed or produced by Core Image filters.
You use CIImage objects in conjunction with other Core Image classes—such as CIFilter, CIContext, CIVector, and CIColor—to take advantage of the built-in Core Image filters when processing images. 
You can create CIImage objects with data supplied from a variety of sources, including Quartz 2D images, Core Video image buffers (CVImageBuffer), URL-based objects, and NSData objects.

Although a CIImage object has image data associated with it, it is not an image.
You can think of a CIImage object as an image “recipe.”
A CIImage object has all the information necessary to produce an image, but Core Image doesn’t actually render an image until it is told to do so.
This lazy evaluation allows Core Image to operate as efficiently as possible.

###
CIContext and CIImage objects are immutable, which means each can be shared safely among threads.
###
Multiple threads can use the same GPU or CPU CIContext object to render CIImage objects.
However, this is not the case for CIFilter objects, which are mutable. A CIFilter object cannot be shared safely among threads.
If you app is multithreaded, each thread must create its own CIFilter objects. Otherwise, your app could behave unexpectedly.

Core Image also provides auto-adjustment methods.
These methods analyze an image for common deficiencies and return a set of filters to correct those deficiencies.
The filters are preset with values for improving image quality by altering values for skin tones, saturation, contrast, and shadows and for removing red-eye or other artifacts caused by flash. (See Getting Autoadjustment Filters.)

For a discussion of all the methods you can use to create CIImage objects on iOS and macOS, see Core Image Programming Guide.

----------class CIFilter : NSObject
An image processor that produces an image by manipulating one or more input images or by generating new image data.
The CIFilter class produces a CIImage object as output.
Typically, a filter takes one or more images as input. Some filters, however, generate an image based on other types of input parameters.
The parameters of a CIFilter object are set and retrieved through the use of key-value pairs.

CIFilter objects are mutable, and thus cannot be shared safely among threads.
Each thread must create its own CIFilter objects, but you can pass a filter’s immutable input and output CIImage objects between threads.

To get a quick overview of how to set up and use Core Image filters, see Core Image Programming Guide.

Subclassing Notes
You can subclass CIFilter in order to create custom filter effects:
By chaining together two or more built-in Core Image filters
By using an image-processing kernel that you write
See Core Image Programming Guide for details.

Methods to Override
Regardless of whether your subclass provides its effect by chaining filters or implementing its own kernel, you should:
Declare any input parameters as properties whose names are prefixed with input, such as inputImage.
Override the setDefaults() methods to provide default values for any input parameters you’ve declared.
Implement an outputImage method to create a new CIImage with your filter’s effect.

Special Considerations
The CIFilter class automatically manages input parameters when archiving, copying, and deallocating filters.
For this reason, your subclass must obey the following guidelines to ensure proper behavior:
Store input parameters in instance variables whose names are prefixed with input.
Don’t use auto-synthesized instance variables, because their names are automatically prefixed with an underscore. Instead, synthesize the property manually. For example:
@synthesize inputMyParameter;

If using manual reference counting, don’t release input parameter instance variables in your dealloc method implementation.
The dealloc implementation in the CIFilter class uses Key-value coding to automatically set the values of all input parameters to nil.

----------class CIContext : NSObject
An evaluation context for rendering image processing results and performing image analysis.

The CIContext class provides an evaluation context for Core Image processing with Quartz 2D, Metal, or OpenGL. You use CIContext objects in conjunction with other Core Image classes, such as CIFilter, CIImage, and CIColor, to process images using Core Image filters.
You also use a Core Image context with the CIDetector class to analyze images—for example, to detect faces or barcodes.

CIContext and CIImage objects are immutable, so multiple threads can use the same CIContext object to render CIImage objects.
However, CIFilter objects are mutable and thus cannot be shared safely among threads.
Each thread must create its own CIFilter objects, but you can pass a filter’s immutable input and output CIImage objects between threads.

----------class CIVector : NSObject
A container for coordinate values, direction vectors, matrices, and other non-scalar values, typically used in Core Image for filter parameters.

----------class CIColor : NSObject
The component values defining a color in a specific color space.
You use CIColor objects in conjunction with other Core Image classes, such as CIFilter, CIContext, and CIImage, to take advantage of the built-in Core Image filters when processing images.

A color space defines a one-, two-, three-, or four-dimensional environment whose color components represent intensity values.
A color component is also referred to as a color channel.
An RGB color space, for example, is a three-dimensional color space whose stimuli are the red, green, and blue intensities that make up a given color.
Regardless of the color space, in Core Image, color values range from 0.0 to 1.0, with 0.0 representing an absence of that component (0 percent) and 1.0 representing 100 percent.

Colors also have an alpha component, which represents the opacity of the color, with 0.0 meaning completely transparent and 1.0 meaning completely opaque.
If a color does not have an explicit alpha component, Core Image paints the color as if the alpha component equals 1.0.
You always provide unpremultiplied color components to Core Image, and Core Image then provides unpremultiplied color components to you.
Core Image premultiplies each color component with the alpha value in order to optimize calculations.
For more information on premultiplied alpha values, see Core Image Programming Guide.


==================================================Custom Filters
Use the Core Image Kernel Language to create universal image processing routines that work in any Core Image context.

----------Writing Custom Kernels
Write your own custom kernels in either the Core Image Kernel Language or the Metal Shading Language.

The Core Image Kernel Language is a shading language optimized for writing custom kernels for use in apps leveraging Core Image.
You can add custom image processing routines to a Core Image pipeline.
You can also write your own kernels in the Metal Shading Language. 

Core Image Kernel Language Reference
https://developer.apple.com/metal/CoreImageKernelLanguageReference11.pdf
Metal Shading Language for Core Image Kernels
https://developer.apple.com/go/?id=metal-shading-language-for-core-image-kernels

If you intend to use Metal-only language features and support exclusively Metal-supported devices, then writing custom kernels in Metal Shading Language can reduce compile-time cost while providing code consistency across your Metal app.

class CIKernel : NSObject
A GPU-based image processing routine used to create custom Core Image filters.
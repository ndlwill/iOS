//
//  TransformVisualization.swift
//  TestAR
//
//  Created by youdun on 2024/12/24.
//

import SceneKit
import ARKit

/**
 å•ä½çŸ©é˜µä¸Žå¯¹è§’çŸ©é˜µçš„å…³ç³»
 å•ä½çŸ©é˜µï¼š
 å•ä½çŸ©é˜µæ˜¯å¯¹è§’çŸ©é˜µçš„ç‰¹æ®Šå½¢å¼ï¼Œå…¶å¯¹è§’çº¿ä¸Šçš„æ‰€æœ‰å…ƒç´ å‡ä¸º 1ã€‚
 å•ä½çŸ©é˜µåœ¨æ•°å­¦ä¸­è¡¨ç¤ºä¸å˜å˜æ¢ï¼Œç±»ä¼¼äºŽåŠ æ³•ä¸­çš„â€œ0â€æˆ–ä¹˜æ³•ä¸­çš„â€œ1â€ã€‚
 
 
 å…ˆæ—‹è½¬å†å¹³ç§»å’Œå…ˆå¹³ç§»å†æ—‹è½¬ä¸ä¸€æ ·ï¼Œå› ä¸ºçŸ©é˜µä¹˜æ³•çš„é¡ºåºå†³å®šäº†å˜æ¢çš„åº”ç”¨é¡ºåºï¼Œè€ŒçŸ©é˜µä¹˜æ³•ä¸äº¤æ¢ï¼ˆéžäº¤æ¢æ€§ï¼‰ï¼Œå³
 ð´â‹…ðµ
 â‰ 
 ðµâ‹…ð´

 simdTransform
 å®šä¹‰ï¼šæè¿°ä¸€ä¸ªèŠ‚ç‚¹ï¼ˆæˆ–å®žä½“ï¼‰çš„æ•´ä½“å˜æ¢ï¼ŒåŒ…å«ä½ç§»ï¼ˆTranslationï¼‰ã€æ—‹è½¬ï¼ˆRotationï¼‰ã€ç¼©æ”¾ï¼ˆScaleï¼‰åœ¨å†…çš„ç»„åˆã€‚
 ä½œç”¨èŒƒå›´ï¼šåº”ç”¨äºŽèŠ‚ç‚¹çš„å…¨å±€åæ ‡ç³»ï¼Œç”¨æ¥å®šä¹‰è¯¥èŠ‚ç‚¹çš„æœ€ç»ˆä½ç½®ã€æ–¹å‘å’Œå¤§å°ã€‚
 åŠŸèƒ½ï¼š
 simdTransform æ˜¯ç›´æŽ¥å®šä¹‰ä¸€ä¸ªèŠ‚ç‚¹ç›¸å¯¹äºŽçˆ¶èŠ‚ç‚¹çš„æœ€ç»ˆå˜æ¢ã€‚ä¾‹å¦‚ï¼š
 è®¾ç½®ä¸€ä¸ªå¯¹è±¡åœ¨åœºæ™¯ä¸­çš„ä½ç½®ã€‚
 æ”¹å˜å¯¹è±¡çš„ç¼©æ”¾æˆ–æ—‹è½¬ã€‚
 
 simdPivot
 å®šä¹‰ï¼šæè¿°èŠ‚ç‚¹çš„æ—‹è½¬å’Œç¼©æ”¾æ“ä½œç›¸å¯¹äºŽçš„å‚è€ƒç‚¹ï¼ˆæˆ–ç§°â€œæž¢è½´ç‚¹â€ï¼‰ã€‚
 ä½œç”¨èŒƒå›´ï¼šåœ¨èŠ‚ç‚¹çš„å±€éƒ¨åæ ‡ç³»ä¸­ï¼Œç”¨äºŽæ”¹å˜æ—‹è½¬å’Œç¼©æ”¾çš„åŸºå‡†ç‚¹ã€‚
 åŠŸèƒ½ï¼š
 simdPivot æ˜¯ç”¨æ¥è°ƒæ•´èŠ‚ç‚¹å†…éƒ¨çš„å‚è€ƒç‚¹ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼ŒèŠ‚ç‚¹çš„æ—‹è½¬å’Œç¼©æ”¾æ˜¯å›´ç»•å…¶å±€éƒ¨åæ ‡ç³»çš„åŽŸç‚¹ï¼ˆ0, 0, 0ï¼‰è¿›è¡Œçš„ã€‚å¦‚æžœå¸Œæœ›æ”¹å˜è¿™ä¸ªå‚è€ƒç‚¹ï¼Œæ¯”å¦‚è®©æ—‹è½¬å›´ç»•èŠ‚ç‚¹çš„æŸä¸ªè¾¹è§’è¿›è¡Œï¼Œå¯ä»¥é€šè¿‡è®¾ç½® simdPivot å®žçŽ°ã€‚
 */
class TransformVisualization: NSObject, VirtualContentController {
    
    var contentNode: SCNNode?
    
    // Load multiple copies of the axis origin visualization for the transforms this class visualizes.
    lazy var rightEyeNode = SCNReferenceNode(named: "coordinateOrigin")
    lazy var leftEyeNode = SCNReferenceNode(named: "coordinateOrigin")
    
    
    /**
     When face tracking is active, ARKit automatically adds ARFaceAnchor objects to the running AR session, containing information about the userâ€™s face, including its position and orientation. (ARKit detects and provides information about only face at a time. If multiple faces are present in the camera image, ARKit chooses the largest or most clearly recognizable face.)
     
     In a SceneKit-based AR experience, you can add 3D content corresponding to a face anchor in the renderer(_:nodeFor:) or renderer(_:didAdd:for:) delegate method.
     ARKit manages a SceneKit node for the anchor, and updates that nodeâ€™s position and orientation on each frame, so any SceneKit content you add to that node automatically follows the position and orientation of the userâ€™s face.
     */
    /**
     Implement this to provide a custom node for the given anchor.
     
     @discussion This node will automatically be added to the scene graph.
     If this method is not implemented, a node will be automatically created.
     If nil is returned the anchor will be ignored.
     @param renderer The renderer that will render the scene.
     @param anchor The added anchor.
     @return Node that will be mapped to the anchor or nil.
     */
    func renderer(_ renderer: any SCNSceneRenderer, nodeFor anchor: ARAnchor) -> SCNNode? {
        // This class adds AR content only for face anchors.
        guard anchor is ARFaceAnchor else { return nil }
        
        // Load an asset from the app bundle to provide visual content for the anchor.
        contentNode = SCNReferenceNode(named: "coordinateOrigin")
        
        // Add content for eye tracking in iOS 12.
        self.addEyeTransformNodes()
        
        return contentNode
    }
    
    func renderer(_ renderer: any SCNSceneRenderer, didUpdate node: SCNNode, for anchor: ARAnchor) {
        guard #available(iOS 12.0, *),
              let faceAnchor = anchor as? ARFaceAnchor else { return }
        
        rightEyeNode.simdTransform = faceAnchor.rightEyeTransform
        leftEyeNode.simdTransform = faceAnchor.leftEyeTransform
    }
    
    func addEyeTransformNodes() {
        guard #available(iOS 12.0, *),
              let anchorNode: SCNNode = contentNode else { return }
        
        // MARK: - simdPivot
        /**
         The default pivot is the identity matrix, specifying that the nodeâ€™s position locates the origin of its coordinate system, its rotation is about an axis through its center, and its scale is also relative to that center point.
         */
        // Scale down the coordinate axis visualizations for eyes.
        rightEyeNode.simdPivot = float4x4(diagonal: [3, 3, 3, 1])
        leftEyeNode.simdPivot = float4x4(diagonal: [3, 3, 3, 1])
        
        anchorNode.addChildNode(rightEyeNode)
        anchorNode.addChildNode(leftEyeNode)
    }
    
}

ARConfiguration
The base object that contains information about how to configure an augmented reality session.

iOS 11.0
class ARConfiguration : NSObject


ARConfiguration defines a base class for the different options you can configure in your AR experience.

All AR configurations establish a correspondence between the real world that the device inhabits and the virtual 3D-coordinate space, where you model content. 
When your app mixes virtual content with a live-camera image, the user experiences the illusion that your virtual content is part of the real world.

To acquire the live-camera imagery, ARKit manages a camera-capture pipeline for you. Depending on the configuration you choose, 
it determines the cameras that capture imagery, and which camera feed the app displays.

AR apps recognize real-world regions of interest. 
At runtime, ARKit generates an ARAnchor for a real-world object it recognizes, which allows an app to refer to its details, such as size and physical location. 
The configuration you choose determines the kinds of real-world objects ARKit recognizes and makes available to your app.

Don't allocate ARConfiguration yourself; instead, instantiate one of its subclasses.

For more information about the camera-capture pipeline, see Choosing Which Camera Feed to Augment.
https://developer.apple.com/documentation/arkit/arkit_in_ios/choosing_which_camera_feed_to_augment

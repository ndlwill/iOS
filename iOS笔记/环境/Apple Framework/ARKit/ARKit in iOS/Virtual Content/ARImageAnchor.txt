ARImageAnchor
An anchor for a known image that ARKit detects in the physical environment.

iOS 11.3
class ARImageAnchor : ARAnchor

When you run a world-tracking AR session and specify ARReferenceImage objects for the session configuration's detectionImages property, ARKit searches for those images in the real-world environment. 
When the session recognizes an image, it automatically adds an ARImageAnchor for each detected image to its list of anchors.

To find the extent of a recognized image in the scene, use the inherited transform property together with the physicalSize of the anchor's referenceImage.


Identifying Detected Images:
var referenceImage: ARReferenceImage
The detected image referenced by the image anchor.


ARReferenceImage:
A 2D image that you want ARKit to detect in the physical environment.
iOS 11.3
class ARReferenceImage : NSObject

To accurately detect the position and orientation of a 2D image in the real world, ARKit requires preprocessed image data and knowledge of the image's real-world dimensions. 
The ARReferenceImage class encapsulates this information. To enable image detection in an AR session, pass a collection of reference images to your session configuration's detectionImages property.

Typically, you create reference images in your Xcode project's asset catalog:
1. In your asset catalog, use the Add (+) button to create an AR Resource Group.
2. Drag image files into the resource group to create AR Reference Image entries in the asset catalog.
3. For each reference image, use the Xcode inspector panel to provide the real-world size at which you want ARKit to recognize the image. (You can also provide a descriptive name, which appears as the name property at runtime and can be useful for debugging.)

iPhone 7 的屏幕具有 326 PPI（像素每英寸）的分辨率
将2.301英寸转换为像素，使用326 PPI的值:
像素数=2.301英寸×326 PPI
像素数≈750.126 像素
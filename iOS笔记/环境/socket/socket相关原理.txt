BSD Sockets 是最早、也是最经典的一套 socket 编程 API。

socket（套接字） 从本质上来说，是 进程之间通信（IPC, Inter-Process Communication）的一种抽象。
可以把它理解为一个“通信端点”（communication endpoint）。

文件描述符（file descriptor）是“文件的句柄”，
socket 则是“网络通信的句柄”。

socket()
bind()
listen()
accept()
connect()
send()
recv()
close()
这些就是“BSD sockets API”。

“BSD Sockets”是“socket 编程接口的一种实现标准”，
而“socket”是一个更广义的通信抽象概念。

所有现代系统上的 socket 编程（包括 Linux、macOS、Windows）
都是基于 BSD Sockets 模型 的。


==================================================port=0
在 socket 编程里，端口号 0 表示“让系统随机分配一个可用端口”。


==================================================



OSI 7层模型（物理层到应用层）是一个抽象模型，它描述了网络通信中数据处理和传输的各个环节。
它的重点是 数据从发送端到接收端是如何被封装、传输、解封装的。

是针对数据的处理和传输的，包括如何编码、路由、分段、会话管理等。
不是直接针对连接建立或握手的，因为连接/握手属于具体协议的行为（如 TCP 的三次握手、TLS 握手），这些是协议实现的一部分。

#####
层是抽象概念，协议是实现层功能的具体规则。TCP 是协议，它实现了传输层的功能。

三次握手（Three-Way Handshake）完全属于 TCP 协议的内容
三次握手的目的：
建立 可靠的面向连接（connection-oriented） 的传输通道。
双方确认彼此 可达性，并 同步序列号。
#####


==================================================序列号（Sequence Number）
TCP 的序列号 确实是按字节计的，这是 TCP 保证顺序传输和可靠性的核心机制

序列号的定义：
TCP 在每个连接建立时，会随机选择一个 初始序列号（ISN, Initial Sequence Number）。
序列号表示数据流中每个字节的编号
发送端把应用层数据拆成 segments，每个 segment 带上 起始序列号，长度为 segment 内字节数。

| Segment   | Sequence Number (起始) | 长度                |
| --------- | -------------------- | ----------------- |
| Segment 1 | 1000                 | 100 字节（1000–1099） |
| Segment 2 | 1100                 | 50 字节（1100–1149）  |

接收端根据序列号重组字节流，保证顺序。

为什么按字节编号而不是按段编号？
段可能拆分或重组：IP 层可能把 TCP segment 分片，或者应用层数据大小不固定。
按字节编号可以精确定位丢失或乱序的数据，不管 segment 怎么拆分。
方便 TCP 重传：只重传缺失的字节段，而不是整个报文。

ACK（确认号）也是按字节计的：
接收端 ACK 表示 下一个期望的字节序号。
举例：如果接收端收到字节 1000–1099，就会发送 ACK = 1100，告诉发送端“我已经收到到 1099，下一个字节我期望 1100”。

#####总结
TCP 序列号是 按字节计数，每个字节都有唯一序列号。
Segment 只是把连续字节打包发送，序列号记录段内第一个字节的位置。
按字节计序列号是 TCP 可靠传输和重传机制的基础。
#####


==================================================TCP 丢包的处理
TCP 丢包的处理
#####
TCP 是面向字节流、可靠传输的协议。
它保证所有数据按序到达，通过序列号（Sequence Number）和确认号（ACK）实现。
#####

当客户端收到的某个包丢失时：
客户端不会向应用层交付这个丢失的字节。
客户端会 ACK 最后一个连续收到的序列号。
服务端在收到重复 ACK 或超时后，会 重传丢失的数据。


服务端重传策略：
TCP 有两种主要触发重传的方式：// #####重传的主要目的是 保证顺序可靠交付。“重传”，严格来说都是指 TCP 报文段（Segment）的重传，而不是 IP 分片的重传。#####
1. 超时重传（RTO, Retransmission Timeout）
服务端发送某段数据后，没有收到 ACK，过了一定时间（RTO）才会重发。
这个时候服务端只会重发 丢失的字节段，而不是把新数据和丢失的数据一起发。
2. 快速重传（Fast Retransmit）
客户端连续收到重复 ACK（一般是 3 个重复 ACK），就会触发服务端快速重传。// 是 服务端（发送方）收到 客户端发来的重复 ACK，而不是客户端收到重复 ACK。客户端告知服务端，它已经收到某个序列号之前的所有数据，但后面某个字节还没收到（丢失了）。
这种情况下服务端 也只重传丢失的包，而不是把后续的新数据一起发送。


服务端是否会顺便发送后续数据？
理论上 TCP 允许“合并发送”（Send Buffer 中后续数据一起发），但是:
如果后续数据已经发送但未被确认，服务端可能在重传丢失数据时顺便把新数据一起发（即 TCP 会把窗口内的数据尽量打包发送）。
如果后续数据还没发送到网络，TCP 就会先重传丢失的数据，再继续发送新数据。
所以，是否会“顺便发送其他响应”，取决于：
1. 后续数据是否已经在发送缓冲区
2. TCP 实现的拥塞控制和 Nagle 算法
3. 窗口大小（Receiver Window）
一般情况下，你看到的是：丢包时服务端先重传丢失的数据，之后再发送新的响应。

#####
TCP 可能会把新数据和丢失数据一起发，但原则上是先保证丢失的数据被送达。
#####


==================================================TCP 快速重传（Fast Retransmit）原理
TCP 快速重传（Fast Retransmit）原理
触发条件：
是 服务端（发送方）收到 客户端发来的重复 ACK，而不是客户端收到重复 ACK。
“重复 ACK”指的是：客户端告知服务端，它已经收到某个序列号之前的所有数据，但后面某个字节还没收到（丢失了）。

具体流程：
客户端收到乱序数据或者发现缺失字节，会 连续发送 ACK，ACK号指向最后一个按序收到的字节。
如果服务端连续收到 3 个相同的 ACK（即 3 个重复 ACK），说明中间有丢失数据。
服务端就会 立即重传丢失的数据段，而不必等到 RTO 超时。


重复 ACK 是客户端发给服务端的。
快速重传是服务端在收到重复 ACK 后执行的动作。
3 个重复 ACK 是一个经验值，用于区分偶尔乱序和真实丢包。 // #####


“偶尔乱序（out-of-order）”指的是数据包到达顺序和发送顺序不完全一致，但并不是丢包。
1. 为什么会出现乱序？
网络路径不同：同一个 TCP 连接的数据可能走不同路由，导致后发的包先到。
链路延迟差异：不同路由或中间设备（交换机、负载均衡器）可能延迟不同。
报文分片：在底层网络中，较大的 TCP 报文可能被拆分，先到的片段顺序可能不同。
2. TCP 的处理
当 TCP 收到乱序的数据：
      会缓存这些乱序的数据（在接收缓冲区），
      并发送 ACK 指向最后一个按序到达的字节。
      这样，发送端不会立即触发重传，因为 TCP 认为可能只是乱序而不是丢包。
如果乱序数据太多，或者发送端收到重复 ACK 达到快速重传阈值（比如 3 个重复 ACK），才会认为可能有丢包，从而触发 快速重传。

#####
乱序 ≠ 丢包
偶尔乱序是正常现象，TCP 本身能处理。
重复 ACK不一定代表丢包，可能只是乱序，但连续 3 个重复 ACK 一般被 TCP 当作丢包信号，触发快速重传。
#####


==================================================TCP 拥塞控制
TCP 拥塞控制，这是 TCP 能在复杂网络环境里保持高效传输、避免网络“塞车”的核心机制

为什么要拥塞控制？
如果网络带宽不足、路由器缓存满了，大量发送会导致 丢包、延迟、重传。
TCP 需要根据网络反馈（ACK、丢包、延迟）动态调整发送速率，既要尽量快，又不能压垮网络。


TCP 拥塞控制的四个核心算法
1. 慢启动（Slow Start）
初始时，TCP 不知道网络容量，小心试探。
拥塞窗口（cwnd） 从 1 MSS（最大报文段大小）开始，每收到一个 ACK，cwnd 增加 1 MSS。
所以 cwnd 呈 指数增长（1, 2, 4, 8...）。
一旦达到慢启动阈值（ssthresh），进入拥塞避免。

2. 拥塞避免（Congestion Avoidance）
为了避免过快增长导致网络拥堵，增长速度变慢。
cwnd 线性增长：大约每往返一次 (RTT)，cwnd 增加 1 MSS。

3. 快速重传（Fast Retransmit）
如果服务端收到 3 个重复 ACK，说明中间某个报文段可能丢了。
不等超时（RTO），立刻重传丢失的数据段，加快恢复。

4. 快速恢复（Fast Recovery）
配合快速重传使用。
触发快速重传后：
      把 ssthresh 设置为当前 cwnd 的一半。
      cwnd 也降低到这个值（避免太激进）。
      然后进入拥塞避免阶段，继续线性增长。
这样既避免完全回到 1 MSS（太保守），又防止继续指数爆炸。


#####
cwnd 与 ssthresh 的变化总结：
cwnd（Congestion Window）：#####动态调整，决定最多能发多少未确认的数据。#####
ssthresh（慢启动门限）：决定是指数增长还是线性增长的分界线。

规则：
正常：cwnd ↑
丢包：ssthresh = cwnd / 2，cwnd 回退
#####

常见 TCP 拥塞控制算法变种：
Reno：经典版本，包含慢启动、拥塞避免、快速重传、快速恢复。
NewReno：改进了 Reno 在多重丢包下的表现。
CUBIC（Linux 默认）：非线性增长，更适合高带宽高延迟网络。
BBR（Google 提出）：基于带宽和 RTT 估计，而不是丢包，能更高效利用链路。


#####
TCP 拥塞控制通过 慢启动 + 拥塞避免 + 快速重传 + 快速恢复 来动态调整发送速率，防止网络过载，同时尽量榨干带宽。
#####


==================================================cwnd（拥塞窗口） 和 rwnd（接收窗口）
TCP 窗口机制

cwnd（拥塞窗口，congestion window）
作用方：发送端
控制内容：发送端 在网络拥塞控制下，能连续发送而不被阻塞的数据量
单位：字节
特点：
根据 网络状况动态调整（慢启动、拥塞避免、快重传、快恢复等算法）
反映发送端对网络可承受吞吐量的估计
不依赖接收端，只根据 ACK 来调整


rwnd（接收窗口，receive window）
作用方：接收端
控制内容：接收端 告知发送端自己接收缓冲区还有多少可用空间
单位：字节
特点：
反映接收端的缓冲区可用大小
发送端必须 遵循 rwnd 限制，不能发送超过接收端缓冲区能容纳的数据


实际发送量 = min(cwnd, rwnd)
TCP 发送端在发送数据时，真正允许发送的数据量由 两者决定：
允许发送数据量 = min(cwnd, rwnd)

也就是说：
cwnd 限制 网络拥塞
rwnd 限制 接收方能力

| 窗口   | 谁控制 | 控制对象         | 作用      |
| ---- | --- | ------------ | ------- |
| cwnd | 发送端 | 网络可承受的未确认数据量 | 避免网络拥塞  |
| rwnd | 接收端 | 接收缓冲区可用容量    | 避免接收端溢出 |

cwnd 看的是 “我能扔给网络多少”
rwnd 看的是 “你能收多少”


==================================================TCP 的 顺序传输机制
TCP 的特点
字节流传输：TCP 把应用层发的数据看作连续字节流。
按序号交付：接收端有一个 接收缓冲区，会根据 序列号（Sequence Number） 排序。
可靠性：丢包会触发 重传，乱序数据会先放在缓冲区，不会提前交付给应用层，必须保证顺序。

例子：
应用层请求 A → TCP 发出 → 序列号 1000~1500
请求 B → TCP 发出 → 序列号 1501~2000
假设 B 的部分数据比 A 先到达：
TCP 接收端会把 B 的数据放到 接收缓冲区，标记为 乱序段。
TCP 不会立即交付给应用层，因为 A 的序列号段还没收到。// 这是 TCP 的可靠性和顺序保证造成的。
一旦 A 的数据到达且按序号完整，TCP 会：
      先把 A 的数据交付应用层
      然后再交付 B 的数据
结论：即使 B 的部分响应先到，TCP 也不会先交付给应用层。应用层看到的数据顺序 总是发送顺序，先 A 后 B。


如果你用的是 HTTP/1.1 或 HTTP/2 的 TCP 复用：
（1）在 HTTP/1.x 上，单个 TCP 连接上请求 B 可能会阻塞等待 A 完全响应（队头阻塞）。// #####HTTP/1.x 单连接队头阻塞（Head-of-Line Blocking）主要是响应顺序的限制，不是请求顺序的绝对限制#####
#####
请求发送阶段：HTTP/1.1 在 同一个连接上可以连续发送多个请求（pipelining），不必等前一个响应完成。
响应接收阶段：服务器必须 按请求顺序返回响应，前一个响应没完成，后一个响应就必须等待，这就是 队头阻塞（Head-of-Line Blocking） 的本质。
#####

（2）HTTP/2 引入多路复用，TCP 层依然按序交付，但应用层会通过流 ID 区分不同请求的响应，实现并行处理。
#####
同一个 TCP 连接可以同时发送多个请求。
服务器可以 交错发送响应数据。
队头阻塞的影响大大降低，但仍有 TCP 层的队头阻塞问题（特别是丢包时）。

每个字节都有 序列号，接收端必须按序号重组数据。
如果中间某个 TCP 包丢失：
      接收端 会阻塞等待丢失的包重传
      即便后面的包已经到达，也不能先交付给应用层
#####


HTTP/1.x 队头阻塞（应用层）
发生位置：HTTP 服务器端 → 响应顺序
队头阻塞体现为 响应被阻塞，阻塞的是 服务端响应的发送
HTTP/2 队头阻塞（TCP 层）
发生位置：TCP 传输层 → 接收端重组顺序
队头阻塞体现为 接收端等待数据按序交付


队头阻塞只在异常情况下显著：
丢包、严重乱序或网络抖动时，B 的数据要等 A 重传完成才交付应用层，这才会造成可感知的延迟。
网络正常 = 无丢包、乱序少
A 的数据很快就能到达接收端。
B 即使稍快一点到达，TCP 的缓冲区很快就能按序交付 A，然后交付 B。
延迟差通常在毫秒级，应用层几乎感受不到。



TCP 的 顺序传输机制，从发送到接收：
1. TCP 是字节流（Byte Stream）：
TCP 把应用层的数据看作连续的字节序列，不区分消息边界。// TCP 不知道应用层的“请求边界”，只看字节序列。
发送端写入的数据，会被 TCP 拆分成 segments（报文段） 发送。
接收端接收到 segment 后，按字节顺序交给应用层。


2. 数据传输顺序保证：
TCP 保证 可靠、顺序、无重复
每个字节都有一个 序列号（Sequence Number）。
TCP segment 带上起始序列号和长度。
接收端按序号排列字节，如果出现 丢包或乱序：
      TCP 阻塞后续字节交付应用层
      等待丢失段重传（重传机制保证可靠性）

3. ACK（确认）机制：
接收端会发送 ACK，告知发送端已成功收到的字节序号。
发送端根据 ACK 来管理 发送窗口（Sliding Window），决定可以发送哪些字节。
这样既保证顺序，又控制流量（Flow Control）。


在 HTTP/2 上，虽然不同 stream 的帧可以交错发送，但底层 TCP 仍然是顺序传输：
A、B 两个 stream 的帧混在一个 TCP 字节流里
如果 A 的某个 segment 丢包 → B 的帧也会暂时阻塞


==================================================TCP 发送缓冲区（send buffer）何时触发发送
TCP 发送缓冲区（send buffer）何时触发发送 的问题，这涉及 TCP 的 Nagle 算法、拥塞控制和缓冲机制

TCP 发送缓冲区概念
发送缓冲区是 内核为每个 TCP 连接维护的缓冲区，存放应用层写入的数据。
TCP 并不会等待整个缓冲区填满才发送，而是根据以下策略决定何时发送 segment：


发送触发条件（主要因素）：
1. 缓冲区满
如果发送缓冲区被填满，内核 必须立刻发送部分或全部数据，否则应用层阻塞。
2. Nagle 算法
#####默认启用 Nagle 算法（减少小包）：#####
      如果 已有未确认的数据（unacknowledged data），小的写入不会立即发送，而是等待累积更多数据。
      #####
      “未确认的数据（unacknowledged data）” 指的就是：// 未确认的数据 = 已发送但未被接收端确认的数据
      发送端已经把数据放入 TCP 发送缓冲区并通过网络发送出去了
      但是 接收端还没有发送 ACK 确认这些数据
      也就是说，这部分数据 在网络中或接收端等待确认

      例子：
      假设 MSS = 1000 字节，应用层连续写入 200 字节：
      第一次写入 200 字节 → TCP 发送出去
      还没收到 ACK → 这是 未确认数据
      第二次写入 200 字节 → 因为 Nagle 算法启用，TCP 会暂时不发送，等待前面 200 字节的 ACK
      收到 ACK 后，TCP 会把缓冲区中的新数据发送出去
      #####
      如果 没有未确认的数据，即使写入很小，也会立即发送。
目的是减少小包频繁发送，降低网络拥塞。

Nagle 算法规则：// Nagle 算法控制小包发送
如果有 未确认的数据在网络中，小数据段不会立即发送
等到前面的数据被确认（收到 ACK），或者积累到 MSS（最大报文段）大小时，才发送新数据
3. 超时触发
内核会设置一个小的 延迟定时器（通常几毫秒），如果在短时间内没有填满缓冲区，仍会触发发送，保证数据不会无限延迟。
4. 显式 flush / PUSH
TCP 提供 PSH 标志（Push），应用层调用 send() 或类似接口时，如果使用了 PSH，数据会尽快发送，不用等缓冲区满。



#####发送缓冲区（Send Buffer）相关原理机制：
在 TCP 发送端，发送缓冲区（Send Buffer）里的数据就是按照序列号（Sequence Number）顺序排列的。

TCP 发送缓冲区的作用
应用层调用 send()/write() → 数据会先进入 TCP 发送缓冲区。
TCP 协议层再从缓冲区里把数据切分成 MSS 大小的报文段，分配序列号，交给 IP 层发送。// IP 分片（IP Fragmentation）
发送缓冲区的数据 不会乱序存放，一定是按序号连续排列。


发送缓冲区里的数据大体分三类：
1. 已发送且已确认 (ACKed)
可以从缓冲区删除。
2. 已发送但未确认 (Unacked)
必须保留，等待 ACK，如果超时或重复 ACK 触发 → 重传。
3. 未发送 (Not Yet Sent)
还在缓冲区，等到 cwnd（拥塞窗口） 和 rwnd（接收窗口） 允许时才会发。


按序号排列的意义：
TCP 是字节流协议，每个字节都有序列号。
序列号保证了：
      接收方能检测丢包（发现序号断层）。
      接收方能处理乱序（先缓存，等缺的补上）。
      发送方能进行超时重传和快速重传。
#####


==================================================TCP 把数据切成 MSS 大小的段交给 IP 层后，IP 层可能还会再切片。那序列号会不会被“打碎”呢？
TCP 的切分与序列号：
TCP 层切分：
TCP 把应用数据拆成报文段，每段大小 ≤ MSS（最大报文段大小）。
每个 TCP 报文段 都会分配一个 序列号（Sequence Number），表示这个段第一个字节在整个字节流中的位置。
例如：Seq=1001, Length=1000，表示这个段包含字节 1001~2000。
序列号是以字节为单位


IP 层的分片：
（1）MTU 限制：
每个链路层（比如以太网）都有最大传输单元（MTU），常见是 1500 字节。
如果一个 TCP 报文段（含 TCP/IPv4 头）大于 MTU，IP 层会把整个 TCP 报文段再拆成多个片段（Fragment）。
（2）IP 分片特点：
IP 分片只在 IP 层有效，它不会改动 TCP 头里的序列号。
各个 IP 分片到达接收端后，会在 IP 层重组，恢复成完整的 TCP 报文段，再交给 TCP。
TCP 看到的仍然是“完整的报文段”，就像从来没有被拆过。


序列号会不会被拆？
不会。
TCP 序列号只在 TCP 报文段级别定义，不会因为 IP 分片而被“打断”。
即使一个 TCP 报文段在传输中被分成多个 IP 分片，这些分片在 IP 层重组之后，还是恢复成原始的那个 TCP 报文段（序列号不变）。


为什么 TCP 要控制 MSS？
为了避免 IP 分片。
如果 MSS 选择得太大，超过链路 MTU，IP 层就会分片。
分片有缺点：丢一个片 → 整个 TCP 段都要重传（因为 TCP 只知道段丢了，不知道片丢了）。
所以，TCP 在握手时会通过 MSS 选项告诉对方自己能接收的最大报文段大小，一般设置为 MTU - IP头 - TCP头。
例如：以太网 MTU=1500 → MSS = 1460。

#####总结：
TCP 序列号分配在 TCP 层，单位是字节。
IP 分片只影响 TCP 段的物理传输，不会改变 TCP 序列号。
接收端 IP 层会先重组，TCP 永远看到完整的段。
为避免分片，TCP 会根据 MSS 控制报文大小。
#####


==================================================“重传”，严格来说都是指 TCP 报文段（Segment）的重传，而不是 IP 分片的重传。
为什么是 TCP 段的重传，而不是 IP 分片？
1. TCP 的可靠性由 TCP 自己负责
TCP 给每个报文段分配字节序列号，靠 ACK 来确认哪些字节收到了。
如果某个报文段（对应一段连续字节）没有被确认，TCP 就认为“丢了”，然后重传整个报文段。
2. IP 层是无连接、不可靠的
IP 分片只是网络传输的需要（受 MTU 限制）。
如果某个分片丢失，IP 层无法单独重传，只能丢弃整个报文段的所有分片。
最终 TCP 发现这个报文段没收到，就会重传一整个 TCP 段。


举个例子：
假设一个 TCP 段大小为 1460 字节（MSS），经过某条 MTU=600 的链路。
IP 层会把它切成 3 个分片（600 + 600 + 260）。
如果第二个分片丢了：
      接收方 IP 层无法重组这个 TCP 段 → 整个 TCP 段丢失。
      TCP 层不会收到 ACK → 触发 TCP 段重传（重新发 1460 字节，而不是只发 600 字节）。


#####总结
重传的单位是 TCP 段（Segment），不是 IP 分片。
TCP 不关心分片的细节，它只看到“这个段有没有被确认”。
分片丢失 = 整个 TCP 段丢失 → TCP 段重传。
#####


==================================================socket 的 connect() 是怎么知道连接成功或失败的，取决于你是 阻塞模式 还是 非阻塞模式：
1. 阻塞模式（默认）
调用 connect() 时，当前线程会一直阻塞，直到：
连接成功：connect() 返回 0。
连接失败：connect() 返回 -1，并设置 errno（如 ECONNREFUSED、ETIMEDOUT、ENETUNREACH 等）。
在阻塞模式下，返回值 就告诉你连接是否成功。

2. 非阻塞模式（O_NONBLOCK）
如果套接字是非阻塞的，调用 connect() 时：
如果能立刻建立连接（如本机端口），返回 0。
大多数情况下，connect() 会返回 -1，errno == EINPROGRESS，表示连接还在进行。

此时需要通过 事件机制 来判断后续结果：
使用 select() / poll() / epoll() 等等待 可写事件。// 它们都是 I/O 多路复用机制，本质都是事件驱动
当 socket 变为可写时，说明连接完成（成功或失败）。
这时调用 getsockopt(fd, SOL_SOCKET, SO_ERROR, &err, &len)：// 查询套接字 fd 上的错误状态
err == 0 → 连接成功
err != 0 → 连接失败（错误码在 err 里，比如 ECONNREFUSED）


底层原理：
当调用 connect() 时，内核会：
发起 TCP 三次握手（如果是 TCP）。
在握手完成时，把 socket 标记为 可写。
如果握手失败（RST、超时、路由错误），也会把 socket 标记为 可写，并在 SO_ERROR 里填上失败原因。


总结：
阻塞模式：直接看 connect() 返回值。
非阻塞模式：等到 socket 可写，再用 getsockopt(... SO_ERROR ...) 判断。

#include <sys/types.h>
#include <sys/socket.h>
// 核心作用就是 获取套接字的配置或状态信息
int getsockopt(int sockfd,    // 套接字描述符
               int level,      // 选项所在的协议层，如 SOL_SOCKET
               int optname,    // 选项名，如 SO_ERROR
               void *optval,   // 存放选项值的缓冲区
               socklen_t *optlen); // 缓冲区长度，调用时传入，返回时修改为实际长度

获取套接字选项配置：
获取套接字的当前配置，比如：
| 选项 | 含义 |
|------|------|
| SO_RCVBUF | 接收缓冲区大小 |
| SO_SNDBUF | 发送缓冲区大小 |
| SO_REUSEADDR | 地址复用状态 |
| SO_KEEPALIVE | 是否开启 TCP KeepAlive |
int bufsize;
socklen_t len = sizeof(bufsize);
getsockopt(sockfd, SOL_SOCKET, SO_RCVBUF, &bufsize, &len);
printf("recv buffer size = %d\n", bufsize);


获取协议相关信息：
某些协议层有自己的选项，比如 TCP：
| 选项 | 含义 |
|------|------|
| TCP_NODELAY | 是否禁用 Nagle 算法 |
| TCP_MAXSEG | 最大报文段长度 |
int flag;
socklen_t len = sizeof(flag);
getsockopt(sockfd, IPPROTO_TCP, TCP_NODELAY, &flag, &len);



==================================================多路复用
#####
select()
支持：macOS 和 Linux 都支持。
适合：
小型应用，连接数不多（几十到几百个）。
poll()
支持：macOS 和 Linux 都支持。
适合：
中型应用，几百到几千连接。
epoll()
支持：Linux 专有，macOS 不支持。
适合：
Linux 上高并发服务器（数万连接）。


macOS 高性能 I/O 还有 kqueue()（macOS/BSD），是 macOS 专用的高效多路复用接口，相当于 Linux 的 epoll
特点：
高效，可处理成万上十万连接（真正的高并发）。
O(1) 复杂度，事件驱动。
如果你写跨平台网络库，通常用 select 或 poll，然后在 Linux 可以优化为 epoll，在 macOS 可以优化为 kqueue。

事件驱动 vs 阻塞 I/O
阻塞 I/O：read() / write() 直接阻塞线程，等待数据到来。
事件驱动：通过操作系统通知“哪些 socket 可以读/写”，线程不用一直阻塞，知道事件来了再处理。
select/poll/epoll/kqueue 都属于 事件驱动模型的一种实现方式。它们都是通过等待 I/O 事件来通知应用程序哪些 socket 可以操作。

select/poll 更像“轮询事件集合”，每次调用都要遍历 fd 数组，所以高并发下效率低。
epoll/kqueue 内核维护就绪队列，只在有事件时通知应用，真正做到事件驱动 + 高效。
所以严格意义上，select/poll 是事件驱动，但在高并发时更像在轮询；epoll/kqueue 才是真正高效的事件驱动。

| 接口         | 平台          | 实现方式 / 特点                               | 是否事件驱动            |
| ---------- | ----------- | --------------------------------------- | ----------------- |
| **select** | Linux/macOS | 轮询 fd 集合，每次调用都要拷贝 fd\_set               | ✅ 是事件驱动，但效率低      |
| **poll**   | Linux/macOS | 轮询 struct pollfd 数组，没有 fd 数量限制          | ✅ 是事件驱动，但 O(n) 遍历 |
| **epoll**  | Linux       | 内核维护就绪 fd 列表，只有有事件才返回，支持水平/边缘触发         | ✅ 真正高效事件驱动        |
| **kqueue** | macOS/BSD   | 内核维护事件队列，可注册各种事件（socket、timer、signal 等） | ✅ 高效事件驱动          |
#####


“多路复用接口”本质上就是 让一个线程同时监听和处理多个 I/O 资源（比如多个 socket、文件描述符、定时器等），而不需要为每个 I/O 都开一个线程。
在 macOS 上，kqueue() 就是这样一个 高效的多路复用接口，它的核心思路可以这样理解：
“多路复用”的含义
多路：多个 I/O 对象（socket、文件、管道等）
复用：一个线程可以复用这些 I/O 对象进行事件监听
接口：操作系统提供的 API，比如 kqueue()、select()、poll()、epoll()
换句话说，多路复用接口就是一个 事件通知中心：
你把想关心的 I/O 对象注册到它上面
当有事件发生（可读、可写、出错等），接口通知你
线程只在事件到来时处理 I/O，不用一直阻塞或轮询

为什么 macOS 用 kqueue
select / poll 都需要 每次调用遍历所有 fd，高并发下效率差。
kqueue 内核维护一个 事件队列：
只通知发生事件的 fd
支持边缘触发（edge-triggered）和水平触发（level-triggered）
可以注册多种事件（socket、文件、信号、定时器等），不只是网络

多路复用接口 = 事件驱动 + 高效 I/O


I/O 多路复用 & HTTP/2 多路复用 区别：
I/O 多路复用（select/poll/epoll/kqueue）：
层级：操作系统 / 套接字层
作用：一个线程可以同时监听多个 I/O 对象（socket、文件等），只在有事件时处理，不用为每个连接开线程
本质：事件驱动 + 高效 I/O
例子：
Linux 上 epoll 处理上万个 TCP 连接
macOS 上 kqueue 监听 socket、文件、信号、定时器等

HTTP/2 多路复用：
层级：应用层 / 协议层
作用：在一个 TCP 连接里同时承载多个 HTTP 请求和响应（流），避免每个请求都建立新的连接
本质：协议级的数据流复用
例子：
同一个 TCP 连接上，浏览器同时发起 10 个 HTTP/2 请求，每个请求是一个流（stream）
HTTP/2 用 流 ID + 帧分片 来区分不同请求的数据

#####
I/O 多路复用：一个线程处理多条 I/O 路径
HTTP/2 多路复用：一条 TCP 连接承载多条 HTTP 请求/响应
#####


==================================================I/O 多路复用接口（select/poll/epoll/kqueue 等）在有多个事件同时就绪时的通知行为
接口类型：水平触发 vs 边缘触发
多路复用的行为差别主要在于 水平触发(Level-Triggered, LT) 和 边缘触发(Edge-Triggered, ET)：

| 类型                       | 通知行为                                                                                 |
| ------------------------ | ------------------------------------------------------------------------------------ |
| **LT（默认，如 select/poll）** | 只要文件描述符可读/可写，就会被返回。即使你还没处理完，下次 `select/poll` 调用依然会返回它。多个事件到来不会排队，而是每次调用都返回所有可用的就绪事件。 |
| **ET（如 epoll ET 模式）**    | 只有状态发生变化时通知一次（从不可读变为可读，从不可写变为可写）。如果你没一次性读完可读数据，下次不会再通知，必须继续读。                        |


对于同一个 socket 上同时发生多个事件（可读、可写、出错等）时，多路复用接口的通知行为：
多路复用接口只是告诉你“某 socket 某事件就绪”，不管你处理没处理完。
同一个 socket 多个事件到来：
      LT：每次调用返回所有就绪事件，重复返回未处理的事件。
      ET：只返回状态变化的事件，一次不处理完可能漏掉后续通知。
事件处理顺序完全由你决定，接口不控制处理顺序。


对于同一个 socket 可读事件来了，但在你处理期间耗时很长，接口是否还会通知可读事件：
水平触发（LT）
规则：只要条件成立（socket 可读/可写/出错），每次调用 select/poll/epoll_wait 就会返回该事件。
情况处理：
可读事件到来 → 你开始处理，耗时很长。
在你处理期间，socket 缓冲区仍有数据未读 → 条件仍然成立。
下一次你调用 select/poll/epoll_wait，依然会返回 可读事件。
结论：
不会错过事件，即便你处理很慢。
但是 LT 不会“累积多次通知”，只要条件成立，下次调用就返回。

边缘触发（ET）
规则：只有状态变化时通知一次。
情况处理：
可读事件到来 → 你开始处理，耗时很长。
如果在你处理期间又来了新数据，但你还没有一次性把之前的数据全部读完 → 不会再触发新的可读事件。
你必须循环读完所有可读数据，才能保证下次状态变化再次触发事件。
结论：
耗时处理期间可能错过新数据的通知，必须确保一次处理完所有就绪数据。



==================================================内核事件就绪状态的维护和触发机制
在 iOS 上使用 libevent 时，默认模式是 水平触发（Level-Triggered，LT）
无论 LT 还是 ET，libevent 都会把内核触发的事件放入它自己的事件队列，然后按顺序调用回调函数。

事件的本质：
多路复用（select/poll/epoll/kqueue）报告的事件，实际上是 文件描述符的状态变化，例如：
可读（READ）：内核缓冲区里有数据
可写（WRITE）：发送缓冲区有空余
出错（ERROR/HUP）：socket 出现异常
事件不是“系统给你单独发通知”，而是你调用接口时查询的结果。


LT（水平触发）模式
机制：
内核维护一个标记：这个 socket 可读/可写。
只要条件成立，下一次 select/poll/epoll_wait 调用就会返回事件。
不需要“系统知道你处理完了”，只要缓冲区还有数据，就一直返回可读。
说明：
你慢慢处理，LT 会重复通知（每次调用接口都返回状态）。
没有“漏掉通知”的概念，只是事件返回可能延迟到你下一次调用接口。


ET（边缘触发）模式
机制：
#####内核只在状态发生变化时通知一次：#####
数据从 0 → >0 可读
发送缓冲区从满 → 有空余
关键：内核只触发一次事件，而不会持续标记“就绪状态”，直到状态再次发生变化。
为什么可能漏掉：
当你开始处理数据时，如果 没一次性把缓冲区读空，缓冲区仍有数据。
新数据到来时，缓冲区已经非空 → 内核认为状态没有变化 → 不再触发事件。
解决方式：
循环读取/写入，直到 EAGAIN / EWOULDBLOCK。 
这样做，相当于告诉系统：“我把这个状态处理完了”，内核才会再次检测新的状态变化。


| 模式     | 系统触发机制          | “处理完再发”机制               |
| ------ | --------------- | ----------------------- |
| **LT** | 条件成立就一直标记为可读/可写 | 不需要，调用接口就能看到            |
| **ET** | 只有状态变化触发一次      | 必须一次性处理完所有数据，否则新事件可能不触发 |


EAGAIN（或者在某些系统上叫 EWOULDBLOCK）是一个 errno 错误码，通常出现在 非阻塞 I/O 操作中，意思是：
中文理解：“资源暂时不可用，请稍后重试”
场景：你尝试读或写一个非阻塞的 socket/文件：
读操作：
缓冲区里没有数据可读 → 返回 -1，errno = EAGAIN
写操作：
发送缓冲区已满，暂时无法写入 → 返回 -1，errno = EAGAIN

非阻塞 I/O 必须检查 EAGAIN，否则会以为出错了。
在 ET（边缘触发）模式下，通常循环读/写直到返回 EAGAIN，表示已经把当前就绪状态处理完了。


上面的
#####内核只在状态发生变化时通知一次：#####
这里的“状态发生变化”是 指内核关注的 I/O 条件从“不满足” → “满足”，它本质上是 socket/文件描述符缓冲区状态的变化。
1. 可读事件（READABLE）
状态条件：内核缓冲区里有数据可读
状态变化触发时机：
缓冲区之前为空（不可读）
新数据到来，缓冲区从空 → 非空
解释：边缘触发（ET）只在这里通知一次，告诉你“现在有数据可读”。
如果你没有一次性把数据读完，再有新数据到来，缓冲区本身还是非空 → 内核认为状态没有变化 → 不再触发事件。
2. 可写事件（WRITABLE）
状态条件：发送缓冲区有空闲空间可写
状态变化触发时机：
发送缓冲区之前满（不可写）
缓冲区有空闲（可写） → 触发写事件
如果缓冲区一直有空闲，ET 也不会重复触发写事件。
3. 出错/关闭事件（ERROR/HUP）
状态变化触发时机：
socket 出现异常、对端关闭、连接断开等
状态变化一次，内核通知一次

LT（水平触发）：只要条件成立，就一直返回事件，不关心“状态变化”
ET（边缘触发）：只有条件从 未满足 → 满足 才触发一次事件
所以，ET 模式下，如果你没有一次性处理完，系统可能认为状态没变化而不再触发事件

1. 场景描述
你在 一个 socket 上使用 ET 模式，并监听可读事件。
流程如下：
数据到达内核缓冲区 → 状态从“不可读”→“可读” → 内核触发 可读事件。
你调用 read() 把缓冲区的数据读完 → 缓冲区为空。
你进行 耗时处理（CPU 操作、数据库操作等），此时没有读操作。
新的数据到达 → 缓冲区再次变为非空。
问题：内核会再次触发可读事件吗？

耗时操作期间是否触发事件：
内核不会因为你正在处理耗时操作而延迟事件。
只要状态发生变化，下一次 epoll_wait 就会返回事件。


LT：Level-Triggered（水平触发）// “水平触发”指：只要条件成立（比如 socket 可读），就一直通知。
ET：Edge-Triggered（边缘触发）// “边缘触发”指：只有状态发生变化（比如从不可读 → 可读）时通知一次。
对于这个场景，如果使用libevent：
需要区分一下 libevent 本身的机制 和 底层内核事件通知机制
1. 底层内核 ET/LT 机制
libevent 本身并不改变内核对 socket 的就绪判断规则：
ET 模式：内核只在状态变化时通知。
LT 模式：内核只要条件成立就会通知。
libevent 调用的就是 epoll/kqueue/select 之类的接口。
2. libevent 的事件队列机制
libevent 提供了一个 事件分发和队列：
    内核返回一批就绪事件（可能是多个 socket，或同一个 socket 多个事件类型）。
    libevent 会把这些事件 放入它自己的事件队列。
    调用 event_base_loop() 时，会 按顺序从队列取出事件并调用回调。
#####也就是说：即使你的回调处理很慢，队列里的事件会顺序排队等待处理。#####
3. 对单个 socket 的情况
假设你用 ET 模式监听可读：
内核通知一次（状态从空 → 非空）。
libevent 把事件放入队列 → 调用回调处理。
回调中耗时操作（比如解析数据、计算等）：
队列中还可以接收 其他 socket 或同一个 socket 新到来的事件。
只要新数据到达且触发状态变化，libevent 会再次把事件放入队列。
效果：
你的回调只处理队列中事件，不会漏掉新来的事件。
实际处理顺序就是 队列顺序，你可以一个一个处理。

对单个 socket：
ET + libevent：你必须在回调里循环读到 EAGAIN，否则可能漏掉当前缓冲区数据。
场景说明
1.2假设一个 socket 可读：
内核缓冲区之前为空 → 新数据到达（一下子很多数据，一次读不完的数据） → 状态变化 → ET 触发一次事件。
2. 回调被调用，你开始 read()：
一次 read() 可能只读走部分数据（例如 1024 字节缓冲区里有 4096 字节）。
3. 剩余数据仍在缓冲区：
状态仍然“可读”，但 ET 已经触发过一次 → 内核不会再触发新的事件。
4. 如果你不循环读完剩余数据，这些数据可能永远不会触发事件 → 回调不会再被调用。

EAGAIN 的意义：
read() 返回 -1，errno = EAGAIN 表示 缓冲区已经空（非阻塞 I/O）。
循环读到 EAGAIN：
确保 当前缓冲区所有可读数据都被消费。
消费完后，如果新数据到来，缓冲区状态变化 → 内核会再次触发 ET 事件。


循环读到 EAGAIN 的效果
你循环读完缓冲区数据 → 缓冲区从 非空 → 空
状态变化方向：
    从 满足条件（非空，可读） → 不满足条件（空，不可读）
但是 ET 不会因为这个变化再次触发事件，ET 只在 空 → 非空 才触发。
#####
ET（Edge-Triggered）只在 状态从空 → 非空 时触发一次事件。
#####


为什么必须读到 EAGAIN
循环读完缓冲区，保证当前的可读数据全部被消费。
否则，缓冲区仍非空：
ET 已经触发过一次
新数据到来可能不会触发，因为缓冲区从非空 → 非空 → 状态没有变化
读到 EAGAIN → 缓冲区空 → 下次新数据到来时会从空 → 非空 → ET 再次触发事件


==================================================socket读缓冲区的数据，是不是已经被系统按顺序组装好了
1. TCP（Transmission Control Protocol）
TCP 是 面向连接、可靠、字节流 的传输层协议。
顺序保证：
内核在接收端会 按发送顺序组装数据，保证 read() 出来的字节序与发送端发送的顺序一致。
即便网络中数据包乱序到达，TCP 会重排。
连续性：
TCP 是字节流，没有消息边界。
比如发送端一次发送 1000 字节，你 read() 可能一次只读 512 字节，剩下 488 字节下次再读。
所以顺序是保证的，但一次 read() 不一定能读到完整“发送块”。

2. UDP（User Datagram Protocol）
UDP 是 无连接、数据报 的传输层协议。
顺序不保证
每个数据报（packet）是独立的。
recvfrom()/recvmsg() 一次只能拿到一个完整数据报。
如果网络乱序，接收端看到的数据报可能与发送顺序不同。

#####
严格来说，“Socket 层”并不是一个单独的层，它是一种 接口（API）层
Socket 是应用程序与内核网络协议栈交互的 编程接口（API）
通过 Socket，应用可以：
发送/接收数据 (send() / recv() 或 write() / read())
设置连接参数（TCP/UDP）
监听端口、接受连接等
2. 与传输层的关系
当你用 TCP/UDP Socket：
      TCP Socket → 对应 传输层 TCP 协议
      UDP Socket → 对应 传输层 UDP 协议
#####Socket 的缓冲区实际上就是 内核 TCP/UDP 协议栈维护的传输层缓冲区。#####
所以：
从功能上看，应用层看到的 Socket 就是传输层的接口。
但它本身不是协议层，只是 API。


Socket 层和系统缓冲区：
TCP socket 的接收缓冲区由内核维护。
数据包到达网卡 → 内核 TCP 协议栈重组 → 放入接收缓冲区 → 用户调用 read() 获取。
顺序保证在 TCP 层由内核实现，用户只需要按顺序读即可，不用担心乱序。


| 协议  | 顺序保证    | read() 特性                    |
| --- | ------- | ---------------------------- |
| TCP | 保证按发送顺序 | 字节流，可能多次 read 才读完发送端一次写入的数据  |
| UDP | 不保证顺序   | 数据报边界保留，一次 recvfrom() 取一个数据报 |
#####


==================================================数据重组是网络层还是传输层处理的
数据重组主要是 传输层（TCP/UDP）处理的，但具体要看你说的“重组”指哪种：

1. 传输层（TCP）负责的数据重组
TCP 是面向字节流的可靠传输协议。
作用：
乱序包重排：如果网络中数据包乱序到达，TCP 会按序号重新排序。
丢包重传：丢失的数据包会通过重传机制补全。
粘包/拆包：TCP 是字节流，没有消息边界，所以接收端需要按字节顺序读数据，内核会把收到的字节按顺序放入 socket 缓冲区。
位置：操作系统内核 TCP 协议栈。

2. 网络层（IP）作用
IP 是 无连接、不可靠 的层。
主要职责：
（1）路由分发：把数据包从源 IP 送到目标 IP。
（2）分片重组（IP 分片）：
      当一个 IP 包大于网络 MTU 时，会被分片传输。
      目标主机 网络层 会在 IP 层把碎片重新组合成完整 IP 数据包，然后交给传输层。
#####重点：IP 层重组的是 IP 包碎片，不涉及 TCP 流的顺序保证。#####


总结流程
应用层 write() → 传输层 TCP 分段 → 网络层 IP 包 → 物理/链路层传输
接收端物理/链路层收到数据 → 网络层 IP 重组碎片 → 传输层 TCP 重排/校验 → 放入 socket 缓冲区 → 应用层 read()

| 层        | 处理内容           | 是否保证顺序            |
| -------- | -------------- | ----------------- |
| IP（网络层）  | IP 包碎片重组       | 不保证最终字节顺序（只是碎片重组） |
| TCP（传输层） | 数据包重排、丢包重传、流组装 | 保证发送顺序、可靠传输       |


==================================================当我们说「TCP 拆成一个个 segment」时，每一个 TCP segment 本质上就是：
[ TCP Header ][ TCP Payload (数据) ]

TCP Header（首部）：
每个 segment 都有一份 TCP 首部，格式固定（最小 20 字节，可带可选字段扩展）。
这个 TCP 首部的格式始终相同：源端口、目的端口、序号、确认号、首部长度、标志位、窗口大小、校验和、紧急指针、可选项。
TCP Payload：
就是当前 segment 承载的应用层数据。可能是很小的一段（甚至没有数据，比如纯 ACK 包），也可能是一大块，具体取决于 MSS、拥塞窗口、流量控制等因素。

TCP segment 的首部就是 TCP 协议头
TCP 把数据流拆分成多个 segment，每个 segment 前面都会加上一个 TCP 头。
底层再在外面套上 IP 头（形成 IP packet），再套上 数据链路层头（形成帧 frame）。

只含 TCP 首部（不带数据）的段也叫 TCP segment（如 SYN、ACK 包）。
带上部分应用层数据（比如 HTTP 数据）的段，还是一个 TCP segment。
这就是 队头阻塞 的一种表现:
HTTP/2 多个请求（A 和 B）会复用同一个 TCP 连接。
只要 A 的数据包丢了、乱序或者延迟重传，TCP 必须等它到达才能把后续数据交给应用层。
结果就是 B 明明网络包到了，也被迫等 A。

HTTP/3（QUIC）里的流是独立的，A 卡住只会影响自己，不会阻塞 B。


在 HTTP/1.1 时代，一个 TCP 连接基本一次只能处理一个请求，想并发就得开多个连接（浏览器一般会对同域名开 6 个左右）。
HTTP/2 引入了 多路复用（Multiplexing）：
在一个 TCP 连接里，可以同时发多个请求和响应。
它把数据切成小帧（frame），给每个请求分配一个 流 ID。
这些帧可以交错发送，然后在另一端重新拼装回原来的请求或响应。
这样一来：
只要 TCP 连接建立好了，多个请求就能在同一连接上并行传输。
避免了 HTTP/1.1 那种 "请求队列化" 的性能瓶颈（除了队头阻塞的问题）。


但也有缺点
虽然多个请求可以复用同一个 TCP 连接，但：
TCP 层只有一个数据流
如果中间某个包丢了，后续所有数据（无论属于哪个请求）都要等它重传 —— 这就是 TCP 队头阻塞。
如果连接断了，所有在这个连接上的请求都会失败，需要重试。

可行：HTTP/2 设计就是为了让多个请求复用同一个 TCP 连接。
代价：一旦底层 TCP 阻塞，所有请求都会被影响，这就是 HTTP/3（基于 QUIC）要解决的问题。